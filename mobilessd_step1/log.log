I0522 16:00:20.950366 13930 caffe.cpp:217] Using GPUs 0
I0522 16:00:21.013188 13930 caffe.cpp:222] GPU 0: GeForce RTX 2080
I0522 16:00:21.302425 13930 solver.cpp:63] Initializing solver from parameters: 
train_net: "mobilessd_step1/Mobilenet448_ssd_train.prototxt"
test_net: "mobilessd_step1/Mobilenet448_ssd_test.prototxt"
test_iter: 142
test_interval: 1000
base_lr: 1e-05
display: 100
max_iter: 200000
lr_policy: "multistep"
gamma: 0.5
weight_decay: 5e-05
snapshot: 1000
snapshot_prefix: "mobilessd_step1/step1"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 20000
stepvalue: 40000
iter_size: 1
type: "RMSProp"
eval_type: "detection"
ap_version: "11point"
I0522 16:00:21.302512 13930 solver.cpp:96] Creating training net from train_net file: mobilessd_step1/Mobilenet448_ssd_train.prototxt
I0522 16:00:21.303218 13930 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/Mobilenet448_ssd_train.prototxt
I0522 16:00:21.303228 13930 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0522 16:00:21.304064 13930 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 448
      width: 448
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
    quant_enable: false
  }
  data_param {
    source: "/home/zhangwanchun/data/VOCdevkit/VOC0712/lmdb/VOC0712_trainval_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/home/zhangwanchun/data/VOCdevkit/VOC0712/lmdb/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "sample_pooling"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "sample_pooling"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 512
    stride: 2
    weight_filler {
      type: "constant_array"
      value_array: 1
      value_array: 0
      value_array: 0
      value_array: 0
    }
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "sample_pooling"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "ip6"
  type: "Convolution"
  bottom: "conv13"
  top: "ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip6"
  top: "ip6"
}
layer {
  name: "ip7"
  type: "Convolution"
  bottom: "ip6"
  top: "ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "ip7"
  top: "ip7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "ip7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv12_norm"
  type: "Normalize"
  bottom: "conv12/dw"
  top: "conv12_norm"
  norm_param {
    across_spatial: false
    channel_shared: false
  }
}
layer {
  name: "conv12_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_loc"
  top: "conv12_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_loc_perm"
  top: "conv12_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_conf"
  top: "conv12_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_conf_perm"
  top: "conv12_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_loc"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_loc_perm"
  type: "Permute"
  bottom: "ip7_mbox_loc"
  top: "ip7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_loc_flat"
  type: "Flatten"
  bottom: "ip7_mbox_loc_perm"
  top: "ip7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_conf"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_conf_perm"
  type: "Permute"
  bottom: "ip7_mbox_conf"
  top: "ip7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_conf_flat"
  type: "Flatten"
  bottom: "ip7_mbox_conf_perm"
  top: "ip7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12/dw_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv12/dw"
  bottom: "data"
  top: "conv12/dw_mbox_priorbox"
  prior_box_param {
    min_size: 44.8
    max_size: 89.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
I0522 16:00:21.304469 13930 layer_factory.hpp:77] Creating layer data
I0522 16:00:21.304570 13930 net.cpp:100] Creating Layer data
I0522 16:00:21.304580 13930 net.cpp:408] data -> data
I0522 16:00:21.304605 13930 net.cpp:408] data -> label
I0522 16:00:21.305361 13953 db_lmdb.cpp:35] Opened lmdb /home/zhangwanchun/data/VOCdevkit/VOC0712/lmdb/VOC0712_trainval_lmdb
I0522 16:00:24.154232 13930 annotated_data_layer.cpp:62] output data size: 1,3,448,448
I0522 16:00:24.157184 13930 net.cpp:150] Setting up data
I0522 16:00:24.157197 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:24.157202 13930 net.cpp:157] Top shape: 1 1 1 8 (8)
I0522 16:00:24.157203 13930 net.cpp:165] Memory required for data: 2408480
I0522 16:00:24.157212 13930 layer_factory.hpp:77] Creating layer data_data_0_split
I0522 16:00:24.157220 13930 net.cpp:100] Creating Layer data_data_0_split
I0522 16:00:24.157224 13930 net.cpp:434] data_data_0_split <- data
I0522 16:00:24.157235 13930 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0522 16:00:24.157248 13930 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0522 16:00:24.157256 13930 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0522 16:00:24.157265 13930 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0522 16:00:24.157271 13930 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0522 16:00:24.157322 13930 net.cpp:150] Setting up data_data_0_split
I0522 16:00:24.157328 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:24.157331 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:24.157335 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:24.157348 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:24.157351 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:24.157352 13930 net.cpp:165] Memory required for data: 14450720
I0522 16:00:24.157356 13930 layer_factory.hpp:77] Creating layer conv0
I0522 16:00:24.157371 13930 net.cpp:100] Creating Layer conv0
I0522 16:00:24.157374 13930 net.cpp:434] conv0 <- data_data_0_split_0
I0522 16:00:24.157383 13930 net.cpp:408] conv0 -> conv0
I0522 16:00:24.873672 13930 net.cpp:150] Setting up conv0
I0522 16:00:24.873692 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.873694 13930 net.cpp:165] Memory required for data: 20873248
I0522 16:00:24.873705 13930 layer_factory.hpp:77] Creating layer conv0/bn
I0522 16:00:24.873713 13930 net.cpp:100] Creating Layer conv0/bn
I0522 16:00:24.873716 13930 net.cpp:434] conv0/bn <- conv0
I0522 16:00:24.873720 13930 net.cpp:395] conv0/bn -> conv0 (in-place)
I0522 16:00:24.874403 13930 net.cpp:150] Setting up conv0/bn
I0522 16:00:24.874413 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.874415 13930 net.cpp:165] Memory required for data: 27295776
I0522 16:00:24.874423 13930 layer_factory.hpp:77] Creating layer conv0/scale
I0522 16:00:24.874430 13930 net.cpp:100] Creating Layer conv0/scale
I0522 16:00:24.874433 13930 net.cpp:434] conv0/scale <- conv0
I0522 16:00:24.874439 13930 net.cpp:395] conv0/scale -> conv0 (in-place)
I0522 16:00:24.874477 13930 layer_factory.hpp:77] Creating layer conv0/scale
I0522 16:00:24.874598 13930 net.cpp:150] Setting up conv0/scale
I0522 16:00:24.874603 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.874605 13930 net.cpp:165] Memory required for data: 33718304
I0522 16:00:24.874610 13930 layer_factory.hpp:77] Creating layer conv0/relu
I0522 16:00:24.874616 13930 net.cpp:100] Creating Layer conv0/relu
I0522 16:00:24.874619 13930 net.cpp:434] conv0/relu <- conv0
I0522 16:00:24.874624 13930 net.cpp:395] conv0/relu -> conv0 (in-place)
I0522 16:00:24.874964 13930 net.cpp:150] Setting up conv0/relu
I0522 16:00:24.874971 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.874974 13930 net.cpp:165] Memory required for data: 40140832
I0522 16:00:24.874976 13930 layer_factory.hpp:77] Creating layer conv1/dw
I0522 16:00:24.874984 13930 net.cpp:100] Creating Layer conv1/dw
I0522 16:00:24.874986 13930 net.cpp:434] conv1/dw <- conv0
I0522 16:00:24.874991 13930 net.cpp:408] conv1/dw -> conv1/dw
I0522 16:00:24.875149 13930 net.cpp:150] Setting up conv1/dw
I0522 16:00:24.875155 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.875157 13930 net.cpp:165] Memory required for data: 46563360
I0522 16:00:24.875160 13930 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0522 16:00:24.875164 13930 net.cpp:100] Creating Layer conv1/dw/bn
I0522 16:00:24.875166 13930 net.cpp:434] conv1/dw/bn <- conv1/dw
I0522 16:00:24.875169 13930 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0522 16:00:24.875324 13930 net.cpp:150] Setting up conv1/dw/bn
I0522 16:00:24.875330 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.875332 13930 net.cpp:165] Memory required for data: 52985888
I0522 16:00:24.875337 13930 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0522 16:00:24.875342 13930 net.cpp:100] Creating Layer conv1/dw/scale
I0522 16:00:24.875345 13930 net.cpp:434] conv1/dw/scale <- conv1/dw
I0522 16:00:24.875349 13930 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0522 16:00:24.875381 13930 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0522 16:00:24.875494 13930 net.cpp:150] Setting up conv1/dw/scale
I0522 16:00:24.875500 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.875502 13930 net.cpp:165] Memory required for data: 59408416
I0522 16:00:24.875506 13930 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0522 16:00:24.875509 13930 net.cpp:100] Creating Layer conv1/dw/relu
I0522 16:00:24.875512 13930 net.cpp:434] conv1/dw/relu <- conv1/dw
I0522 16:00:24.875516 13930 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0522 16:00:24.876045 13930 net.cpp:150] Setting up conv1/dw/relu
I0522 16:00:24.876053 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:24.876056 13930 net.cpp:165] Memory required for data: 65830944
I0522 16:00:24.876058 13930 layer_factory.hpp:77] Creating layer conv1
I0522 16:00:24.876065 13930 net.cpp:100] Creating Layer conv1
I0522 16:00:24.876067 13930 net.cpp:434] conv1 <- conv1/dw
I0522 16:00:24.876072 13930 net.cpp:408] conv1 -> conv1
I0522 16:00:24.878175 13930 net.cpp:150] Setting up conv1
I0522 16:00:24.878186 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:24.878188 13930 net.cpp:165] Memory required for data: 78676000
I0522 16:00:24.878192 13930 layer_factory.hpp:77] Creating layer conv1/bn
I0522 16:00:24.878196 13930 net.cpp:100] Creating Layer conv1/bn
I0522 16:00:24.878198 13930 net.cpp:434] conv1/bn <- conv1
I0522 16:00:24.878202 13930 net.cpp:395] conv1/bn -> conv1 (in-place)
I0522 16:00:24.878368 13930 net.cpp:150] Setting up conv1/bn
I0522 16:00:24.878374 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:24.878376 13930 net.cpp:165] Memory required for data: 91521056
I0522 16:00:24.878381 13930 layer_factory.hpp:77] Creating layer conv1/scale
I0522 16:00:24.878386 13930 net.cpp:100] Creating Layer conv1/scale
I0522 16:00:24.878387 13930 net.cpp:434] conv1/scale <- conv1
I0522 16:00:24.878391 13930 net.cpp:395] conv1/scale -> conv1 (in-place)
I0522 16:00:24.878422 13930 layer_factory.hpp:77] Creating layer conv1/scale
I0522 16:00:24.878541 13930 net.cpp:150] Setting up conv1/scale
I0522 16:00:24.878547 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:24.878549 13930 net.cpp:165] Memory required for data: 104366112
I0522 16:00:24.878556 13930 layer_factory.hpp:77] Creating layer conv1/relu
I0522 16:00:24.878559 13930 net.cpp:100] Creating Layer conv1/relu
I0522 16:00:24.878562 13930 net.cpp:434] conv1/relu <- conv1
I0522 16:00:24.878566 13930 net.cpp:395] conv1/relu -> conv1 (in-place)
I0522 16:00:24.878904 13930 net.cpp:150] Setting up conv1/relu
I0522 16:00:24.878913 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:24.878916 13930 net.cpp:165] Memory required for data: 117211168
I0522 16:00:24.878917 13930 layer_factory.hpp:77] Creating layer conv2/dw
I0522 16:00:24.878922 13930 net.cpp:100] Creating Layer conv2/dw
I0522 16:00:24.878926 13930 net.cpp:434] conv2/dw <- conv1
I0522 16:00:24.878931 13930 net.cpp:408] conv2/dw -> conv2/dw
I0522 16:00:24.879169 13930 net.cpp:150] Setting up conv2/dw
I0522 16:00:24.879175 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:24.879178 13930 net.cpp:165] Memory required for data: 120422432
I0522 16:00:24.879180 13930 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0522 16:00:24.879184 13930 net.cpp:100] Creating Layer conv2/dw/bn
I0522 16:00:24.879186 13930 net.cpp:434] conv2/dw/bn <- conv2/dw
I0522 16:00:24.879189 13930 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0522 16:00:24.879819 13930 net.cpp:150] Setting up conv2/dw/bn
I0522 16:00:24.879827 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:24.879829 13930 net.cpp:165] Memory required for data: 123633696
I0522 16:00:24.879834 13930 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0522 16:00:24.879842 13930 net.cpp:100] Creating Layer conv2/dw/scale
I0522 16:00:24.879844 13930 net.cpp:434] conv2/dw/scale <- conv2/dw
I0522 16:00:24.879848 13930 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0522 16:00:24.879884 13930 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0522 16:00:24.879973 13930 net.cpp:150] Setting up conv2/dw/scale
I0522 16:00:24.879978 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:24.879981 13930 net.cpp:165] Memory required for data: 126844960
I0522 16:00:24.879984 13930 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0522 16:00:24.879987 13930 net.cpp:100] Creating Layer conv2/dw/relu
I0522 16:00:24.879989 13930 net.cpp:434] conv2/dw/relu <- conv2/dw
I0522 16:00:24.879993 13930 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0522 16:00:24.881333 13930 net.cpp:150] Setting up conv2/dw/relu
I0522 16:00:24.881352 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:24.881356 13930 net.cpp:165] Memory required for data: 130056224
I0522 16:00:24.881357 13930 layer_factory.hpp:77] Creating layer conv2
I0522 16:00:24.881364 13930 net.cpp:100] Creating Layer conv2
I0522 16:00:24.881366 13930 net.cpp:434] conv2 <- conv2/dw
I0522 16:00:24.881371 13930 net.cpp:408] conv2 -> conv2
I0522 16:00:24.883178 13930 net.cpp:150] Setting up conv2
I0522 16:00:24.883188 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.883190 13930 net.cpp:165] Memory required for data: 136478752
I0522 16:00:24.883193 13930 layer_factory.hpp:77] Creating layer conv2/bn
I0522 16:00:24.883198 13930 net.cpp:100] Creating Layer conv2/bn
I0522 16:00:24.883201 13930 net.cpp:434] conv2/bn <- conv2
I0522 16:00:24.883205 13930 net.cpp:395] conv2/bn -> conv2 (in-place)
I0522 16:00:24.883353 13930 net.cpp:150] Setting up conv2/bn
I0522 16:00:24.883358 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.883361 13930 net.cpp:165] Memory required for data: 142901280
I0522 16:00:24.883365 13930 layer_factory.hpp:77] Creating layer conv2/scale
I0522 16:00:24.883369 13930 net.cpp:100] Creating Layer conv2/scale
I0522 16:00:24.883371 13930 net.cpp:434] conv2/scale <- conv2
I0522 16:00:24.883375 13930 net.cpp:395] conv2/scale -> conv2 (in-place)
I0522 16:00:24.883404 13930 layer_factory.hpp:77] Creating layer conv2/scale
I0522 16:00:24.883486 13930 net.cpp:150] Setting up conv2/scale
I0522 16:00:24.883491 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.883493 13930 net.cpp:165] Memory required for data: 149323808
I0522 16:00:24.883497 13930 layer_factory.hpp:77] Creating layer conv2/relu
I0522 16:00:24.883500 13930 net.cpp:100] Creating Layer conv2/relu
I0522 16:00:24.883502 13930 net.cpp:434] conv2/relu <- conv2
I0522 16:00:24.883507 13930 net.cpp:395] conv2/relu -> conv2 (in-place)
I0522 16:00:24.883848 13930 net.cpp:150] Setting up conv2/relu
I0522 16:00:24.883857 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.883858 13930 net.cpp:165] Memory required for data: 155746336
I0522 16:00:24.883860 13930 layer_factory.hpp:77] Creating layer conv3/dw
I0522 16:00:24.883867 13930 net.cpp:100] Creating Layer conv3/dw
I0522 16:00:24.883873 13930 net.cpp:434] conv3/dw <- conv2
I0522 16:00:24.883878 13930 net.cpp:408] conv3/dw -> conv3/dw
I0522 16:00:24.884069 13930 net.cpp:150] Setting up conv3/dw
I0522 16:00:24.884075 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.884078 13930 net.cpp:165] Memory required for data: 162168864
I0522 16:00:24.884080 13930 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0522 16:00:24.884084 13930 net.cpp:100] Creating Layer conv3/dw/bn
I0522 16:00:24.884086 13930 net.cpp:434] conv3/dw/bn <- conv3/dw
I0522 16:00:24.884089 13930 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0522 16:00:24.884228 13930 net.cpp:150] Setting up conv3/dw/bn
I0522 16:00:24.884233 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.884236 13930 net.cpp:165] Memory required for data: 168591392
I0522 16:00:24.884243 13930 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0522 16:00:24.884248 13930 net.cpp:100] Creating Layer conv3/dw/scale
I0522 16:00:24.884249 13930 net.cpp:434] conv3/dw/scale <- conv3/dw
I0522 16:00:24.884253 13930 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0522 16:00:24.884282 13930 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0522 16:00:24.884367 13930 net.cpp:150] Setting up conv3/dw/scale
I0522 16:00:24.884372 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.884374 13930 net.cpp:165] Memory required for data: 175013920
I0522 16:00:24.884378 13930 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0522 16:00:24.884382 13930 net.cpp:100] Creating Layer conv3/dw/relu
I0522 16:00:24.884383 13930 net.cpp:434] conv3/dw/relu <- conv3/dw
I0522 16:00:24.884387 13930 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0522 16:00:24.884923 13930 net.cpp:150] Setting up conv3/dw/relu
I0522 16:00:24.884938 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.884940 13930 net.cpp:165] Memory required for data: 181436448
I0522 16:00:24.884943 13930 layer_factory.hpp:77] Creating layer conv3
I0522 16:00:24.884949 13930 net.cpp:100] Creating Layer conv3
I0522 16:00:24.884953 13930 net.cpp:434] conv3 <- conv3/dw
I0522 16:00:24.884956 13930 net.cpp:408] conv3 -> conv3
I0522 16:00:24.886798 13930 net.cpp:150] Setting up conv3
I0522 16:00:24.886822 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.886824 13930 net.cpp:165] Memory required for data: 187858976
I0522 16:00:24.886828 13930 layer_factory.hpp:77] Creating layer conv3/bn
I0522 16:00:24.886832 13930 net.cpp:100] Creating Layer conv3/bn
I0522 16:00:24.886834 13930 net.cpp:434] conv3/bn <- conv3
I0522 16:00:24.886838 13930 net.cpp:395] conv3/bn -> conv3 (in-place)
I0522 16:00:24.887087 13930 net.cpp:150] Setting up conv3/bn
I0522 16:00:24.887092 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.887095 13930 net.cpp:165] Memory required for data: 194281504
I0522 16:00:24.887099 13930 layer_factory.hpp:77] Creating layer conv3/scale
I0522 16:00:24.887104 13930 net.cpp:100] Creating Layer conv3/scale
I0522 16:00:24.887106 13930 net.cpp:434] conv3/scale <- conv3
I0522 16:00:24.887109 13930 net.cpp:395] conv3/scale -> conv3 (in-place)
I0522 16:00:24.887154 13930 layer_factory.hpp:77] Creating layer conv3/scale
I0522 16:00:24.887326 13930 net.cpp:150] Setting up conv3/scale
I0522 16:00:24.887331 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.887333 13930 net.cpp:165] Memory required for data: 200704032
I0522 16:00:24.887336 13930 layer_factory.hpp:77] Creating layer conv3/relu
I0522 16:00:24.887341 13930 net.cpp:100] Creating Layer conv3/relu
I0522 16:00:24.887344 13930 net.cpp:434] conv3/relu <- conv3
I0522 16:00:24.887348 13930 net.cpp:395] conv3/relu -> conv3 (in-place)
I0522 16:00:24.887704 13930 net.cpp:150] Setting up conv3/relu
I0522 16:00:24.887712 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:24.887729 13930 net.cpp:165] Memory required for data: 207126560
I0522 16:00:24.887732 13930 layer_factory.hpp:77] Creating layer conv4/dw
I0522 16:00:24.887738 13930 net.cpp:100] Creating Layer conv4/dw
I0522 16:00:24.887740 13930 net.cpp:434] conv4/dw <- conv3
I0522 16:00:24.887745 13930 net.cpp:408] conv4/dw -> conv4/dw
I0522 16:00:24.887928 13930 net.cpp:150] Setting up conv4/dw
I0522 16:00:24.887935 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:24.887938 13930 net.cpp:165] Memory required for data: 208732192
I0522 16:00:24.887944 13930 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0522 16:00:24.887950 13930 net.cpp:100] Creating Layer conv4/dw/bn
I0522 16:00:24.887954 13930 net.cpp:434] conv4/dw/bn <- conv4/dw
I0522 16:00:24.887960 13930 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0522 16:00:24.888118 13930 net.cpp:150] Setting up conv4/dw/bn
I0522 16:00:24.888123 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:24.888128 13930 net.cpp:165] Memory required for data: 210337824
I0522 16:00:24.888134 13930 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0522 16:00:24.888144 13930 net.cpp:100] Creating Layer conv4/dw/scale
I0522 16:00:24.888149 13930 net.cpp:434] conv4/dw/scale <- conv4/dw
I0522 16:00:24.888152 13930 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0522 16:00:24.888185 13930 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0522 16:00:24.888273 13930 net.cpp:150] Setting up conv4/dw/scale
I0522 16:00:24.888278 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:24.888281 13930 net.cpp:165] Memory required for data: 211943456
I0522 16:00:24.888288 13930 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0522 16:00:24.888293 13930 net.cpp:100] Creating Layer conv4/dw/relu
I0522 16:00:24.888298 13930 net.cpp:434] conv4/dw/relu <- conv4/dw
I0522 16:00:24.888304 13930 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0522 16:00:24.889654 13930 net.cpp:150] Setting up conv4/dw/relu
I0522 16:00:24.889678 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:24.889680 13930 net.cpp:165] Memory required for data: 213549088
I0522 16:00:24.889683 13930 layer_factory.hpp:77] Creating layer conv4
I0522 16:00:24.889689 13930 net.cpp:100] Creating Layer conv4
I0522 16:00:24.889693 13930 net.cpp:434] conv4 <- conv4/dw
I0522 16:00:24.889698 13930 net.cpp:408] conv4 -> conv4
I0522 16:00:24.891482 13930 net.cpp:150] Setting up conv4
I0522 16:00:24.891494 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.891496 13930 net.cpp:165] Memory required for data: 216760352
I0522 16:00:24.891500 13930 layer_factory.hpp:77] Creating layer conv4/bn
I0522 16:00:24.891505 13930 net.cpp:100] Creating Layer conv4/bn
I0522 16:00:24.891507 13930 net.cpp:434] conv4/bn <- conv4
I0522 16:00:24.891511 13930 net.cpp:395] conv4/bn -> conv4 (in-place)
I0522 16:00:24.891666 13930 net.cpp:150] Setting up conv4/bn
I0522 16:00:24.891671 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.891674 13930 net.cpp:165] Memory required for data: 219971616
I0522 16:00:24.891678 13930 layer_factory.hpp:77] Creating layer conv4/scale
I0522 16:00:24.891683 13930 net.cpp:100] Creating Layer conv4/scale
I0522 16:00:24.891686 13930 net.cpp:434] conv4/scale <- conv4
I0522 16:00:24.891690 13930 net.cpp:395] conv4/scale -> conv4 (in-place)
I0522 16:00:24.891721 13930 layer_factory.hpp:77] Creating layer conv4/scale
I0522 16:00:24.891805 13930 net.cpp:150] Setting up conv4/scale
I0522 16:00:24.891810 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.891813 13930 net.cpp:165] Memory required for data: 223182880
I0522 16:00:24.891818 13930 layer_factory.hpp:77] Creating layer conv4/relu
I0522 16:00:24.891821 13930 net.cpp:100] Creating Layer conv4/relu
I0522 16:00:24.891824 13930 net.cpp:434] conv4/relu <- conv4
I0522 16:00:24.891827 13930 net.cpp:395] conv4/relu -> conv4 (in-place)
I0522 16:00:24.892211 13930 net.cpp:150] Setting up conv4/relu
I0522 16:00:24.892220 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.892222 13930 net.cpp:165] Memory required for data: 226394144
I0522 16:00:24.892225 13930 layer_factory.hpp:77] Creating layer conv5/dw
I0522 16:00:24.892230 13930 net.cpp:100] Creating Layer conv5/dw
I0522 16:00:24.892235 13930 net.cpp:434] conv5/dw <- conv4
I0522 16:00:24.892238 13930 net.cpp:408] conv5/dw -> conv5/dw
I0522 16:00:24.892406 13930 net.cpp:150] Setting up conv5/dw
I0522 16:00:24.892412 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.892416 13930 net.cpp:165] Memory required for data: 229605408
I0522 16:00:24.892418 13930 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0522 16:00:24.892422 13930 net.cpp:100] Creating Layer conv5/dw/bn
I0522 16:00:24.892426 13930 net.cpp:434] conv5/dw/bn <- conv5/dw
I0522 16:00:24.892428 13930 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0522 16:00:24.892566 13930 net.cpp:150] Setting up conv5/dw/bn
I0522 16:00:24.892571 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.892573 13930 net.cpp:165] Memory required for data: 232816672
I0522 16:00:24.892580 13930 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0522 16:00:24.892583 13930 net.cpp:100] Creating Layer conv5/dw/scale
I0522 16:00:24.892585 13930 net.cpp:434] conv5/dw/scale <- conv5/dw
I0522 16:00:24.892590 13930 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0522 16:00:24.892621 13930 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0522 16:00:24.892702 13930 net.cpp:150] Setting up conv5/dw/scale
I0522 16:00:24.892707 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.892710 13930 net.cpp:165] Memory required for data: 236027936
I0522 16:00:24.892714 13930 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0522 16:00:24.892719 13930 net.cpp:100] Creating Layer conv5/dw/relu
I0522 16:00:24.892721 13930 net.cpp:434] conv5/dw/relu <- conv5/dw
I0522 16:00:24.892725 13930 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0522 16:00:24.893242 13930 net.cpp:150] Setting up conv5/dw/relu
I0522 16:00:24.893257 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.893261 13930 net.cpp:165] Memory required for data: 239239200
I0522 16:00:24.893265 13930 layer_factory.hpp:77] Creating layer conv5
I0522 16:00:24.893275 13930 net.cpp:100] Creating Layer conv5
I0522 16:00:24.893280 13930 net.cpp:434] conv5 <- conv5/dw
I0522 16:00:24.893286 13930 net.cpp:408] conv5 -> conv5
I0522 16:00:24.895771 13930 net.cpp:150] Setting up conv5
I0522 16:00:24.895781 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.895784 13930 net.cpp:165] Memory required for data: 242450464
I0522 16:00:24.895787 13930 layer_factory.hpp:77] Creating layer conv5/bn
I0522 16:00:24.895793 13930 net.cpp:100] Creating Layer conv5/bn
I0522 16:00:24.895797 13930 net.cpp:434] conv5/bn <- conv5
I0522 16:00:24.895800 13930 net.cpp:395] conv5/bn -> conv5 (in-place)
I0522 16:00:24.895962 13930 net.cpp:150] Setting up conv5/bn
I0522 16:00:24.895967 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.895972 13930 net.cpp:165] Memory required for data: 245661728
I0522 16:00:24.895975 13930 layer_factory.hpp:77] Creating layer conv5/scale
I0522 16:00:24.895980 13930 net.cpp:100] Creating Layer conv5/scale
I0522 16:00:24.895982 13930 net.cpp:434] conv5/scale <- conv5
I0522 16:00:24.895987 13930 net.cpp:395] conv5/scale -> conv5 (in-place)
I0522 16:00:24.896018 13930 layer_factory.hpp:77] Creating layer conv5/scale
I0522 16:00:24.896102 13930 net.cpp:150] Setting up conv5/scale
I0522 16:00:24.896107 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.896111 13930 net.cpp:165] Memory required for data: 248872992
I0522 16:00:24.896121 13930 layer_factory.hpp:77] Creating layer conv5/relu
I0522 16:00:24.896127 13930 net.cpp:100] Creating Layer conv5/relu
I0522 16:00:24.896131 13930 net.cpp:434] conv5/relu <- conv5
I0522 16:00:24.896134 13930 net.cpp:395] conv5/relu -> conv5 (in-place)
I0522 16:00:24.896469 13930 net.cpp:150] Setting up conv5/relu
I0522 16:00:24.896476 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:24.896479 13930 net.cpp:165] Memory required for data: 252084256
I0522 16:00:24.896482 13930 layer_factory.hpp:77] Creating layer conv6/dw
I0522 16:00:24.896489 13930 net.cpp:100] Creating Layer conv6/dw
I0522 16:00:24.896494 13930 net.cpp:434] conv6/dw <- conv5
I0522 16:00:24.896502 13930 net.cpp:408] conv6/dw -> conv6/dw
I0522 16:00:24.896728 13930 net.cpp:150] Setting up conv6/dw
I0522 16:00:24.896733 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:24.896737 13930 net.cpp:165] Memory required for data: 252887072
I0522 16:00:24.896742 13930 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0522 16:00:24.896749 13930 net.cpp:100] Creating Layer conv6/dw/bn
I0522 16:00:24.896752 13930 net.cpp:434] conv6/dw/bn <- conv6/dw
I0522 16:00:24.896759 13930 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0522 16:00:24.896940 13930 net.cpp:150] Setting up conv6/dw/bn
I0522 16:00:24.896945 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:24.896950 13930 net.cpp:165] Memory required for data: 253689888
I0522 16:00:24.896956 13930 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0522 16:00:24.896961 13930 net.cpp:100] Creating Layer conv6/dw/scale
I0522 16:00:24.896965 13930 net.cpp:434] conv6/dw/scale <- conv6/dw
I0522 16:00:24.896971 13930 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0522 16:00:24.897003 13930 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0522 16:00:24.897094 13930 net.cpp:150] Setting up conv6/dw/scale
I0522 16:00:24.897100 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:24.897104 13930 net.cpp:165] Memory required for data: 254492704
I0522 16:00:24.897110 13930 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0522 16:00:24.897115 13930 net.cpp:100] Creating Layer conv6/dw/relu
I0522 16:00:24.897119 13930 net.cpp:434] conv6/dw/relu <- conv6/dw
I0522 16:00:24.897126 13930 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0522 16:00:24.898447 13930 net.cpp:150] Setting up conv6/dw/relu
I0522 16:00:24.898458 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:24.898469 13930 net.cpp:165] Memory required for data: 255295520
I0522 16:00:24.898475 13930 layer_factory.hpp:77] Creating layer conv6
I0522 16:00:24.898483 13930 net.cpp:100] Creating Layer conv6
I0522 16:00:24.898486 13930 net.cpp:434] conv6 <- conv6/dw
I0522 16:00:24.898494 13930 net.cpp:408] conv6 -> conv6
I0522 16:00:24.901588 13930 net.cpp:150] Setting up conv6
I0522 16:00:24.901597 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.901600 13930 net.cpp:165] Memory required for data: 256901152
I0522 16:00:24.901605 13930 layer_factory.hpp:77] Creating layer conv6/bn
I0522 16:00:24.901613 13930 net.cpp:100] Creating Layer conv6/bn
I0522 16:00:24.901618 13930 net.cpp:434] conv6/bn <- conv6
I0522 16:00:24.901624 13930 net.cpp:395] conv6/bn -> conv6 (in-place)
I0522 16:00:24.901787 13930 net.cpp:150] Setting up conv6/bn
I0522 16:00:24.901793 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.901796 13930 net.cpp:165] Memory required for data: 258506784
I0522 16:00:24.901803 13930 layer_factory.hpp:77] Creating layer conv6/scale
I0522 16:00:24.901810 13930 net.cpp:100] Creating Layer conv6/scale
I0522 16:00:24.901814 13930 net.cpp:434] conv6/scale <- conv6
I0522 16:00:24.901819 13930 net.cpp:395] conv6/scale -> conv6 (in-place)
I0522 16:00:24.901854 13930 layer_factory.hpp:77] Creating layer conv6/scale
I0522 16:00:24.901947 13930 net.cpp:150] Setting up conv6/scale
I0522 16:00:24.901952 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.901957 13930 net.cpp:165] Memory required for data: 260112416
I0522 16:00:24.901962 13930 layer_factory.hpp:77] Creating layer conv6/relu
I0522 16:00:24.901968 13930 net.cpp:100] Creating Layer conv6/relu
I0522 16:00:24.901971 13930 net.cpp:434] conv6/relu <- conv6
I0522 16:00:24.901976 13930 net.cpp:395] conv6/relu -> conv6 (in-place)
I0522 16:00:24.902323 13930 net.cpp:150] Setting up conv6/relu
I0522 16:00:24.902329 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.902333 13930 net.cpp:165] Memory required for data: 261718048
I0522 16:00:24.902338 13930 layer_factory.hpp:77] Creating layer conv7/dw
I0522 16:00:24.902348 13930 net.cpp:100] Creating Layer conv7/dw
I0522 16:00:24.902351 13930 net.cpp:434] conv7/dw <- conv6
I0522 16:00:24.902359 13930 net.cpp:408] conv7/dw -> conv7/dw
I0522 16:00:24.902542 13930 net.cpp:150] Setting up conv7/dw
I0522 16:00:24.902549 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.902552 13930 net.cpp:165] Memory required for data: 263323680
I0522 16:00:24.902556 13930 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0522 16:00:24.902563 13930 net.cpp:100] Creating Layer conv7/dw/bn
I0522 16:00:24.902567 13930 net.cpp:434] conv7/dw/bn <- conv7/dw
I0522 16:00:24.902571 13930 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0522 16:00:24.902722 13930 net.cpp:150] Setting up conv7/dw/bn
I0522 16:00:24.902727 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.902731 13930 net.cpp:165] Memory required for data: 264929312
I0522 16:00:24.902738 13930 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0522 16:00:24.902745 13930 net.cpp:100] Creating Layer conv7/dw/scale
I0522 16:00:24.902748 13930 net.cpp:434] conv7/dw/scale <- conv7/dw
I0522 16:00:24.902753 13930 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0522 16:00:24.902786 13930 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0522 16:00:24.902899 13930 net.cpp:150] Setting up conv7/dw/scale
I0522 16:00:24.902904 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.902909 13930 net.cpp:165] Memory required for data: 266534944
I0522 16:00:24.902915 13930 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0522 16:00:24.902920 13930 net.cpp:100] Creating Layer conv7/dw/relu
I0522 16:00:24.902925 13930 net.cpp:434] conv7/dw/relu <- conv7/dw
I0522 16:00:24.902931 13930 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0522 16:00:24.903463 13930 net.cpp:150] Setting up conv7/dw/relu
I0522 16:00:24.903473 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.903484 13930 net.cpp:165] Memory required for data: 268140576
I0522 16:00:24.903489 13930 layer_factory.hpp:77] Creating layer conv7
I0522 16:00:24.903499 13930 net.cpp:100] Creating Layer conv7
I0522 16:00:24.903502 13930 net.cpp:434] conv7 <- conv7/dw
I0522 16:00:24.903508 13930 net.cpp:408] conv7 -> conv7
I0522 16:00:24.906965 13930 net.cpp:150] Setting up conv7
I0522 16:00:24.906973 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.906976 13930 net.cpp:165] Memory required for data: 269746208
I0522 16:00:24.906981 13930 layer_factory.hpp:77] Creating layer conv7/bn
I0522 16:00:24.906988 13930 net.cpp:100] Creating Layer conv7/bn
I0522 16:00:24.906991 13930 net.cpp:434] conv7/bn <- conv7
I0522 16:00:24.907016 13930 net.cpp:395] conv7/bn -> conv7 (in-place)
I0522 16:00:24.907197 13930 net.cpp:150] Setting up conv7/bn
I0522 16:00:24.907203 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.907205 13930 net.cpp:165] Memory required for data: 271351840
I0522 16:00:24.907210 13930 layer_factory.hpp:77] Creating layer conv7/scale
I0522 16:00:24.907214 13930 net.cpp:100] Creating Layer conv7/scale
I0522 16:00:24.907217 13930 net.cpp:434] conv7/scale <- conv7
I0522 16:00:24.907220 13930 net.cpp:395] conv7/scale -> conv7 (in-place)
I0522 16:00:24.907253 13930 layer_factory.hpp:77] Creating layer conv7/scale
I0522 16:00:24.907385 13930 net.cpp:150] Setting up conv7/scale
I0522 16:00:24.907390 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.907392 13930 net.cpp:165] Memory required for data: 272957472
I0522 16:00:24.907397 13930 layer_factory.hpp:77] Creating layer conv7/relu
I0522 16:00:24.907399 13930 net.cpp:100] Creating Layer conv7/relu
I0522 16:00:24.907402 13930 net.cpp:434] conv7/relu <- conv7
I0522 16:00:24.907407 13930 net.cpp:395] conv7/relu -> conv7 (in-place)
I0522 16:00:24.907752 13930 net.cpp:150] Setting up conv7/relu
I0522 16:00:24.907759 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.907763 13930 net.cpp:165] Memory required for data: 274563104
I0522 16:00:24.907764 13930 layer_factory.hpp:77] Creating layer conv8/dw
I0522 16:00:24.907770 13930 net.cpp:100] Creating Layer conv8/dw
I0522 16:00:24.907773 13930 net.cpp:434] conv8/dw <- conv7
I0522 16:00:24.907778 13930 net.cpp:408] conv8/dw -> conv8/dw
I0522 16:00:24.907965 13930 net.cpp:150] Setting up conv8/dw
I0522 16:00:24.907971 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.907974 13930 net.cpp:165] Memory required for data: 276168736
I0522 16:00:24.907976 13930 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0522 16:00:24.907980 13930 net.cpp:100] Creating Layer conv8/dw/bn
I0522 16:00:24.907982 13930 net.cpp:434] conv8/dw/bn <- conv8/dw
I0522 16:00:24.907986 13930 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0522 16:00:24.908134 13930 net.cpp:150] Setting up conv8/dw/bn
I0522 16:00:24.908139 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.908141 13930 net.cpp:165] Memory required for data: 277774368
I0522 16:00:24.908145 13930 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0522 16:00:24.908155 13930 net.cpp:100] Creating Layer conv8/dw/scale
I0522 16:00:24.908157 13930 net.cpp:434] conv8/dw/scale <- conv8/dw
I0522 16:00:24.908160 13930 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0522 16:00:24.908192 13930 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0522 16:00:24.908324 13930 net.cpp:150] Setting up conv8/dw/scale
I0522 16:00:24.908329 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.908331 13930 net.cpp:165] Memory required for data: 279380000
I0522 16:00:24.908335 13930 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0522 16:00:24.908339 13930 net.cpp:100] Creating Layer conv8/dw/relu
I0522 16:00:24.908341 13930 net.cpp:434] conv8/dw/relu <- conv8/dw
I0522 16:00:24.908345 13930 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0522 16:00:24.908859 13930 net.cpp:150] Setting up conv8/dw/relu
I0522 16:00:24.908867 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.908876 13930 net.cpp:165] Memory required for data: 280985632
I0522 16:00:24.908879 13930 layer_factory.hpp:77] Creating layer conv8
I0522 16:00:24.908885 13930 net.cpp:100] Creating Layer conv8
I0522 16:00:24.908886 13930 net.cpp:434] conv8 <- conv8/dw
I0522 16:00:24.908892 13930 net.cpp:408] conv8 -> conv8
I0522 16:00:24.913379 13930 net.cpp:150] Setting up conv8
I0522 16:00:24.913388 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.913391 13930 net.cpp:165] Memory required for data: 282591264
I0522 16:00:24.913395 13930 layer_factory.hpp:77] Creating layer conv8/bn
I0522 16:00:24.913401 13930 net.cpp:100] Creating Layer conv8/bn
I0522 16:00:24.913403 13930 net.cpp:434] conv8/bn <- conv8
I0522 16:00:24.913408 13930 net.cpp:395] conv8/bn -> conv8 (in-place)
I0522 16:00:24.913573 13930 net.cpp:150] Setting up conv8/bn
I0522 16:00:24.913578 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.913579 13930 net.cpp:165] Memory required for data: 284196896
I0522 16:00:24.913583 13930 layer_factory.hpp:77] Creating layer conv8/scale
I0522 16:00:24.913588 13930 net.cpp:100] Creating Layer conv8/scale
I0522 16:00:24.913590 13930 net.cpp:434] conv8/scale <- conv8
I0522 16:00:24.913594 13930 net.cpp:395] conv8/scale -> conv8 (in-place)
I0522 16:00:24.913625 13930 layer_factory.hpp:77] Creating layer conv8/scale
I0522 16:00:24.913759 13930 net.cpp:150] Setting up conv8/scale
I0522 16:00:24.913764 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.913766 13930 net.cpp:165] Memory required for data: 285802528
I0522 16:00:24.913770 13930 layer_factory.hpp:77] Creating layer conv8/relu
I0522 16:00:24.913774 13930 net.cpp:100] Creating Layer conv8/relu
I0522 16:00:24.913775 13930 net.cpp:434] conv8/relu <- conv8
I0522 16:00:24.913779 13930 net.cpp:395] conv8/relu -> conv8 (in-place)
I0522 16:00:24.914121 13930 net.cpp:150] Setting up conv8/relu
I0522 16:00:24.914130 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.914132 13930 net.cpp:165] Memory required for data: 287408160
I0522 16:00:24.914135 13930 layer_factory.hpp:77] Creating layer conv9/dw
I0522 16:00:24.914140 13930 net.cpp:100] Creating Layer conv9/dw
I0522 16:00:24.914142 13930 net.cpp:434] conv9/dw <- conv8
I0522 16:00:24.914147 13930 net.cpp:408] conv9/dw -> conv9/dw
I0522 16:00:24.914330 13930 net.cpp:150] Setting up conv9/dw
I0522 16:00:24.914336 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.914338 13930 net.cpp:165] Memory required for data: 289013792
I0522 16:00:24.914342 13930 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0522 16:00:24.914345 13930 net.cpp:100] Creating Layer conv9/dw/bn
I0522 16:00:24.914347 13930 net.cpp:434] conv9/dw/bn <- conv9/dw
I0522 16:00:24.914350 13930 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0522 16:00:24.914500 13930 net.cpp:150] Setting up conv9/dw/bn
I0522 16:00:24.914505 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.914507 13930 net.cpp:165] Memory required for data: 290619424
I0522 16:00:24.914511 13930 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0522 16:00:24.914515 13930 net.cpp:100] Creating Layer conv9/dw/scale
I0522 16:00:24.914518 13930 net.cpp:434] conv9/dw/scale <- conv9/dw
I0522 16:00:24.914521 13930 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0522 16:00:24.914553 13930 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0522 16:00:24.914685 13930 net.cpp:150] Setting up conv9/dw/scale
I0522 16:00:24.914690 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.914691 13930 net.cpp:165] Memory required for data: 292225056
I0522 16:00:24.914695 13930 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0522 16:00:24.914698 13930 net.cpp:100] Creating Layer conv9/dw/relu
I0522 16:00:24.914701 13930 net.cpp:434] conv9/dw/relu <- conv9/dw
I0522 16:00:24.914705 13930 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0522 16:00:24.915218 13930 net.cpp:150] Setting up conv9/dw/relu
I0522 16:00:24.915226 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.915230 13930 net.cpp:165] Memory required for data: 293830688
I0522 16:00:24.915241 13930 layer_factory.hpp:77] Creating layer conv9
I0522 16:00:24.915247 13930 net.cpp:100] Creating Layer conv9
I0522 16:00:24.915249 13930 net.cpp:434] conv9 <- conv9/dw
I0522 16:00:24.915256 13930 net.cpp:408] conv9 -> conv9
I0522 16:00:24.918503 13930 net.cpp:150] Setting up conv9
I0522 16:00:24.918512 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.918515 13930 net.cpp:165] Memory required for data: 295436320
I0522 16:00:24.918519 13930 layer_factory.hpp:77] Creating layer conv9/bn
I0522 16:00:24.918522 13930 net.cpp:100] Creating Layer conv9/bn
I0522 16:00:24.918525 13930 net.cpp:434] conv9/bn <- conv9
I0522 16:00:24.918529 13930 net.cpp:395] conv9/bn -> conv9 (in-place)
I0522 16:00:24.918694 13930 net.cpp:150] Setting up conv9/bn
I0522 16:00:24.918699 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.918700 13930 net.cpp:165] Memory required for data: 297041952
I0522 16:00:24.918705 13930 layer_factory.hpp:77] Creating layer conv9/scale
I0522 16:00:24.918709 13930 net.cpp:100] Creating Layer conv9/scale
I0522 16:00:24.918711 13930 net.cpp:434] conv9/scale <- conv9
I0522 16:00:24.918715 13930 net.cpp:395] conv9/scale -> conv9 (in-place)
I0522 16:00:24.918747 13930 layer_factory.hpp:77] Creating layer conv9/scale
I0522 16:00:24.918840 13930 net.cpp:150] Setting up conv9/scale
I0522 16:00:24.918845 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.918848 13930 net.cpp:165] Memory required for data: 298647584
I0522 16:00:24.918850 13930 layer_factory.hpp:77] Creating layer conv9/relu
I0522 16:00:24.918854 13930 net.cpp:100] Creating Layer conv9/relu
I0522 16:00:24.918856 13930 net.cpp:434] conv9/relu <- conv9
I0522 16:00:24.918860 13930 net.cpp:395] conv9/relu -> conv9 (in-place)
I0522 16:00:24.919203 13930 net.cpp:150] Setting up conv9/relu
I0522 16:00:24.919210 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.919212 13930 net.cpp:165] Memory required for data: 300253216
I0522 16:00:24.919214 13930 layer_factory.hpp:77] Creating layer conv10/dw
I0522 16:00:24.919220 13930 net.cpp:100] Creating Layer conv10/dw
I0522 16:00:24.919224 13930 net.cpp:434] conv10/dw <- conv9
I0522 16:00:24.919229 13930 net.cpp:408] conv10/dw -> conv10/dw
I0522 16:00:24.919412 13930 net.cpp:150] Setting up conv10/dw
I0522 16:00:24.919417 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.919420 13930 net.cpp:165] Memory required for data: 301858848
I0522 16:00:24.919423 13930 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0522 16:00:24.919427 13930 net.cpp:100] Creating Layer conv10/dw/bn
I0522 16:00:24.919430 13930 net.cpp:434] conv10/dw/bn <- conv10/dw
I0522 16:00:24.919432 13930 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0522 16:00:24.919584 13930 net.cpp:150] Setting up conv10/dw/bn
I0522 16:00:24.919589 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.919591 13930 net.cpp:165] Memory required for data: 303464480
I0522 16:00:24.919595 13930 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0522 16:00:24.919600 13930 net.cpp:100] Creating Layer conv10/dw/scale
I0522 16:00:24.919602 13930 net.cpp:434] conv10/dw/scale <- conv10/dw
I0522 16:00:24.919605 13930 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0522 16:00:24.919636 13930 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0522 16:00:24.919731 13930 net.cpp:150] Setting up conv10/dw/scale
I0522 16:00:24.919736 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.919739 13930 net.cpp:165] Memory required for data: 305070112
I0522 16:00:24.919742 13930 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0522 16:00:24.919745 13930 net.cpp:100] Creating Layer conv10/dw/relu
I0522 16:00:24.919747 13930 net.cpp:434] conv10/dw/relu <- conv10/dw
I0522 16:00:24.919751 13930 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0522 16:00:24.920089 13930 net.cpp:150] Setting up conv10/dw/relu
I0522 16:00:24.920096 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.920099 13930 net.cpp:165] Memory required for data: 306675744
I0522 16:00:24.920107 13930 layer_factory.hpp:77] Creating layer conv10
I0522 16:00:24.920114 13930 net.cpp:100] Creating Layer conv10
I0522 16:00:24.920115 13930 net.cpp:434] conv10 <- conv10/dw
I0522 16:00:24.920121 13930 net.cpp:408] conv10 -> conv10
I0522 16:00:24.924773 13930 net.cpp:150] Setting up conv10
I0522 16:00:24.924803 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.924806 13930 net.cpp:165] Memory required for data: 308281376
I0522 16:00:24.924810 13930 layer_factory.hpp:77] Creating layer conv10/bn
I0522 16:00:24.924815 13930 net.cpp:100] Creating Layer conv10/bn
I0522 16:00:24.924818 13930 net.cpp:434] conv10/bn <- conv10
I0522 16:00:24.924823 13930 net.cpp:395] conv10/bn -> conv10 (in-place)
I0522 16:00:24.925017 13930 net.cpp:150] Setting up conv10/bn
I0522 16:00:24.925022 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.925024 13930 net.cpp:165] Memory required for data: 309887008
I0522 16:00:24.925029 13930 layer_factory.hpp:77] Creating layer conv10/scale
I0522 16:00:24.925034 13930 net.cpp:100] Creating Layer conv10/scale
I0522 16:00:24.925036 13930 net.cpp:434] conv10/scale <- conv10
I0522 16:00:24.925040 13930 net.cpp:395] conv10/scale -> conv10 (in-place)
I0522 16:00:24.925072 13930 layer_factory.hpp:77] Creating layer conv10/scale
I0522 16:00:24.925168 13930 net.cpp:150] Setting up conv10/scale
I0522 16:00:24.925173 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.925174 13930 net.cpp:165] Memory required for data: 311492640
I0522 16:00:24.925177 13930 layer_factory.hpp:77] Creating layer conv10/relu
I0522 16:00:24.925180 13930 net.cpp:100] Creating Layer conv10/relu
I0522 16:00:24.925184 13930 net.cpp:434] conv10/relu <- conv10
I0522 16:00:24.925187 13930 net.cpp:395] conv10/relu -> conv10 (in-place)
I0522 16:00:24.925698 13930 net.cpp:150] Setting up conv10/relu
I0522 16:00:24.925707 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.925710 13930 net.cpp:165] Memory required for data: 313098272
I0522 16:00:24.925712 13930 layer_factory.hpp:77] Creating layer conv11/dw
I0522 16:00:24.925719 13930 net.cpp:100] Creating Layer conv11/dw
I0522 16:00:24.925721 13930 net.cpp:434] conv11/dw <- conv10
I0522 16:00:24.925726 13930 net.cpp:408] conv11/dw -> conv11/dw
I0522 16:00:24.925916 13930 net.cpp:150] Setting up conv11/dw
I0522 16:00:24.925921 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.925923 13930 net.cpp:165] Memory required for data: 314703904
I0522 16:00:24.925927 13930 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0522 16:00:24.925931 13930 net.cpp:100] Creating Layer conv11/dw/bn
I0522 16:00:24.925933 13930 net.cpp:434] conv11/dw/bn <- conv11/dw
I0522 16:00:24.925936 13930 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0522 16:00:24.926093 13930 net.cpp:150] Setting up conv11/dw/bn
I0522 16:00:24.926097 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.926100 13930 net.cpp:165] Memory required for data: 316309536
I0522 16:00:24.926113 13930 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0522 16:00:24.926118 13930 net.cpp:100] Creating Layer conv11/dw/scale
I0522 16:00:24.926121 13930 net.cpp:434] conv11/dw/scale <- conv11/dw
I0522 16:00:24.926124 13930 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0522 16:00:24.926157 13930 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0522 16:00:24.926250 13930 net.cpp:150] Setting up conv11/dw/scale
I0522 16:00:24.926256 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.926259 13930 net.cpp:165] Memory required for data: 317915168
I0522 16:00:24.926261 13930 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0522 16:00:24.926265 13930 net.cpp:100] Creating Layer conv11/dw/relu
I0522 16:00:24.926267 13930 net.cpp:434] conv11/dw/relu <- conv11/dw
I0522 16:00:24.926270 13930 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0522 16:00:24.926611 13930 net.cpp:150] Setting up conv11/dw/relu
I0522 16:00:24.926618 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.926627 13930 net.cpp:165] Memory required for data: 319520800
I0522 16:00:24.926630 13930 layer_factory.hpp:77] Creating layer conv11
I0522 16:00:24.926635 13930 net.cpp:100] Creating Layer conv11
I0522 16:00:24.926638 13930 net.cpp:434] conv11 <- conv11/dw
I0522 16:00:24.926643 13930 net.cpp:408] conv11 -> conv11
I0522 16:00:24.930138 13930 net.cpp:150] Setting up conv11
I0522 16:00:24.930147 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.930150 13930 net.cpp:165] Memory required for data: 321126432
I0522 16:00:24.930153 13930 layer_factory.hpp:77] Creating layer conv11/bn
I0522 16:00:24.930158 13930 net.cpp:100] Creating Layer conv11/bn
I0522 16:00:24.930160 13930 net.cpp:434] conv11/bn <- conv11
I0522 16:00:24.930164 13930 net.cpp:395] conv11/bn -> conv11 (in-place)
I0522 16:00:24.930335 13930 net.cpp:150] Setting up conv11/bn
I0522 16:00:24.930341 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.930342 13930 net.cpp:165] Memory required for data: 322732064
I0522 16:00:24.930347 13930 layer_factory.hpp:77] Creating layer conv11/scale
I0522 16:00:24.930351 13930 net.cpp:100] Creating Layer conv11/scale
I0522 16:00:24.930353 13930 net.cpp:434] conv11/scale <- conv11
I0522 16:00:24.930356 13930 net.cpp:395] conv11/scale -> conv11 (in-place)
I0522 16:00:24.930392 13930 layer_factory.hpp:77] Creating layer conv11/scale
I0522 16:00:24.930486 13930 net.cpp:150] Setting up conv11/scale
I0522 16:00:24.930491 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.930493 13930 net.cpp:165] Memory required for data: 324337696
I0522 16:00:24.930497 13930 layer_factory.hpp:77] Creating layer conv11/relu
I0522 16:00:24.930501 13930 net.cpp:100] Creating Layer conv11/relu
I0522 16:00:24.930503 13930 net.cpp:434] conv11/relu <- conv11
I0522 16:00:24.930506 13930 net.cpp:395] conv11/relu -> conv11 (in-place)
I0522 16:00:24.930846 13930 net.cpp:150] Setting up conv11/relu
I0522 16:00:24.930855 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.930856 13930 net.cpp:165] Memory required for data: 325943328
I0522 16:00:24.930858 13930 layer_factory.hpp:77] Creating layer conv12/dw
I0522 16:00:24.930866 13930 net.cpp:100] Creating Layer conv12/dw
I0522 16:00:24.930867 13930 net.cpp:434] conv12/dw <- conv11
I0522 16:00:24.930872 13930 net.cpp:408] conv12/dw -> conv12/dw
I0522 16:00:24.931058 13930 net.cpp:150] Setting up conv12/dw
I0522 16:00:24.931063 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.931066 13930 net.cpp:165] Memory required for data: 327548960
I0522 16:00:24.931069 13930 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0522 16:00:24.931072 13930 net.cpp:100] Creating Layer conv12/dw/bn
I0522 16:00:24.931074 13930 net.cpp:434] conv12/dw/bn <- conv12/dw
I0522 16:00:24.931078 13930 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0522 16:00:24.931234 13930 net.cpp:150] Setting up conv12/dw/bn
I0522 16:00:24.931239 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.931241 13930 net.cpp:165] Memory required for data: 329154592
I0522 16:00:24.931246 13930 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0522 16:00:24.931249 13930 net.cpp:100] Creating Layer conv12/dw/scale
I0522 16:00:24.931252 13930 net.cpp:434] conv12/dw/scale <- conv12/dw
I0522 16:00:24.931254 13930 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0522 16:00:24.931288 13930 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0522 16:00:24.931380 13930 net.cpp:150] Setting up conv12/dw/scale
I0522 16:00:24.931386 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.931388 13930 net.cpp:165] Memory required for data: 330760224
I0522 16:00:24.931392 13930 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0522 16:00:24.931396 13930 net.cpp:100] Creating Layer conv12/dw/relu
I0522 16:00:24.931397 13930 net.cpp:434] conv12/dw/relu <- conv12/dw
I0522 16:00:24.931401 13930 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0522 16:00:24.931735 13930 net.cpp:150] Setting up conv12/dw/relu
I0522 16:00:24.931741 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.931749 13930 net.cpp:165] Memory required for data: 332365856
I0522 16:00:24.931752 13930 layer_factory.hpp:77] Creating layer conv12/dw_conv12/dw/relu_0_split
I0522 16:00:24.931757 13930 net.cpp:100] Creating Layer conv12/dw_conv12/dw/relu_0_split
I0522 16:00:24.931759 13930 net.cpp:434] conv12/dw_conv12/dw/relu_0_split <- conv12/dw
I0522 16:00:24.931764 13930 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_0
I0522 16:00:24.931768 13930 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_1
I0522 16:00:24.931777 13930 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_2
I0522 16:00:24.931823 13930 net.cpp:150] Setting up conv12/dw_conv12/dw/relu_0_split
I0522 16:00:24.931828 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.931833 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.931835 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:24.931836 13930 net.cpp:165] Memory required for data: 337182752
I0522 16:00:24.931839 13930 layer_factory.hpp:77] Creating layer sample_pooling
I0522 16:00:24.931844 13930 net.cpp:100] Creating Layer sample_pooling
I0522 16:00:24.931847 13930 net.cpp:434] sample_pooling <- conv12/dw_conv12/dw/relu_0_split_0
I0522 16:00:24.931851 13930 net.cpp:408] sample_pooling -> sample_pooling
I0522 16:00:25.864713 13930 net.cpp:150] Setting up sample_pooling
I0522 16:00:25.864730 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:25.864733 13930 net.cpp:165] Memory required for data: 337584160
I0522 16:00:25.864740 13930 layer_factory.hpp:77] Creating layer conv12
I0522 16:00:25.864751 13930 net.cpp:100] Creating Layer conv12
I0522 16:00:25.864754 13930 net.cpp:434] conv12 <- sample_pooling
I0522 16:00:25.864761 13930 net.cpp:408] conv12 -> conv12
I0522 16:00:25.872871 13930 net.cpp:150] Setting up conv12
I0522 16:00:25.872884 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.872886 13930 net.cpp:165] Memory required for data: 338386976
I0522 16:00:25.872891 13930 layer_factory.hpp:77] Creating layer conv12/bn
I0522 16:00:25.872897 13930 net.cpp:100] Creating Layer conv12/bn
I0522 16:00:25.872901 13930 net.cpp:434] conv12/bn <- conv12
I0522 16:00:25.872905 13930 net.cpp:395] conv12/bn -> conv12 (in-place)
I0522 16:00:25.873656 13930 net.cpp:150] Setting up conv12/bn
I0522 16:00:25.873661 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.873663 13930 net.cpp:165] Memory required for data: 339189792
I0522 16:00:25.873668 13930 layer_factory.hpp:77] Creating layer conv12/scale
I0522 16:00:25.873674 13930 net.cpp:100] Creating Layer conv12/scale
I0522 16:00:25.873677 13930 net.cpp:434] conv12/scale <- conv12
I0522 16:00:25.873680 13930 net.cpp:395] conv12/scale -> conv12 (in-place)
I0522 16:00:25.873790 13930 layer_factory.hpp:77] Creating layer conv12/scale
I0522 16:00:25.874188 13930 net.cpp:150] Setting up conv12/scale
I0522 16:00:25.874194 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.874197 13930 net.cpp:165] Memory required for data: 339992608
I0522 16:00:25.874200 13930 layer_factory.hpp:77] Creating layer conv12/relu
I0522 16:00:25.874205 13930 net.cpp:100] Creating Layer conv12/relu
I0522 16:00:25.874207 13930 net.cpp:434] conv12/relu <- conv12
I0522 16:00:25.874212 13930 net.cpp:395] conv12/relu -> conv12 (in-place)
I0522 16:00:25.874599 13930 net.cpp:150] Setting up conv12/relu
I0522 16:00:25.874608 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.874610 13930 net.cpp:165] Memory required for data: 340795424
I0522 16:00:25.874614 13930 layer_factory.hpp:77] Creating layer conv13/dw
I0522 16:00:25.874619 13930 net.cpp:100] Creating Layer conv13/dw
I0522 16:00:25.874622 13930 net.cpp:434] conv13/dw <- conv12
I0522 16:00:25.874626 13930 net.cpp:408] conv13/dw -> conv13/dw
I0522 16:00:25.875367 13930 net.cpp:150] Setting up conv13/dw
I0522 16:00:25.875373 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.875385 13930 net.cpp:165] Memory required for data: 341598240
I0522 16:00:25.875388 13930 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0522 16:00:25.875392 13930 net.cpp:100] Creating Layer conv13/dw/bn
I0522 16:00:25.875394 13930 net.cpp:434] conv13/dw/bn <- conv13/dw
I0522 16:00:25.875398 13930 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0522 16:00:25.876121 13930 net.cpp:150] Setting up conv13/dw/bn
I0522 16:00:25.876128 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.876130 13930 net.cpp:165] Memory required for data: 342401056
I0522 16:00:25.876134 13930 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0522 16:00:25.876138 13930 net.cpp:100] Creating Layer conv13/dw/scale
I0522 16:00:25.876142 13930 net.cpp:434] conv13/dw/scale <- conv13/dw
I0522 16:00:25.876149 13930 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0522 16:00:25.876258 13930 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0522 16:00:25.876698 13930 net.cpp:150] Setting up conv13/dw/scale
I0522 16:00:25.876703 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.876705 13930 net.cpp:165] Memory required for data: 343203872
I0522 16:00:25.876709 13930 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0522 16:00:25.876713 13930 net.cpp:100] Creating Layer conv13/dw/relu
I0522 16:00:25.876715 13930 net.cpp:434] conv13/dw/relu <- conv13/dw
I0522 16:00:25.876719 13930 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0522 16:00:25.877110 13930 net.cpp:150] Setting up conv13/dw/relu
I0522 16:00:25.877117 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.877120 13930 net.cpp:165] Memory required for data: 344006688
I0522 16:00:25.877122 13930 layer_factory.hpp:77] Creating layer conv13
I0522 16:00:25.877128 13930 net.cpp:100] Creating Layer conv13
I0522 16:00:25.877131 13930 net.cpp:434] conv13 <- conv13/dw
I0522 16:00:25.877136 13930 net.cpp:408] conv13 -> conv13
I0522 16:00:25.886658 13930 net.cpp:150] Setting up conv13
I0522 16:00:25.886669 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.886672 13930 net.cpp:165] Memory required for data: 344809504
I0522 16:00:25.886677 13930 layer_factory.hpp:77] Creating layer conv13/bn
I0522 16:00:25.886682 13930 net.cpp:100] Creating Layer conv13/bn
I0522 16:00:25.886684 13930 net.cpp:434] conv13/bn <- conv13
I0522 16:00:25.886689 13930 net.cpp:395] conv13/bn -> conv13 (in-place)
I0522 16:00:25.887423 13930 net.cpp:150] Setting up conv13/bn
I0522 16:00:25.887430 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.887432 13930 net.cpp:165] Memory required for data: 345612320
I0522 16:00:25.887436 13930 layer_factory.hpp:77] Creating layer conv13/scale
I0522 16:00:25.887441 13930 net.cpp:100] Creating Layer conv13/scale
I0522 16:00:25.887444 13930 net.cpp:434] conv13/scale <- conv13
I0522 16:00:25.887449 13930 net.cpp:395] conv13/scale -> conv13 (in-place)
I0522 16:00:25.887555 13930 layer_factory.hpp:77] Creating layer conv13/scale
I0522 16:00:25.887959 13930 net.cpp:150] Setting up conv13/scale
I0522 16:00:25.887965 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.887967 13930 net.cpp:165] Memory required for data: 346415136
I0522 16:00:25.887970 13930 layer_factory.hpp:77] Creating layer conv13/relu
I0522 16:00:25.887974 13930 net.cpp:100] Creating Layer conv13/relu
I0522 16:00:25.887976 13930 net.cpp:434] conv13/relu <- conv13
I0522 16:00:25.887980 13930 net.cpp:395] conv13/relu -> conv13 (in-place)
I0522 16:00:25.888375 13930 net.cpp:150] Setting up conv13/relu
I0522 16:00:25.888383 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:25.888386 13930 net.cpp:165] Memory required for data: 347217952
I0522 16:00:25.888388 13930 layer_factory.hpp:77] Creating layer ip6
I0522 16:00:25.888396 13930 net.cpp:100] Creating Layer ip6
I0522 16:00:25.888397 13930 net.cpp:434] ip6 <- conv13
I0522 16:00:25.888402 13930 net.cpp:408] ip6 -> ip6
I0522 16:00:25.899351 13930 net.cpp:150] Setting up ip6
I0522 16:00:25.899367 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:25.899385 13930 net.cpp:165] Memory required for data: 347418656
I0522 16:00:25.899391 13930 layer_factory.hpp:77] Creating layer relu6
I0522 16:00:25.899397 13930 net.cpp:100] Creating Layer relu6
I0522 16:00:25.899401 13930 net.cpp:434] relu6 <- ip6
I0522 16:00:25.899410 13930 net.cpp:395] relu6 -> ip6 (in-place)
I0522 16:00:25.899891 13930 net.cpp:150] Setting up relu6
I0522 16:00:25.899899 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:25.899927 13930 net.cpp:165] Memory required for data: 347619360
I0522 16:00:25.899930 13930 layer_factory.hpp:77] Creating layer ip7
I0522 16:00:25.899955 13930 net.cpp:100] Creating Layer ip7
I0522 16:00:25.899960 13930 net.cpp:434] ip7 <- ip6
I0522 16:00:25.899966 13930 net.cpp:408] ip7 -> ip7
I0522 16:00:25.901307 13930 net.cpp:150] Setting up ip7
I0522 16:00:25.901314 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:25.901315 13930 net.cpp:165] Memory required for data: 348020768
I0522 16:00:25.901319 13930 layer_factory.hpp:77] Creating layer relu7
I0522 16:00:25.901324 13930 net.cpp:100] Creating Layer relu7
I0522 16:00:25.901325 13930 net.cpp:434] relu7 <- ip7
I0522 16:00:25.901329 13930 net.cpp:395] relu7 -> ip7 (in-place)
I0522 16:00:25.904119 13930 net.cpp:150] Setting up relu7
I0522 16:00:25.904129 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:25.904130 13930 net.cpp:165] Memory required for data: 348422176
I0522 16:00:25.904132 13930 layer_factory.hpp:77] Creating layer ip7_relu7_0_split
I0522 16:00:25.904165 13930 net.cpp:100] Creating Layer ip7_relu7_0_split
I0522 16:00:25.904170 13930 net.cpp:434] ip7_relu7_0_split <- ip7
I0522 16:00:25.904175 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_0
I0522 16:00:25.904184 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_1
I0522 16:00:25.904213 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_2
I0522 16:00:25.904219 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_3
I0522 16:00:25.904505 13930 net.cpp:150] Setting up ip7_relu7_0_split
I0522 16:00:25.904510 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:25.904515 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:25.904517 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:25.904520 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:25.904521 13930 net.cpp:165] Memory required for data: 350027808
I0522 16:00:25.904523 13930 layer_factory.hpp:77] Creating layer conv6_1
I0522 16:00:25.904531 13930 net.cpp:100] Creating Layer conv6_1
I0522 16:00:25.904533 13930 net.cpp:434] conv6_1 <- ip7_relu7_0_split_0
I0522 16:00:25.904538 13930 net.cpp:408] conv6_1 -> conv6_1
I0522 16:00:25.908092 13930 net.cpp:150] Setting up conv6_1
I0522 16:00:25.908102 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:25.908104 13930 net.cpp:165] Memory required for data: 350228512
I0522 16:00:25.908109 13930 layer_factory.hpp:77] Creating layer conv6_1_relu
I0522 16:00:25.908113 13930 net.cpp:100] Creating Layer conv6_1_relu
I0522 16:00:25.908115 13930 net.cpp:434] conv6_1_relu <- conv6_1
I0522 16:00:25.908120 13930 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0522 16:00:25.908514 13930 net.cpp:150] Setting up conv6_1_relu
I0522 16:00:25.908520 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:25.908524 13930 net.cpp:165] Memory required for data: 350429216
I0522 16:00:25.908526 13930 layer_factory.hpp:77] Creating layer conv6_2
I0522 16:00:25.908532 13930 net.cpp:100] Creating Layer conv6_2
I0522 16:00:25.908535 13930 net.cpp:434] conv6_2 <- conv6_1
I0522 16:00:25.908540 13930 net.cpp:408] conv6_2 -> conv6_2
I0522 16:00:25.913938 13930 net.cpp:150] Setting up conv6_2
I0522 16:00:25.913946 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:25.913949 13930 net.cpp:165] Memory required for data: 350479392
I0522 16:00:25.913954 13930 layer_factory.hpp:77] Creating layer conv6_2_relu
I0522 16:00:25.913959 13930 net.cpp:100] Creating Layer conv6_2_relu
I0522 16:00:25.913961 13930 net.cpp:434] conv6_2_relu <- conv6_2
I0522 16:00:25.913964 13930 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0522 16:00:25.914377 13930 net.cpp:150] Setting up conv6_2_relu
I0522 16:00:25.914386 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:25.914387 13930 net.cpp:165] Memory required for data: 350529568
I0522 16:00:25.914391 13930 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0522 16:00:25.914395 13930 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0522 16:00:25.914398 13930 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0522 16:00:25.914402 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0522 16:00:25.914407 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0522 16:00:25.914412 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0522 16:00:25.914417 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0522 16:00:25.914628 13930 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0522 16:00:25.914634 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:25.914638 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:25.914640 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:25.914642 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:25.914644 13930 net.cpp:165] Memory required for data: 350730272
I0522 16:00:25.914646 13930 layer_factory.hpp:77] Creating layer conv7_1
I0522 16:00:25.914654 13930 net.cpp:100] Creating Layer conv7_1
I0522 16:00:25.914655 13930 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0522 16:00:25.914660 13930 net.cpp:408] conv7_1 -> conv7_1
I0522 16:00:25.919396 13930 net.cpp:150] Setting up conv7_1
I0522 16:00:25.919405 13930 net.cpp:157] Top shape: 1 128 7 7 (6272)
I0522 16:00:25.919407 13930 net.cpp:165] Memory required for data: 350755360
I0522 16:00:25.919412 13930 layer_factory.hpp:77] Creating layer conv7_1_relu
I0522 16:00:25.919418 13930 net.cpp:100] Creating Layer conv7_1_relu
I0522 16:00:25.919420 13930 net.cpp:434] conv7_1_relu <- conv7_1
I0522 16:00:25.919425 13930 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0522 16:00:25.920080 13930 net.cpp:150] Setting up conv7_1_relu
I0522 16:00:25.920089 13930 net.cpp:157] Top shape: 1 128 7 7 (6272)
I0522 16:00:25.920091 13930 net.cpp:165] Memory required for data: 350780448
I0522 16:00:25.920094 13930 layer_factory.hpp:77] Creating layer conv7_2
I0522 16:00:25.920101 13930 net.cpp:100] Creating Layer conv7_2
I0522 16:00:25.920104 13930 net.cpp:434] conv7_2 <- conv7_1
I0522 16:00:25.920109 13930 net.cpp:408] conv7_2 -> conv7_2
I0522 16:00:25.923633 13930 net.cpp:150] Setting up conv7_2
I0522 16:00:25.923642 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:25.923645 13930 net.cpp:165] Memory required for data: 350796832
I0522 16:00:25.923650 13930 layer_factory.hpp:77] Creating layer conv7_2_relu
I0522 16:00:25.923653 13930 net.cpp:100] Creating Layer conv7_2_relu
I0522 16:00:25.923655 13930 net.cpp:434] conv7_2_relu <- conv7_2
I0522 16:00:25.923660 13930 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0522 16:00:25.924067 13930 net.cpp:150] Setting up conv7_2_relu
I0522 16:00:25.924074 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:25.924077 13930 net.cpp:165] Memory required for data: 350813216
I0522 16:00:25.924079 13930 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0522 16:00:25.924083 13930 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0522 16:00:25.924085 13930 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0522 16:00:25.924090 13930 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0522 16:00:25.924096 13930 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0522 16:00:25.924101 13930 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0522 16:00:25.924264 13930 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0522 16:00:25.924270 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:25.924273 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:25.924283 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:25.924285 13930 net.cpp:165] Memory required for data: 350862368
I0522 16:00:25.924288 13930 layer_factory.hpp:77] Creating layer conv12_norm
I0522 16:00:25.924293 13930 net.cpp:100] Creating Layer conv12_norm
I0522 16:00:25.924296 13930 net.cpp:434] conv12_norm <- conv12/dw_conv12/dw/relu_0_split_1
I0522 16:00:25.924300 13930 net.cpp:408] conv12_norm -> conv12_norm
I0522 16:00:25.924862 13930 net.cpp:150] Setting up conv12_norm
I0522 16:00:25.924870 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:25.924871 13930 net.cpp:165] Memory required for data: 352468000
I0522 16:00:25.924875 13930 layer_factory.hpp:77] Creating layer conv12_norm_conv12_norm_0_split
I0522 16:00:25.924886 13930 net.cpp:100] Creating Layer conv12_norm_conv12_norm_0_split
I0522 16:00:25.924890 13930 net.cpp:434] conv12_norm_conv12_norm_0_split <- conv12_norm
I0522 16:00:25.924892 13930 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_0
I0522 16:00:25.924897 13930 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_1
I0522 16:00:25.925005 13930 net.cpp:150] Setting up conv12_norm_conv12_norm_0_split
I0522 16:00:25.925011 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:25.925014 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:25.925015 13930 net.cpp:165] Memory required for data: 355679264
I0522 16:00:25.925019 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc
I0522 16:00:25.925026 13930 net.cpp:100] Creating Layer conv12_norm_mbox_loc
I0522 16:00:25.925029 13930 net.cpp:434] conv12_norm_mbox_loc <- conv12_norm_conv12_norm_0_split_0
I0522 16:00:25.925032 13930 net.cpp:408] conv12_norm_mbox_loc -> conv12_norm_mbox_loc
I0522 16:00:25.928638 13930 net.cpp:150] Setting up conv12_norm_mbox_loc
I0522 16:00:25.928649 13930 net.cpp:157] Top shape: 1 24 28 28 (18816)
I0522 16:00:25.928651 13930 net.cpp:165] Memory required for data: 355754528
I0522 16:00:25.928656 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_perm
I0522 16:00:25.928663 13930 net.cpp:100] Creating Layer conv12_norm_mbox_loc_perm
I0522 16:00:25.928665 13930 net.cpp:434] conv12_norm_mbox_loc_perm <- conv12_norm_mbox_loc
I0522 16:00:25.928669 13930 net.cpp:408] conv12_norm_mbox_loc_perm -> conv12_norm_mbox_loc_perm
I0522 16:00:25.929033 13930 net.cpp:150] Setting up conv12_norm_mbox_loc_perm
I0522 16:00:25.929039 13930 net.cpp:157] Top shape: 1 28 28 24 (18816)
I0522 16:00:25.929040 13930 net.cpp:165] Memory required for data: 355829792
I0522 16:00:25.929042 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_flat
I0522 16:00:25.929047 13930 net.cpp:100] Creating Layer conv12_norm_mbox_loc_flat
I0522 16:00:25.929050 13930 net.cpp:434] conv12_norm_mbox_loc_flat <- conv12_norm_mbox_loc_perm
I0522 16:00:25.929054 13930 net.cpp:408] conv12_norm_mbox_loc_flat -> conv12_norm_mbox_loc_flat
I0522 16:00:25.929112 13930 net.cpp:150] Setting up conv12_norm_mbox_loc_flat
I0522 16:00:25.929117 13930 net.cpp:157] Top shape: 1 18816 (18816)
I0522 16:00:25.929119 13930 net.cpp:165] Memory required for data: 355905056
I0522 16:00:25.929122 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf
I0522 16:00:25.929128 13930 net.cpp:100] Creating Layer conv12_norm_mbox_conf
I0522 16:00:25.929131 13930 net.cpp:434] conv12_norm_mbox_conf <- conv12_norm_conv12_norm_0_split_1
I0522 16:00:25.929136 13930 net.cpp:408] conv12_norm_mbox_conf -> conv12_norm_mbox_conf
I0522 16:00:25.934844 13930 net.cpp:150] Setting up conv12_norm_mbox_conf
I0522 16:00:25.934855 13930 net.cpp:157] Top shape: 1 36 28 28 (28224)
I0522 16:00:25.934857 13930 net.cpp:165] Memory required for data: 356017952
I0522 16:00:25.934862 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_perm
I0522 16:00:25.934870 13930 net.cpp:100] Creating Layer conv12_norm_mbox_conf_perm
I0522 16:00:25.934872 13930 net.cpp:434] conv12_norm_mbox_conf_perm <- conv12_norm_mbox_conf
I0522 16:00:25.934876 13930 net.cpp:408] conv12_norm_mbox_conf_perm -> conv12_norm_mbox_conf_perm
I0522 16:00:25.935245 13930 net.cpp:150] Setting up conv12_norm_mbox_conf_perm
I0522 16:00:25.935251 13930 net.cpp:157] Top shape: 1 28 28 36 (28224)
I0522 16:00:25.935253 13930 net.cpp:165] Memory required for data: 356130848
I0522 16:00:25.935256 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_flat
I0522 16:00:25.935259 13930 net.cpp:100] Creating Layer conv12_norm_mbox_conf_flat
I0522 16:00:25.935262 13930 net.cpp:434] conv12_norm_mbox_conf_flat <- conv12_norm_mbox_conf_perm
I0522 16:00:25.935266 13930 net.cpp:408] conv12_norm_mbox_conf_flat -> conv12_norm_mbox_conf_flat
I0522 16:00:25.935323 13930 net.cpp:150] Setting up conv12_norm_mbox_conf_flat
I0522 16:00:25.935328 13930 net.cpp:157] Top shape: 1 28224 (28224)
I0522 16:00:25.935330 13930 net.cpp:165] Memory required for data: 356243744
I0522 16:00:25.935333 13930 layer_factory.hpp:77] Creating layer ip7_mbox_loc
I0522 16:00:25.935339 13930 net.cpp:100] Creating Layer ip7_mbox_loc
I0522 16:00:25.935343 13930 net.cpp:434] ip7_mbox_loc <- ip7_relu7_0_split_1
I0522 16:00:25.935348 13930 net.cpp:408] ip7_mbox_loc -> ip7_mbox_loc
I0522 16:00:25.938508 13930 net.cpp:150] Setting up ip7_mbox_loc
I0522 16:00:25.938517 13930 net.cpp:157] Top shape: 1 24 14 14 (4704)
I0522 16:00:25.938520 13930 net.cpp:165] Memory required for data: 356262560
I0522 16:00:25.938525 13930 layer_factory.hpp:77] Creating layer ip7_mbox_loc_perm
I0522 16:00:25.938529 13930 net.cpp:100] Creating Layer ip7_mbox_loc_perm
I0522 16:00:25.938532 13930 net.cpp:434] ip7_mbox_loc_perm <- ip7_mbox_loc
I0522 16:00:25.938536 13930 net.cpp:408] ip7_mbox_loc_perm -> ip7_mbox_loc_perm
I0522 16:00:25.938897 13930 net.cpp:150] Setting up ip7_mbox_loc_perm
I0522 16:00:25.938902 13930 net.cpp:157] Top shape: 1 14 14 24 (4704)
I0522 16:00:25.938905 13930 net.cpp:165] Memory required for data: 356281376
I0522 16:00:25.938907 13930 layer_factory.hpp:77] Creating layer ip7_mbox_loc_flat
I0522 16:00:25.938911 13930 net.cpp:100] Creating Layer ip7_mbox_loc_flat
I0522 16:00:25.938913 13930 net.cpp:434] ip7_mbox_loc_flat <- ip7_mbox_loc_perm
I0522 16:00:25.938917 13930 net.cpp:408] ip7_mbox_loc_flat -> ip7_mbox_loc_flat
I0522 16:00:25.938974 13930 net.cpp:150] Setting up ip7_mbox_loc_flat
I0522 16:00:25.938979 13930 net.cpp:157] Top shape: 1 4704 (4704)
I0522 16:00:25.938982 13930 net.cpp:165] Memory required for data: 356300192
I0522 16:00:25.938983 13930 layer_factory.hpp:77] Creating layer ip7_mbox_conf
I0522 16:00:25.938990 13930 net.cpp:100] Creating Layer ip7_mbox_conf
I0522 16:00:25.938993 13930 net.cpp:434] ip7_mbox_conf <- ip7_relu7_0_split_2
I0522 16:00:25.938998 13930 net.cpp:408] ip7_mbox_conf -> ip7_mbox_conf
I0522 16:00:25.942855 13930 net.cpp:150] Setting up ip7_mbox_conf
I0522 16:00:25.942864 13930 net.cpp:157] Top shape: 1 36 14 14 (7056)
I0522 16:00:25.942867 13930 net.cpp:165] Memory required for data: 356328416
I0522 16:00:25.942871 13930 layer_factory.hpp:77] Creating layer ip7_mbox_conf_perm
I0522 16:00:25.942875 13930 net.cpp:100] Creating Layer ip7_mbox_conf_perm
I0522 16:00:25.942878 13930 net.cpp:434] ip7_mbox_conf_perm <- ip7_mbox_conf
I0522 16:00:25.942883 13930 net.cpp:408] ip7_mbox_conf_perm -> ip7_mbox_conf_perm
I0522 16:00:25.943243 13930 net.cpp:150] Setting up ip7_mbox_conf_perm
I0522 16:00:25.943249 13930 net.cpp:157] Top shape: 1 14 14 36 (7056)
I0522 16:00:25.943251 13930 net.cpp:165] Memory required for data: 356356640
I0522 16:00:25.943254 13930 layer_factory.hpp:77] Creating layer ip7_mbox_conf_flat
I0522 16:00:25.943258 13930 net.cpp:100] Creating Layer ip7_mbox_conf_flat
I0522 16:00:25.943260 13930 net.cpp:434] ip7_mbox_conf_flat <- ip7_mbox_conf_perm
I0522 16:00:25.943264 13930 net.cpp:408] ip7_mbox_conf_flat -> ip7_mbox_conf_flat
I0522 16:00:25.943321 13930 net.cpp:150] Setting up ip7_mbox_conf_flat
I0522 16:00:25.943325 13930 net.cpp:157] Top shape: 1 7056 (7056)
I0522 16:00:25.943327 13930 net.cpp:165] Memory required for data: 356384864
I0522 16:00:25.943329 13930 layer_factory.hpp:77] Creating layer conv12/dw_mbox_priorbox
I0522 16:00:25.943342 13930 net.cpp:100] Creating Layer conv12/dw_mbox_priorbox
I0522 16:00:25.943344 13930 net.cpp:434] conv12/dw_mbox_priorbox <- conv12/dw_conv12/dw/relu_0_split_2
I0522 16:00:25.943348 13930 net.cpp:434] conv12/dw_mbox_priorbox <- data_data_0_split_1
I0522 16:00:25.943353 13930 net.cpp:408] conv12/dw_mbox_priorbox -> conv12/dw_mbox_priorbox
I0522 16:00:25.943416 13930 net.cpp:150] Setting up conv12/dw_mbox_priorbox
I0522 16:00:25.943421 13930 net.cpp:157] Top shape: 1 2 18816 (37632)
I0522 16:00:25.943423 13930 net.cpp:165] Memory required for data: 356535392
I0522 16:00:25.943425 13930 layer_factory.hpp:77] Creating layer ip7_mbox_priorbox
I0522 16:00:25.943429 13930 net.cpp:100] Creating Layer ip7_mbox_priorbox
I0522 16:00:25.943431 13930 net.cpp:434] ip7_mbox_priorbox <- ip7_relu7_0_split_3
I0522 16:00:25.943434 13930 net.cpp:434] ip7_mbox_priorbox <- data_data_0_split_2
I0522 16:00:25.943439 13930 net.cpp:408] ip7_mbox_priorbox -> ip7_mbox_priorbox
I0522 16:00:25.943497 13930 net.cpp:150] Setting up ip7_mbox_priorbox
I0522 16:00:25.943502 13930 net.cpp:157] Top shape: 1 2 4704 (9408)
I0522 16:00:25.943503 13930 net.cpp:165] Memory required for data: 356573024
I0522 16:00:25.943506 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0522 16:00:25.943511 13930 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0522 16:00:25.943514 13930 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0522 16:00:25.943521 13930 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0522 16:00:25.948525 13930 net.cpp:150] Setting up conv6_2_mbox_loc
I0522 16:00:25.948534 13930 net.cpp:157] Top shape: 1 24 7 7 (1176)
I0522 16:00:25.948537 13930 net.cpp:165] Memory required for data: 356577728
I0522 16:00:25.948541 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0522 16:00:25.948547 13930 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0522 16:00:25.948551 13930 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0522 16:00:25.948555 13930 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0522 16:00:25.948921 13930 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0522 16:00:25.948926 13930 net.cpp:157] Top shape: 1 7 7 24 (1176)
I0522 16:00:25.948930 13930 net.cpp:165] Memory required for data: 356582432
I0522 16:00:25.948931 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0522 16:00:25.948935 13930 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0522 16:00:25.948937 13930 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0522 16:00:25.948942 13930 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0522 16:00:25.949002 13930 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0522 16:00:25.949008 13930 net.cpp:157] Top shape: 1 1176 (1176)
I0522 16:00:25.949012 13930 net.cpp:165] Memory required for data: 356587136
I0522 16:00:25.949014 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0522 16:00:25.949025 13930 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0522 16:00:25.949028 13930 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0522 16:00:25.949034 13930 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0522 16:00:25.952078 13930 net.cpp:150] Setting up conv6_2_mbox_conf
I0522 16:00:25.952087 13930 net.cpp:157] Top shape: 1 36 7 7 (1764)
I0522 16:00:25.952090 13930 net.cpp:165] Memory required for data: 356594192
I0522 16:00:25.952095 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0522 16:00:25.952100 13930 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0522 16:00:25.952103 13930 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0522 16:00:25.952107 13930 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0522 16:00:25.952471 13930 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0522 16:00:25.952478 13930 net.cpp:157] Top shape: 1 7 7 36 (1764)
I0522 16:00:25.952481 13930 net.cpp:165] Memory required for data: 356601248
I0522 16:00:25.952482 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0522 16:00:25.952492 13930 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0522 16:00:25.952495 13930 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0522 16:00:25.952500 13930 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0522 16:00:25.952559 13930 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0522 16:00:25.952566 13930 net.cpp:157] Top shape: 1 1764 (1764)
I0522 16:00:25.952569 13930 net.cpp:165] Memory required for data: 356608304
I0522 16:00:25.952570 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0522 16:00:25.952574 13930 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0522 16:00:25.952577 13930 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0522 16:00:25.952580 13930 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0522 16:00:25.952585 13930 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0522 16:00:25.952646 13930 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0522 16:00:25.952653 13930 net.cpp:157] Top shape: 1 2 1176 (2352)
I0522 16:00:25.952656 13930 net.cpp:165] Memory required for data: 356617712
I0522 16:00:25.952657 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0522 16:00:25.952664 13930 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0522 16:00:25.952666 13930 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_0
I0522 16:00:25.952672 13930 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0522 16:00:25.955837 13930 net.cpp:150] Setting up conv7_2_mbox_loc
I0522 16:00:25.955847 13930 net.cpp:157] Top shape: 1 16 4 4 (256)
I0522 16:00:25.955848 13930 net.cpp:165] Memory required for data: 356618736
I0522 16:00:25.955853 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0522 16:00:25.955859 13930 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0522 16:00:25.955862 13930 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0522 16:00:25.955866 13930 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0522 16:00:25.956235 13930 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0522 16:00:25.956241 13930 net.cpp:157] Top shape: 1 4 4 16 (256)
I0522 16:00:25.956243 13930 net.cpp:165] Memory required for data: 356619760
I0522 16:00:25.956245 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0522 16:00:25.956250 13930 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0522 16:00:25.956252 13930 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0522 16:00:25.956257 13930 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0522 16:00:25.956313 13930 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0522 16:00:25.956319 13930 net.cpp:157] Top shape: 1 256 (256)
I0522 16:00:25.956321 13930 net.cpp:165] Memory required for data: 356620784
I0522 16:00:25.956323 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0522 16:00:25.956329 13930 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0522 16:00:25.956333 13930 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_1
I0522 16:00:25.956338 13930 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0522 16:00:25.961763 13930 net.cpp:150] Setting up conv7_2_mbox_conf
I0522 16:00:25.961774 13930 net.cpp:157] Top shape: 1 24 4 4 (384)
I0522 16:00:25.961777 13930 net.cpp:165] Memory required for data: 356622320
I0522 16:00:25.961782 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0522 16:00:25.961787 13930 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0522 16:00:25.961791 13930 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0522 16:00:25.961796 13930 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0522 16:00:25.962162 13930 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0522 16:00:25.962167 13930 net.cpp:157] Top shape: 1 4 4 24 (384)
I0522 16:00:25.962168 13930 net.cpp:165] Memory required for data: 356623856
I0522 16:00:25.962172 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0522 16:00:25.962175 13930 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0522 16:00:25.962177 13930 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0522 16:00:25.962214 13930 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0522 16:00:25.962302 13930 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0522 16:00:25.962307 13930 net.cpp:157] Top shape: 1 384 (384)
I0522 16:00:25.962309 13930 net.cpp:165] Memory required for data: 356625392
I0522 16:00:25.962311 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0522 16:00:25.962316 13930 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0522 16:00:25.962318 13930 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_2
I0522 16:00:25.962321 13930 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0522 16:00:25.962347 13930 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0522 16:00:25.962462 13930 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0522 16:00:25.962467 13930 net.cpp:157] Top shape: 1 2 256 (512)
I0522 16:00:25.962469 13930 net.cpp:165] Memory required for data: 356627440
I0522 16:00:25.962471 13930 layer_factory.hpp:77] Creating layer mbox_loc
I0522 16:00:25.962476 13930 net.cpp:100] Creating Layer mbox_loc
I0522 16:00:25.962478 13930 net.cpp:434] mbox_loc <- conv12_norm_mbox_loc_flat
I0522 16:00:25.962482 13930 net.cpp:434] mbox_loc <- ip7_mbox_loc_flat
I0522 16:00:25.962486 13930 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0522 16:00:25.962488 13930 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0522 16:00:25.962492 13930 net.cpp:408] mbox_loc -> mbox_loc
I0522 16:00:25.962553 13930 net.cpp:150] Setting up mbox_loc
I0522 16:00:25.962558 13930 net.cpp:157] Top shape: 1 24952 (24952)
I0522 16:00:25.962589 13930 net.cpp:165] Memory required for data: 356727248
I0522 16:00:25.962590 13930 layer_factory.hpp:77] Creating layer mbox_conf
I0522 16:00:25.962594 13930 net.cpp:100] Creating Layer mbox_conf
I0522 16:00:25.962596 13930 net.cpp:434] mbox_conf <- conv12_norm_mbox_conf_flat
I0522 16:00:25.962599 13930 net.cpp:434] mbox_conf <- ip7_mbox_conf_flat
I0522 16:00:25.962604 13930 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0522 16:00:25.962606 13930 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0522 16:00:25.962612 13930 net.cpp:408] mbox_conf -> mbox_conf
I0522 16:00:25.962728 13930 net.cpp:150] Setting up mbox_conf
I0522 16:00:25.962733 13930 net.cpp:157] Top shape: 1 37428 (37428)
I0522 16:00:25.962734 13930 net.cpp:165] Memory required for data: 356876960
I0522 16:00:25.962736 13930 layer_factory.hpp:77] Creating layer mbox_priorbox
I0522 16:00:25.962740 13930 net.cpp:100] Creating Layer mbox_priorbox
I0522 16:00:25.962743 13930 net.cpp:434] mbox_priorbox <- conv12/dw_mbox_priorbox
I0522 16:00:25.962745 13930 net.cpp:434] mbox_priorbox <- ip7_mbox_priorbox
I0522 16:00:25.962749 13930 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0522 16:00:25.962751 13930 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0522 16:00:25.962754 13930 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0522 16:00:25.962812 13930 net.cpp:150] Setting up mbox_priorbox
I0522 16:00:25.962816 13930 net.cpp:157] Top shape: 1 2 24952 (49904)
I0522 16:00:25.962819 13930 net.cpp:165] Memory required for data: 357076576
I0522 16:00:25.962821 13930 layer_factory.hpp:77] Creating layer mbox_loss
I0522 16:00:25.962828 13930 net.cpp:100] Creating Layer mbox_loss
I0522 16:00:25.962831 13930 net.cpp:434] mbox_loss <- mbox_loc
I0522 16:00:25.962834 13930 net.cpp:434] mbox_loss <- mbox_conf
I0522 16:00:25.962836 13930 net.cpp:434] mbox_loss <- mbox_priorbox
I0522 16:00:25.962839 13930 net.cpp:434] mbox_loss <- label
I0522 16:00:25.962844 13930 net.cpp:408] mbox_loss -> mbox_loss
I0522 16:00:25.963075 13930 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0522 16:00:25.963385 13930 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0522 16:00:25.963392 13930 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0522 16:00:25.964159 13930 net.cpp:150] Setting up mbox_loss
I0522 16:00:25.964166 13930 net.cpp:157] Top shape: (1)
I0522 16:00:25.964169 13930 net.cpp:160]     with loss weight 1
I0522 16:00:25.964185 13930 net.cpp:165] Memory required for data: 357076580
I0522 16:00:25.964187 13930 net.cpp:226] mbox_loss needs backward computation.
I0522 16:00:25.964193 13930 net.cpp:228] mbox_priorbox does not need backward computation.
I0522 16:00:25.964198 13930 net.cpp:226] mbox_conf needs backward computation.
I0522 16:00:25.964201 13930 net.cpp:226] mbox_loc needs backward computation.
I0522 16:00:25.964205 13930 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0522 16:00:25.964208 13930 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0522 16:00:25.964212 13930 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0522 16:00:25.964215 13930 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0522 16:00:25.964217 13930 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0522 16:00:25.964221 13930 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0522 16:00:25.964222 13930 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0522 16:00:25.964226 13930 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0522 16:00:25.964231 13930 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0522 16:00:25.964236 13930 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0522 16:00:25.964238 13930 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0522 16:00:25.964241 13930 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0522 16:00:25.964244 13930 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0522 16:00:25.964248 13930 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0522 16:00:25.964253 13930 net.cpp:228] ip7_mbox_priorbox does not need backward computation.
I0522 16:00:25.964257 13930 net.cpp:228] conv12/dw_mbox_priorbox does not need backward computation.
I0522 16:00:25.964262 13930 net.cpp:226] ip7_mbox_conf_flat needs backward computation.
I0522 16:00:25.964267 13930 net.cpp:226] ip7_mbox_conf_perm needs backward computation.
I0522 16:00:25.964272 13930 net.cpp:226] ip7_mbox_conf needs backward computation.
I0522 16:00:25.964274 13930 net.cpp:226] ip7_mbox_loc_flat needs backward computation.
I0522 16:00:25.964279 13930 net.cpp:226] ip7_mbox_loc_perm needs backward computation.
I0522 16:00:25.964282 13930 net.cpp:226] ip7_mbox_loc needs backward computation.
I0522 16:00:25.964285 13930 net.cpp:226] conv12_norm_mbox_conf_flat needs backward computation.
I0522 16:00:25.964288 13930 net.cpp:226] conv12_norm_mbox_conf_perm needs backward computation.
I0522 16:00:25.964293 13930 net.cpp:226] conv12_norm_mbox_conf needs backward computation.
I0522 16:00:25.964296 13930 net.cpp:226] conv12_norm_mbox_loc_flat needs backward computation.
I0522 16:00:25.964301 13930 net.cpp:226] conv12_norm_mbox_loc_perm needs backward computation.
I0522 16:00:25.964305 13930 net.cpp:226] conv12_norm_mbox_loc needs backward computation.
I0522 16:00:25.964311 13930 net.cpp:226] conv12_norm_conv12_norm_0_split needs backward computation.
I0522 16:00:25.964316 13930 net.cpp:226] conv12_norm needs backward computation.
I0522 16:00:25.964321 13930 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0522 16:00:25.964325 13930 net.cpp:226] conv7_2_relu needs backward computation.
I0522 16:00:25.964330 13930 net.cpp:226] conv7_2 needs backward computation.
I0522 16:00:25.964335 13930 net.cpp:226] conv7_1_relu needs backward computation.
I0522 16:00:25.964339 13930 net.cpp:226] conv7_1 needs backward computation.
I0522 16:00:25.964344 13930 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0522 16:00:25.964347 13930 net.cpp:226] conv6_2_relu needs backward computation.
I0522 16:00:25.964350 13930 net.cpp:226] conv6_2 needs backward computation.
I0522 16:00:25.964354 13930 net.cpp:226] conv6_1_relu needs backward computation.
I0522 16:00:25.964357 13930 net.cpp:226] conv6_1 needs backward computation.
I0522 16:00:25.964361 13930 net.cpp:226] ip7_relu7_0_split needs backward computation.
I0522 16:00:25.964366 13930 net.cpp:226] relu7 needs backward computation.
I0522 16:00:25.964375 13930 net.cpp:226] ip7 needs backward computation.
I0522 16:00:25.964377 13930 net.cpp:226] relu6 needs backward computation.
I0522 16:00:25.964380 13930 net.cpp:226] ip6 needs backward computation.
I0522 16:00:25.964385 13930 net.cpp:226] conv13/relu needs backward computation.
I0522 16:00:25.964390 13930 net.cpp:226] conv13/scale needs backward computation.
I0522 16:00:25.964393 13930 net.cpp:226] conv13/bn needs backward computation.
I0522 16:00:25.964397 13930 net.cpp:226] conv13 needs backward computation.
I0522 16:00:25.964401 13930 net.cpp:226] conv13/dw/relu needs backward computation.
I0522 16:00:25.964404 13930 net.cpp:226] conv13/dw/scale needs backward computation.
I0522 16:00:25.964407 13930 net.cpp:226] conv13/dw/bn needs backward computation.
I0522 16:00:25.964411 13930 net.cpp:226] conv13/dw needs backward computation.
I0522 16:00:25.964416 13930 net.cpp:226] conv12/relu needs backward computation.
I0522 16:00:25.964418 13930 net.cpp:226] conv12/scale needs backward computation.
I0522 16:00:25.964421 13930 net.cpp:226] conv12/bn needs backward computation.
I0522 16:00:25.964426 13930 net.cpp:226] conv12 needs backward computation.
I0522 16:00:25.964429 13930 net.cpp:226] sample_pooling needs backward computation.
I0522 16:00:25.964433 13930 net.cpp:226] conv12/dw_conv12/dw/relu_0_split needs backward computation.
I0522 16:00:25.964438 13930 net.cpp:226] conv12/dw/relu needs backward computation.
I0522 16:00:25.964442 13930 net.cpp:226] conv12/dw/scale needs backward computation.
I0522 16:00:25.964447 13930 net.cpp:226] conv12/dw/bn needs backward computation.
I0522 16:00:25.964450 13930 net.cpp:226] conv12/dw needs backward computation.
I0522 16:00:25.964454 13930 net.cpp:226] conv11/relu needs backward computation.
I0522 16:00:25.964457 13930 net.cpp:226] conv11/scale needs backward computation.
I0522 16:00:25.964462 13930 net.cpp:226] conv11/bn needs backward computation.
I0522 16:00:25.964464 13930 net.cpp:226] conv11 needs backward computation.
I0522 16:00:25.964468 13930 net.cpp:226] conv11/dw/relu needs backward computation.
I0522 16:00:25.964471 13930 net.cpp:226] conv11/dw/scale needs backward computation.
I0522 16:00:25.964475 13930 net.cpp:226] conv11/dw/bn needs backward computation.
I0522 16:00:25.964478 13930 net.cpp:226] conv11/dw needs backward computation.
I0522 16:00:25.964483 13930 net.cpp:226] conv10/relu needs backward computation.
I0522 16:00:25.964485 13930 net.cpp:226] conv10/scale needs backward computation.
I0522 16:00:25.964488 13930 net.cpp:226] conv10/bn needs backward computation.
I0522 16:00:25.964493 13930 net.cpp:226] conv10 needs backward computation.
I0522 16:00:25.964495 13930 net.cpp:226] conv10/dw/relu needs backward computation.
I0522 16:00:25.964499 13930 net.cpp:226] conv10/dw/scale needs backward computation.
I0522 16:00:25.964504 13930 net.cpp:226] conv10/dw/bn needs backward computation.
I0522 16:00:25.964507 13930 net.cpp:226] conv10/dw needs backward computation.
I0522 16:00:25.964511 13930 net.cpp:226] conv9/relu needs backward computation.
I0522 16:00:25.964514 13930 net.cpp:226] conv9/scale needs backward computation.
I0522 16:00:25.964517 13930 net.cpp:226] conv9/bn needs backward computation.
I0522 16:00:25.964520 13930 net.cpp:226] conv9 needs backward computation.
I0522 16:00:25.964524 13930 net.cpp:226] conv9/dw/relu needs backward computation.
I0522 16:00:25.964529 13930 net.cpp:226] conv9/dw/scale needs backward computation.
I0522 16:00:25.964530 13930 net.cpp:226] conv9/dw/bn needs backward computation.
I0522 16:00:25.964534 13930 net.cpp:226] conv9/dw needs backward computation.
I0522 16:00:25.964535 13930 net.cpp:226] conv8/relu needs backward computation.
I0522 16:00:25.964537 13930 net.cpp:226] conv8/scale needs backward computation.
I0522 16:00:25.964540 13930 net.cpp:226] conv8/bn needs backward computation.
I0522 16:00:25.964542 13930 net.cpp:226] conv8 needs backward computation.
I0522 16:00:25.964545 13930 net.cpp:226] conv8/dw/relu needs backward computation.
I0522 16:00:25.964550 13930 net.cpp:226] conv8/dw/scale needs backward computation.
I0522 16:00:25.964557 13930 net.cpp:226] conv8/dw/bn needs backward computation.
I0522 16:00:25.964561 13930 net.cpp:226] conv8/dw needs backward computation.
I0522 16:00:25.964565 13930 net.cpp:226] conv7/relu needs backward computation.
I0522 16:00:25.964567 13930 net.cpp:226] conv7/scale needs backward computation.
I0522 16:00:25.964570 13930 net.cpp:226] conv7/bn needs backward computation.
I0522 16:00:25.964572 13930 net.cpp:226] conv7 needs backward computation.
I0522 16:00:25.964576 13930 net.cpp:226] conv7/dw/relu needs backward computation.
I0522 16:00:25.964578 13930 net.cpp:226] conv7/dw/scale needs backward computation.
I0522 16:00:25.964582 13930 net.cpp:226] conv7/dw/bn needs backward computation.
I0522 16:00:25.964586 13930 net.cpp:226] conv7/dw needs backward computation.
I0522 16:00:25.964591 13930 net.cpp:226] conv6/relu needs backward computation.
I0522 16:00:25.964594 13930 net.cpp:226] conv6/scale needs backward computation.
I0522 16:00:25.964599 13930 net.cpp:226] conv6/bn needs backward computation.
I0522 16:00:25.964603 13930 net.cpp:226] conv6 needs backward computation.
I0522 16:00:25.964607 13930 net.cpp:226] conv6/dw/relu needs backward computation.
I0522 16:00:25.964612 13930 net.cpp:226] conv6/dw/scale needs backward computation.
I0522 16:00:25.964614 13930 net.cpp:226] conv6/dw/bn needs backward computation.
I0522 16:00:25.964617 13930 net.cpp:226] conv6/dw needs backward computation.
I0522 16:00:25.964618 13930 net.cpp:226] conv5/relu needs backward computation.
I0522 16:00:25.964622 13930 net.cpp:226] conv5/scale needs backward computation.
I0522 16:00:25.964627 13930 net.cpp:226] conv5/bn needs backward computation.
I0522 16:00:25.964629 13930 net.cpp:226] conv5 needs backward computation.
I0522 16:00:25.964633 13930 net.cpp:226] conv5/dw/relu needs backward computation.
I0522 16:00:25.964637 13930 net.cpp:226] conv5/dw/scale needs backward computation.
I0522 16:00:25.964638 13930 net.cpp:226] conv5/dw/bn needs backward computation.
I0522 16:00:25.964640 13930 net.cpp:226] conv5/dw needs backward computation.
I0522 16:00:25.964643 13930 net.cpp:226] conv4/relu needs backward computation.
I0522 16:00:25.964645 13930 net.cpp:226] conv4/scale needs backward computation.
I0522 16:00:25.964649 13930 net.cpp:226] conv4/bn needs backward computation.
I0522 16:00:25.964651 13930 net.cpp:226] conv4 needs backward computation.
I0522 16:00:25.964656 13930 net.cpp:226] conv4/dw/relu needs backward computation.
I0522 16:00:25.964658 13930 net.cpp:226] conv4/dw/scale needs backward computation.
I0522 16:00:25.964660 13930 net.cpp:226] conv4/dw/bn needs backward computation.
I0522 16:00:25.964663 13930 net.cpp:226] conv4/dw needs backward computation.
I0522 16:00:25.964665 13930 net.cpp:226] conv3/relu needs backward computation.
I0522 16:00:25.964668 13930 net.cpp:226] conv3/scale needs backward computation.
I0522 16:00:25.964670 13930 net.cpp:226] conv3/bn needs backward computation.
I0522 16:00:25.964673 13930 net.cpp:226] conv3 needs backward computation.
I0522 16:00:25.964676 13930 net.cpp:226] conv3/dw/relu needs backward computation.
I0522 16:00:25.964679 13930 net.cpp:226] conv3/dw/scale needs backward computation.
I0522 16:00:25.964681 13930 net.cpp:226] conv3/dw/bn needs backward computation.
I0522 16:00:25.964684 13930 net.cpp:226] conv3/dw needs backward computation.
I0522 16:00:25.964685 13930 net.cpp:226] conv2/relu needs backward computation.
I0522 16:00:25.964687 13930 net.cpp:226] conv2/scale needs backward computation.
I0522 16:00:25.964689 13930 net.cpp:226] conv2/bn needs backward computation.
I0522 16:00:25.964692 13930 net.cpp:226] conv2 needs backward computation.
I0522 16:00:25.964694 13930 net.cpp:226] conv2/dw/relu needs backward computation.
I0522 16:00:25.964697 13930 net.cpp:226] conv2/dw/scale needs backward computation.
I0522 16:00:25.964702 13930 net.cpp:226] conv2/dw/bn needs backward computation.
I0522 16:00:25.964704 13930 net.cpp:226] conv2/dw needs backward computation.
I0522 16:00:25.964709 13930 net.cpp:226] conv1/relu needs backward computation.
I0522 16:00:25.964715 13930 net.cpp:226] conv1/scale needs backward computation.
I0522 16:00:25.964717 13930 net.cpp:226] conv1/bn needs backward computation.
I0522 16:00:25.964720 13930 net.cpp:226] conv1 needs backward computation.
I0522 16:00:25.964721 13930 net.cpp:226] conv1/dw/relu needs backward computation.
I0522 16:00:25.964725 13930 net.cpp:226] conv1/dw/scale needs backward computation.
I0522 16:00:25.964726 13930 net.cpp:226] conv1/dw/bn needs backward computation.
I0522 16:00:25.964730 13930 net.cpp:226] conv1/dw needs backward computation.
I0522 16:00:25.964733 13930 net.cpp:226] conv0/relu needs backward computation.
I0522 16:00:25.964736 13930 net.cpp:226] conv0/scale needs backward computation.
I0522 16:00:25.964741 13930 net.cpp:226] conv0/bn needs backward computation.
I0522 16:00:25.964743 13930 net.cpp:226] conv0 needs backward computation.
I0522 16:00:25.964746 13930 net.cpp:228] data_data_0_split does not need backward computation.
I0522 16:00:25.964749 13930 net.cpp:228] data does not need backward computation.
I0522 16:00:25.964752 13930 net.cpp:270] This network produces output mbox_loss
I0522 16:00:25.964815 13930 net.cpp:283] Network initialization done.
I0522 16:00:25.965700 13930 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/Mobilenet448_ssd_test.prototxt
I0522 16:00:25.965709 13930 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0522 16:00:25.965716 13930 solver.cpp:196] Creating test net (#0) specified by test_net file: mobilessd_step1/Mobilenet448_ssd_test.prototxt
I0522 16:00:25.966349 13930 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 448
      width: 448
      interp_mode: LINEAR
    }
    quant_enable: false
  }
  data_param {
    source: "/home/zhangwanchun/data/VOCdevkit/VOC0712/lmdb/VOC0712_test_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/home/zhangwanchun/data/VOCdevkit/VOC0712/lmdb/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "sample_pooling"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "sample_pooling"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 512
    stride: 2
    weight_filler {
      type: "constant_array"
      value_array: 1
      value_array: 0
      value_array: 0
      value_array: 0
    }
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "sample_pooling"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "ip6"
  type: "Convolution"
  bottom: "conv13"
  top: "ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip6"
  top: "ip6"
}
layer {
  name: "ip7"
  type: "Convolution"
  bottom: "ip6"
  top: "ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "ip7"
  top: "ip7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "ip7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv12_norm"
  type: "Normalize"
  bottom: "conv12/dw"
  top: "conv12_norm"
  norm_param {
    across_spatial: false
    channel_shared: false
  }
}
layer {
  name: "conv12_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_loc"
  top: "conv12_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_loc_perm"
  top: "conv12_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_conf"
  top: "conv12_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_conf_perm"
  top: "conv12_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_loc"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_loc_perm"
  type: "Permute"
  bottom: "ip7_mbox_loc"
  top: "ip7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_loc_flat"
  type: "Flatten"
  bottom: "ip7_mbox_loc_perm"
  top: "ip7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_conf"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_conf_perm"
  type: "Permute"
  bottom: "ip7_mbox_conf"
  top: "ip7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_conf_flat"
  type: "Flatten"
  bottom: "ip7_mbox_conf_perm"
  top: "ip7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12/dw_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv12/dw"
  bottom: "data"
  top: "conv12/dw_mbox_priorbox"
  prior_box_param {
    min_size: 44.8
    max_size: 89.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "ip7_mbox_priorbox"
  type: "PriorBox"
  bottom: "ip7"
  bottom: "data"
  top: "ip7_mbox_priorbox"
  prior_box_param {
    min_size: 89.6
    max_size: 246.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 246.4
    max_size: 403.2
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
   
I0522 16:00:25.966800 13930 layer_factory.hpp:77] Creating layer data
I0522 16:00:25.966847 13930 net.cpp:100] Creating Layer data
I0522 16:00:25.966857 13930 net.cpp:408] data -> data
I0522 16:00:25.966893 13930 net.cpp:408] data -> label
I0522 16:00:25.967844 13970 db_lmdb.cpp:35] Opened lmdb /home/zhangwanchun/data/VOCdevkit/VOC0712/lmdb/VOC0712_test_lmdb
I0522 16:00:25.969741 13930 annotated_data_layer.cpp:62] output data size: 1,3,448,448
I0522 16:00:25.973417 13930 net.cpp:150] Setting up data
I0522 16:00:25.973426 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:25.973430 13930 net.cpp:157] Top shape: 1 1 1 8 (8)
I0522 16:00:25.973433 13930 net.cpp:165] Memory required for data: 2408480
I0522 16:00:25.973435 13930 layer_factory.hpp:77] Creating layer data_data_0_split
I0522 16:00:25.973441 13930 net.cpp:100] Creating Layer data_data_0_split
I0522 16:00:25.973444 13930 net.cpp:434] data_data_0_split <- data
I0522 16:00:25.973448 13930 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0522 16:00:25.973454 13930 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0522 16:00:25.973467 13930 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0522 16:00:25.973472 13930 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0522 16:00:25.973476 13930 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0522 16:00:25.973762 13930 net.cpp:150] Setting up data_data_0_split
I0522 16:00:25.973767 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:25.973770 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:25.973773 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:25.973776 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:25.973778 13930 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0522 16:00:25.973780 13930 net.cpp:165] Memory required for data: 14450720
I0522 16:00:25.973783 13930 layer_factory.hpp:77] Creating layer conv0
I0522 16:00:25.973790 13930 net.cpp:100] Creating Layer conv0
I0522 16:00:25.973793 13930 net.cpp:434] conv0 <- data_data_0_split_0
I0522 16:00:25.973796 13930 net.cpp:408] conv0 -> conv0
I0522 16:00:25.976461 13930 net.cpp:150] Setting up conv0
I0522 16:00:25.976471 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.976475 13930 net.cpp:165] Memory required for data: 20873248
I0522 16:00:25.976480 13930 layer_factory.hpp:77] Creating layer conv0/bn
I0522 16:00:25.976483 13930 net.cpp:100] Creating Layer conv0/bn
I0522 16:00:25.976486 13930 net.cpp:434] conv0/bn <- conv0
I0522 16:00:25.976490 13930 net.cpp:395] conv0/bn -> conv0 (in-place)
I0522 16:00:25.977438 13930 net.cpp:150] Setting up conv0/bn
I0522 16:00:25.977444 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.977447 13930 net.cpp:165] Memory required for data: 27295776
I0522 16:00:25.977453 13930 layer_factory.hpp:77] Creating layer conv0/scale
I0522 16:00:25.977458 13930 net.cpp:100] Creating Layer conv0/scale
I0522 16:00:25.977460 13930 net.cpp:434] conv0/scale <- conv0
I0522 16:00:25.977464 13930 net.cpp:395] conv0/scale -> conv0 (in-place)
I0522 16:00:25.977573 13930 layer_factory.hpp:77] Creating layer conv0/scale
I0522 16:00:25.977994 13930 net.cpp:150] Setting up conv0/scale
I0522 16:00:25.977999 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.978003 13930 net.cpp:165] Memory required for data: 33718304
I0522 16:00:25.978008 13930 layer_factory.hpp:77] Creating layer conv0/relu
I0522 16:00:25.978010 13930 net.cpp:100] Creating Layer conv0/relu
I0522 16:00:25.978013 13930 net.cpp:434] conv0/relu <- conv0
I0522 16:00:25.978016 13930 net.cpp:395] conv0/relu -> conv0 (in-place)
I0522 16:00:25.978632 13930 net.cpp:150] Setting up conv0/relu
I0522 16:00:25.978641 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.978642 13930 net.cpp:165] Memory required for data: 40140832
I0522 16:00:25.978646 13930 layer_factory.hpp:77] Creating layer conv1/dw
I0522 16:00:25.978652 13930 net.cpp:100] Creating Layer conv1/dw
I0522 16:00:25.978654 13930 net.cpp:434] conv1/dw <- conv0
I0522 16:00:25.978658 13930 net.cpp:408] conv1/dw -> conv1/dw
I0522 16:00:25.979380 13930 net.cpp:150] Setting up conv1/dw
I0522 16:00:25.979387 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.979389 13930 net.cpp:165] Memory required for data: 46563360
I0522 16:00:25.979393 13930 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0522 16:00:25.979396 13930 net.cpp:100] Creating Layer conv1/dw/bn
I0522 16:00:25.979398 13930 net.cpp:434] conv1/dw/bn <- conv1/dw
I0522 16:00:25.979403 13930 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0522 16:00:25.980161 13930 net.cpp:150] Setting up conv1/dw/bn
I0522 16:00:25.980167 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.980170 13930 net.cpp:165] Memory required for data: 52985888
I0522 16:00:25.980175 13930 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0522 16:00:25.980181 13930 net.cpp:100] Creating Layer conv1/dw/scale
I0522 16:00:25.980185 13930 net.cpp:434] conv1/dw/scale <- conv1/dw
I0522 16:00:25.980187 13930 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0522 16:00:25.980296 13930 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0522 16:00:25.981222 13930 net.cpp:150] Setting up conv1/dw/scale
I0522 16:00:25.981230 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.981233 13930 net.cpp:165] Memory required for data: 59408416
I0522 16:00:25.981236 13930 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0522 16:00:25.981240 13930 net.cpp:100] Creating Layer conv1/dw/relu
I0522 16:00:25.981243 13930 net.cpp:434] conv1/dw/relu <- conv1/dw
I0522 16:00:25.981247 13930 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0522 16:00:25.981650 13930 net.cpp:150] Setting up conv1/dw/relu
I0522 16:00:25.981657 13930 net.cpp:157] Top shape: 1 32 224 224 (1605632)
I0522 16:00:25.981660 13930 net.cpp:165] Memory required for data: 65830944
I0522 16:00:25.981662 13930 layer_factory.hpp:77] Creating layer conv1
I0522 16:00:25.981668 13930 net.cpp:100] Creating Layer conv1
I0522 16:00:25.981670 13930 net.cpp:434] conv1 <- conv1/dw
I0522 16:00:25.981676 13930 net.cpp:408] conv1 -> conv1
I0522 16:00:25.984179 13930 net.cpp:150] Setting up conv1
I0522 16:00:25.984187 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:25.984189 13930 net.cpp:165] Memory required for data: 78676000
I0522 16:00:25.984194 13930 layer_factory.hpp:77] Creating layer conv1/bn
I0522 16:00:25.984199 13930 net.cpp:100] Creating Layer conv1/bn
I0522 16:00:25.984201 13930 net.cpp:434] conv1/bn <- conv1
I0522 16:00:25.984205 13930 net.cpp:395] conv1/bn -> conv1 (in-place)
I0522 16:00:25.984939 13930 net.cpp:150] Setting up conv1/bn
I0522 16:00:25.984944 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:25.984947 13930 net.cpp:165] Memory required for data: 91521056
I0522 16:00:25.984951 13930 layer_factory.hpp:77] Creating layer conv1/scale
I0522 16:00:25.984956 13930 net.cpp:100] Creating Layer conv1/scale
I0522 16:00:25.984958 13930 net.cpp:434] conv1/scale <- conv1
I0522 16:00:25.984961 13930 net.cpp:395] conv1/scale -> conv1 (in-place)
I0522 16:00:25.985072 13930 layer_factory.hpp:77] Creating layer conv1/scale
I0522 16:00:25.985456 13930 net.cpp:150] Setting up conv1/scale
I0522 16:00:25.985463 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:25.985466 13930 net.cpp:165] Memory required for data: 104366112
I0522 16:00:25.985473 13930 layer_factory.hpp:77] Creating layer conv1/relu
I0522 16:00:25.985477 13930 net.cpp:100] Creating Layer conv1/relu
I0522 16:00:25.985481 13930 net.cpp:434] conv1/relu <- conv1
I0522 16:00:25.985483 13930 net.cpp:395] conv1/relu -> conv1 (in-place)
I0522 16:00:25.988404 13930 net.cpp:150] Setting up conv1/relu
I0522 16:00:25.988415 13930 net.cpp:157] Top shape: 1 64 224 224 (3211264)
I0522 16:00:25.988417 13930 net.cpp:165] Memory required for data: 117211168
I0522 16:00:25.988420 13930 layer_factory.hpp:77] Creating layer conv2/dw
I0522 16:00:25.988426 13930 net.cpp:100] Creating Layer conv2/dw
I0522 16:00:25.988430 13930 net.cpp:434] conv2/dw <- conv1
I0522 16:00:25.988433 13930 net.cpp:408] conv2/dw -> conv2/dw
I0522 16:00:25.989157 13930 net.cpp:150] Setting up conv2/dw
I0522 16:00:25.989163 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:25.989166 13930 net.cpp:165] Memory required for data: 120422432
I0522 16:00:25.989169 13930 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0522 16:00:25.989173 13930 net.cpp:100] Creating Layer conv2/dw/bn
I0522 16:00:25.989176 13930 net.cpp:434] conv2/dw/bn <- conv2/dw
I0522 16:00:25.989178 13930 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0522 16:00:25.989922 13930 net.cpp:150] Setting up conv2/dw/bn
I0522 16:00:25.989928 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:25.989929 13930 net.cpp:165] Memory required for data: 123633696
I0522 16:00:25.989934 13930 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0522 16:00:25.989939 13930 net.cpp:100] Creating Layer conv2/dw/scale
I0522 16:00:25.989941 13930 net.cpp:434] conv2/dw/scale <- conv2/dw
I0522 16:00:25.989945 13930 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0522 16:00:25.990056 13930 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0522 16:00:25.990469 13930 net.cpp:150] Setting up conv2/dw/scale
I0522 16:00:25.990475 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:25.990478 13930 net.cpp:165] Memory required for data: 126844960
I0522 16:00:25.990481 13930 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0522 16:00:25.990484 13930 net.cpp:100] Creating Layer conv2/dw/relu
I0522 16:00:25.990486 13930 net.cpp:434] conv2/dw/relu <- conv2/dw
I0522 16:00:25.990490 13930 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0522 16:00:25.990890 13930 net.cpp:150] Setting up conv2/dw/relu
I0522 16:00:25.990898 13930 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0522 16:00:25.990900 13930 net.cpp:165] Memory required for data: 130056224
I0522 16:00:25.990903 13930 layer_factory.hpp:77] Creating layer conv2
I0522 16:00:25.990908 13930 net.cpp:100] Creating Layer conv2
I0522 16:00:25.990911 13930 net.cpp:434] conv2 <- conv2/dw
I0522 16:00:25.990916 13930 net.cpp:408] conv2 -> conv2
I0522 16:00:25.993409 13930 net.cpp:150] Setting up conv2
I0522 16:00:25.993418 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.993422 13930 net.cpp:165] Memory required for data: 136478752
I0522 16:00:25.993424 13930 layer_factory.hpp:77] Creating layer conv2/bn
I0522 16:00:25.993428 13930 net.cpp:100] Creating Layer conv2/bn
I0522 16:00:25.993430 13930 net.cpp:434] conv2/bn <- conv2
I0522 16:00:25.993438 13930 net.cpp:395] conv2/bn -> conv2 (in-place)
I0522 16:00:25.994180 13930 net.cpp:150] Setting up conv2/bn
I0522 16:00:25.994185 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.994187 13930 net.cpp:165] Memory required for data: 142901280
I0522 16:00:25.994192 13930 layer_factory.hpp:77] Creating layer conv2/scale
I0522 16:00:25.994196 13930 net.cpp:100] Creating Layer conv2/scale
I0522 16:00:25.994200 13930 net.cpp:434] conv2/scale <- conv2
I0522 16:00:25.994204 13930 net.cpp:395] conv2/scale -> conv2 (in-place)
I0522 16:00:25.994313 13930 layer_factory.hpp:77] Creating layer conv2/scale
I0522 16:00:25.994781 13930 net.cpp:150] Setting up conv2/scale
I0522 16:00:25.994791 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.994794 13930 net.cpp:165] Memory required for data: 149323808
I0522 16:00:25.994801 13930 layer_factory.hpp:77] Creating layer conv2/relu
I0522 16:00:25.994804 13930 net.cpp:100] Creating Layer conv2/relu
I0522 16:00:25.994807 13930 net.cpp:434] conv2/relu <- conv2
I0522 16:00:25.994810 13930 net.cpp:395] conv2/relu -> conv2 (in-place)
I0522 16:00:25.995483 13930 net.cpp:150] Setting up conv2/relu
I0522 16:00:25.995491 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.995494 13930 net.cpp:165] Memory required for data: 155746336
I0522 16:00:25.995496 13930 layer_factory.hpp:77] Creating layer conv3/dw
I0522 16:00:25.995503 13930 net.cpp:100] Creating Layer conv3/dw
I0522 16:00:25.995507 13930 net.cpp:434] conv3/dw <- conv2
I0522 16:00:25.995510 13930 net.cpp:408] conv3/dw -> conv3/dw
I0522 16:00:25.996228 13930 net.cpp:150] Setting up conv3/dw
I0522 16:00:25.996235 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.996237 13930 net.cpp:165] Memory required for data: 162168864
I0522 16:00:25.996240 13930 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0522 16:00:25.996243 13930 net.cpp:100] Creating Layer conv3/dw/bn
I0522 16:00:25.996246 13930 net.cpp:434] conv3/dw/bn <- conv3/dw
I0522 16:00:25.996249 13930 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0522 16:00:25.996986 13930 net.cpp:150] Setting up conv3/dw/bn
I0522 16:00:25.996991 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.996994 13930 net.cpp:165] Memory required for data: 168591392
I0522 16:00:25.997001 13930 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0522 16:00:25.997006 13930 net.cpp:100] Creating Layer conv3/dw/scale
I0522 16:00:25.997009 13930 net.cpp:434] conv3/dw/scale <- conv3/dw
I0522 16:00:25.997012 13930 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0522 16:00:25.997121 13930 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0522 16:00:25.997524 13930 net.cpp:150] Setting up conv3/dw/scale
I0522 16:00:25.997530 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.997532 13930 net.cpp:165] Memory required for data: 175013920
I0522 16:00:25.997536 13930 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0522 16:00:25.997539 13930 net.cpp:100] Creating Layer conv3/dw/relu
I0522 16:00:25.997541 13930 net.cpp:434] conv3/dw/relu <- conv3/dw
I0522 16:00:25.997547 13930 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0522 16:00:25.997946 13930 net.cpp:150] Setting up conv3/dw/relu
I0522 16:00:25.997953 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:25.997956 13930 net.cpp:165] Memory required for data: 181436448
I0522 16:00:25.997958 13930 layer_factory.hpp:77] Creating layer conv3
I0522 16:00:25.997964 13930 net.cpp:100] Creating Layer conv3
I0522 16:00:25.997967 13930 net.cpp:434] conv3 <- conv3/dw
I0522 16:00:25.997972 13930 net.cpp:408] conv3 -> conv3
I0522 16:00:26.001045 13930 net.cpp:150] Setting up conv3
I0522 16:00:26.001055 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:26.001057 13930 net.cpp:165] Memory required for data: 187858976
I0522 16:00:26.001061 13930 layer_factory.hpp:77] Creating layer conv3/bn
I0522 16:00:26.001065 13930 net.cpp:100] Creating Layer conv3/bn
I0522 16:00:26.001068 13930 net.cpp:434] conv3/bn <- conv3
I0522 16:00:26.001072 13930 net.cpp:395] conv3/bn -> conv3 (in-place)
I0522 16:00:26.002039 13930 net.cpp:150] Setting up conv3/bn
I0522 16:00:26.002046 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:26.002048 13930 net.cpp:165] Memory required for data: 194281504
I0522 16:00:26.002053 13930 layer_factory.hpp:77] Creating layer conv3/scale
I0522 16:00:26.002056 13930 net.cpp:100] Creating Layer conv3/scale
I0522 16:00:26.002059 13930 net.cpp:434] conv3/scale <- conv3
I0522 16:00:26.002063 13930 net.cpp:395] conv3/scale -> conv3 (in-place)
I0522 16:00:26.002171 13930 layer_factory.hpp:77] Creating layer conv3/scale
I0522 16:00:26.002564 13930 net.cpp:150] Setting up conv3/scale
I0522 16:00:26.002570 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:26.002573 13930 net.cpp:165] Memory required for data: 200704032
I0522 16:00:26.002576 13930 layer_factory.hpp:77] Creating layer conv3/relu
I0522 16:00:26.002579 13930 net.cpp:100] Creating Layer conv3/relu
I0522 16:00:26.002583 13930 net.cpp:434] conv3/relu <- conv3
I0522 16:00:26.002586 13930 net.cpp:395] conv3/relu -> conv3 (in-place)
I0522 16:00:26.005318 13930 net.cpp:150] Setting up conv3/relu
I0522 16:00:26.005328 13930 net.cpp:157] Top shape: 1 128 112 112 (1605632)
I0522 16:00:26.005331 13930 net.cpp:165] Memory required for data: 207126560
I0522 16:00:26.005333 13930 layer_factory.hpp:77] Creating layer conv4/dw
I0522 16:00:26.005342 13930 net.cpp:100] Creating Layer conv4/dw
I0522 16:00:26.005345 13930 net.cpp:434] conv4/dw <- conv3
I0522 16:00:26.005349 13930 net.cpp:408] conv4/dw -> conv4/dw
I0522 16:00:26.006074 13930 net.cpp:150] Setting up conv4/dw
I0522 16:00:26.006081 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:26.006083 13930 net.cpp:165] Memory required for data: 208732192
I0522 16:00:26.006088 13930 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0522 16:00:26.006090 13930 net.cpp:100] Creating Layer conv4/dw/bn
I0522 16:00:26.006093 13930 net.cpp:434] conv4/dw/bn <- conv4/dw
I0522 16:00:26.006095 13930 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0522 16:00:26.006834 13930 net.cpp:150] Setting up conv4/dw/bn
I0522 16:00:26.006839 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:26.006840 13930 net.cpp:165] Memory required for data: 210337824
I0522 16:00:26.006845 13930 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0522 16:00:26.006852 13930 net.cpp:100] Creating Layer conv4/dw/scale
I0522 16:00:26.006855 13930 net.cpp:434] conv4/dw/scale <- conv4/dw
I0522 16:00:26.006858 13930 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0522 16:00:26.006968 13930 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0522 16:00:26.007369 13930 net.cpp:150] Setting up conv4/dw/scale
I0522 16:00:26.007383 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:26.007385 13930 net.cpp:165] Memory required for data: 211943456
I0522 16:00:26.007390 13930 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0522 16:00:26.007393 13930 net.cpp:100] Creating Layer conv4/dw/relu
I0522 16:00:26.007395 13930 net.cpp:434] conv4/dw/relu <- conv4/dw
I0522 16:00:26.007398 13930 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0522 16:00:26.007800 13930 net.cpp:150] Setting up conv4/dw/relu
I0522 16:00:26.007808 13930 net.cpp:157] Top shape: 1 128 56 56 (401408)
I0522 16:00:26.007812 13930 net.cpp:165] Memory required for data: 213549088
I0522 16:00:26.007814 13930 layer_factory.hpp:77] Creating layer conv4
I0522 16:00:26.007823 13930 net.cpp:100] Creating Layer conv4
I0522 16:00:26.007828 13930 net.cpp:434] conv4 <- conv4/dw
I0522 16:00:26.007833 13930 net.cpp:408] conv4 -> conv4
I0522 16:00:26.010586 13930 net.cpp:150] Setting up conv4
I0522 16:00:26.010594 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.010597 13930 net.cpp:165] Memory required for data: 216760352
I0522 16:00:26.010601 13930 layer_factory.hpp:77] Creating layer conv4/bn
I0522 16:00:26.010605 13930 net.cpp:100] Creating Layer conv4/bn
I0522 16:00:26.010608 13930 net.cpp:434] conv4/bn <- conv4
I0522 16:00:26.010612 13930 net.cpp:395] conv4/bn -> conv4 (in-place)
I0522 16:00:26.011360 13930 net.cpp:150] Setting up conv4/bn
I0522 16:00:26.011366 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.011368 13930 net.cpp:165] Memory required for data: 219971616
I0522 16:00:26.011373 13930 layer_factory.hpp:77] Creating layer conv4/scale
I0522 16:00:26.011379 13930 net.cpp:100] Creating Layer conv4/scale
I0522 16:00:26.011380 13930 net.cpp:434] conv4/scale <- conv4
I0522 16:00:26.011384 13930 net.cpp:395] conv4/scale -> conv4 (in-place)
I0522 16:00:26.011493 13930 layer_factory.hpp:77] Creating layer conv4/scale
I0522 16:00:26.011898 13930 net.cpp:150] Setting up conv4/scale
I0522 16:00:26.011904 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.011906 13930 net.cpp:165] Memory required for data: 223182880
I0522 16:00:26.011910 13930 layer_factory.hpp:77] Creating layer conv4/relu
I0522 16:00:26.011914 13930 net.cpp:100] Creating Layer conv4/relu
I0522 16:00:26.011916 13930 net.cpp:434] conv4/relu <- conv4
I0522 16:00:26.011920 13930 net.cpp:395] conv4/relu -> conv4 (in-place)
I0522 16:00:26.012560 13930 net.cpp:150] Setting up conv4/relu
I0522 16:00:26.012568 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.012570 13930 net.cpp:165] Memory required for data: 226394144
I0522 16:00:26.012573 13930 layer_factory.hpp:77] Creating layer conv5/dw
I0522 16:00:26.012580 13930 net.cpp:100] Creating Layer conv5/dw
I0522 16:00:26.012583 13930 net.cpp:434] conv5/dw <- conv4
I0522 16:00:26.012588 13930 net.cpp:408] conv5/dw -> conv5/dw
I0522 16:00:26.013332 13930 net.cpp:150] Setting up conv5/dw
I0522 16:00:26.013340 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.013343 13930 net.cpp:165] Memory required for data: 229605408
I0522 16:00:26.013346 13930 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0522 16:00:26.013350 13930 net.cpp:100] Creating Layer conv5/dw/bn
I0522 16:00:26.013353 13930 net.cpp:434] conv5/dw/bn <- conv5/dw
I0522 16:00:26.013356 13930 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0522 16:00:26.014096 13930 net.cpp:150] Setting up conv5/dw/bn
I0522 16:00:26.014101 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.014107 13930 net.cpp:165] Memory required for data: 232816672
I0522 16:00:26.014111 13930 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0522 16:00:26.014114 13930 net.cpp:100] Creating Layer conv5/dw/scale
I0522 16:00:26.014117 13930 net.cpp:434] conv5/dw/scale <- conv5/dw
I0522 16:00:26.014122 13930 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0522 16:00:26.014231 13930 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0522 16:00:26.014631 13930 net.cpp:150] Setting up conv5/dw/scale
I0522 16:00:26.014642 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.014645 13930 net.cpp:165] Memory required for data: 236027936
I0522 16:00:26.014648 13930 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0522 16:00:26.014652 13930 net.cpp:100] Creating Layer conv5/dw/relu
I0522 16:00:26.014654 13930 net.cpp:434] conv5/dw/relu <- conv5/dw
I0522 16:00:26.014660 13930 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0522 16:00:26.015055 13930 net.cpp:150] Setting up conv5/dw/relu
I0522 16:00:26.015064 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.015065 13930 net.cpp:165] Memory required for data: 239239200
I0522 16:00:26.015069 13930 layer_factory.hpp:77] Creating layer conv5
I0522 16:00:26.015074 13930 net.cpp:100] Creating Layer conv5
I0522 16:00:26.015076 13930 net.cpp:434] conv5 <- conv5/dw
I0522 16:00:26.015080 13930 net.cpp:408] conv5 -> conv5
I0522 16:00:26.017815 13930 net.cpp:150] Setting up conv5
I0522 16:00:26.017824 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.017827 13930 net.cpp:165] Memory required for data: 242450464
I0522 16:00:26.017830 13930 layer_factory.hpp:77] Creating layer conv5/bn
I0522 16:00:26.017835 13930 net.cpp:100] Creating Layer conv5/bn
I0522 16:00:26.017838 13930 net.cpp:434] conv5/bn <- conv5
I0522 16:00:26.017841 13930 net.cpp:395] conv5/bn -> conv5 (in-place)
I0522 16:00:26.018591 13930 net.cpp:150] Setting up conv5/bn
I0522 16:00:26.018599 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.018600 13930 net.cpp:165] Memory required for data: 245661728
I0522 16:00:26.018605 13930 layer_factory.hpp:77] Creating layer conv5/scale
I0522 16:00:26.018610 13930 net.cpp:100] Creating Layer conv5/scale
I0522 16:00:26.018611 13930 net.cpp:434] conv5/scale <- conv5
I0522 16:00:26.018615 13930 net.cpp:395] conv5/scale -> conv5 (in-place)
I0522 16:00:26.018724 13930 layer_factory.hpp:77] Creating layer conv5/scale
I0522 16:00:26.019124 13930 net.cpp:150] Setting up conv5/scale
I0522 16:00:26.019129 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.019131 13930 net.cpp:165] Memory required for data: 248872992
I0522 16:00:26.019141 13930 layer_factory.hpp:77] Creating layer conv5/relu
I0522 16:00:26.019145 13930 net.cpp:100] Creating Layer conv5/relu
I0522 16:00:26.019147 13930 net.cpp:434] conv5/relu <- conv5
I0522 16:00:26.019151 13930 net.cpp:395] conv5/relu -> conv5 (in-place)
I0522 16:00:26.021798 13930 net.cpp:150] Setting up conv5/relu
I0522 16:00:26.021808 13930 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0522 16:00:26.021811 13930 net.cpp:165] Memory required for data: 252084256
I0522 16:00:26.021813 13930 layer_factory.hpp:77] Creating layer conv6/dw
I0522 16:00:26.021821 13930 net.cpp:100] Creating Layer conv6/dw
I0522 16:00:26.021824 13930 net.cpp:434] conv6/dw <- conv5
I0522 16:00:26.021829 13930 net.cpp:408] conv6/dw -> conv6/dw
I0522 16:00:26.022575 13930 net.cpp:150] Setting up conv6/dw
I0522 16:00:26.022583 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:26.022585 13930 net.cpp:165] Memory required for data: 252887072
I0522 16:00:26.022589 13930 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0522 16:00:26.022593 13930 net.cpp:100] Creating Layer conv6/dw/bn
I0522 16:00:26.022595 13930 net.cpp:434] conv6/dw/bn <- conv6/dw
I0522 16:00:26.022598 13930 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0522 16:00:26.023352 13930 net.cpp:150] Setting up conv6/dw/bn
I0522 16:00:26.023357 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:26.023360 13930 net.cpp:165] Memory required for data: 253689888
I0522 16:00:26.023365 13930 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0522 16:00:26.023368 13930 net.cpp:100] Creating Layer conv6/dw/scale
I0522 16:00:26.023370 13930 net.cpp:434] conv6/dw/scale <- conv6/dw
I0522 16:00:26.023375 13930 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0522 16:00:26.023484 13930 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0522 16:00:26.023902 13930 net.cpp:150] Setting up conv6/dw/scale
I0522 16:00:26.023914 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:26.023917 13930 net.cpp:165] Memory required for data: 254492704
I0522 16:00:26.023921 13930 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0522 16:00:26.023924 13930 net.cpp:100] Creating Layer conv6/dw/relu
I0522 16:00:26.023926 13930 net.cpp:434] conv6/dw/relu <- conv6/dw
I0522 16:00:26.023931 13930 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0522 16:00:26.024333 13930 net.cpp:150] Setting up conv6/dw/relu
I0522 16:00:26.024341 13930 net.cpp:157] Top shape: 1 256 28 28 (200704)
I0522 16:00:26.024343 13930 net.cpp:165] Memory required for data: 255295520
I0522 16:00:26.024345 13930 layer_factory.hpp:77] Creating layer conv6
I0522 16:00:26.024351 13930 net.cpp:100] Creating Layer conv6
I0522 16:00:26.024354 13930 net.cpp:434] conv6 <- conv6/dw
I0522 16:00:26.024358 13930 net.cpp:408] conv6 -> conv6
I0522 16:00:26.027470 13930 net.cpp:150] Setting up conv6
I0522 16:00:26.027479 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.027482 13930 net.cpp:165] Memory required for data: 256901152
I0522 16:00:26.027485 13930 layer_factory.hpp:77] Creating layer conv6/bn
I0522 16:00:26.027490 13930 net.cpp:100] Creating Layer conv6/bn
I0522 16:00:26.027493 13930 net.cpp:434] conv6/bn <- conv6
I0522 16:00:26.027498 13930 net.cpp:395] conv6/bn -> conv6 (in-place)
I0522 16:00:26.028260 13930 net.cpp:150] Setting up conv6/bn
I0522 16:00:26.028266 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.028268 13930 net.cpp:165] Memory required for data: 258506784
I0522 16:00:26.028273 13930 layer_factory.hpp:77] Creating layer conv6/scale
I0522 16:00:26.028280 13930 net.cpp:100] Creating Layer conv6/scale
I0522 16:00:26.028281 13930 net.cpp:434] conv6/scale <- conv6
I0522 16:00:26.028285 13930 net.cpp:395] conv6/scale -> conv6 (in-place)
I0522 16:00:26.028398 13930 layer_factory.hpp:77] Creating layer conv6/scale
I0522 16:00:26.028808 13930 net.cpp:150] Setting up conv6/scale
I0522 16:00:26.028815 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.028816 13930 net.cpp:165] Memory required for data: 260112416
I0522 16:00:26.028820 13930 layer_factory.hpp:77] Creating layer conv6/relu
I0522 16:00:26.028825 13930 net.cpp:100] Creating Layer conv6/relu
I0522 16:00:26.028826 13930 net.cpp:434] conv6/relu <- conv6
I0522 16:00:26.028829 13930 net.cpp:395] conv6/relu -> conv6 (in-place)
I0522 16:00:26.029592 13930 net.cpp:150] Setting up conv6/relu
I0522 16:00:26.029601 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.029603 13930 net.cpp:165] Memory required for data: 261718048
I0522 16:00:26.029605 13930 layer_factory.hpp:77] Creating layer conv7/dw
I0522 16:00:26.029613 13930 net.cpp:100] Creating Layer conv7/dw
I0522 16:00:26.029615 13930 net.cpp:434] conv7/dw <- conv6
I0522 16:00:26.029619 13930 net.cpp:408] conv7/dw -> conv7/dw
I0522 16:00:26.030364 13930 net.cpp:150] Setting up conv7/dw
I0522 16:00:26.030369 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.030372 13930 net.cpp:165] Memory required for data: 263323680
I0522 16:00:26.030375 13930 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0522 16:00:26.030378 13930 net.cpp:100] Creating Layer conv7/dw/bn
I0522 16:00:26.030380 13930 net.cpp:434] conv7/dw/bn <- conv7/dw
I0522 16:00:26.030385 13930 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0522 16:00:26.031152 13930 net.cpp:150] Setting up conv7/dw/bn
I0522 16:00:26.031158 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.031160 13930 net.cpp:165] Memory required for data: 264929312
I0522 16:00:26.031165 13930 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0522 16:00:26.031169 13930 net.cpp:100] Creating Layer conv7/dw/scale
I0522 16:00:26.031172 13930 net.cpp:434] conv7/dw/scale <- conv7/dw
I0522 16:00:26.031177 13930 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0522 16:00:26.031289 13930 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0522 16:00:26.031699 13930 net.cpp:150] Setting up conv7/dw/scale
I0522 16:00:26.031705 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.031713 13930 net.cpp:165] Memory required for data: 266534944
I0522 16:00:26.031718 13930 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0522 16:00:26.031720 13930 net.cpp:100] Creating Layer conv7/dw/relu
I0522 16:00:26.031723 13930 net.cpp:434] conv7/dw/relu <- conv7/dw
I0522 16:00:26.031728 13930 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0522 16:00:26.032160 13930 net.cpp:150] Setting up conv7/dw/relu
I0522 16:00:26.032169 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.032171 13930 net.cpp:165] Memory required for data: 268140576
I0522 16:00:26.032173 13930 layer_factory.hpp:77] Creating layer conv7
I0522 16:00:26.032181 13930 net.cpp:100] Creating Layer conv7
I0522 16:00:26.032183 13930 net.cpp:434] conv7 <- conv7/dw
I0522 16:00:26.032187 13930 net.cpp:408] conv7 -> conv7
I0522 16:00:26.036684 13930 net.cpp:150] Setting up conv7
I0522 16:00:26.036693 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.036696 13930 net.cpp:165] Memory required for data: 269746208
I0522 16:00:26.036700 13930 layer_factory.hpp:77] Creating layer conv7/bn
I0522 16:00:26.036705 13930 net.cpp:100] Creating Layer conv7/bn
I0522 16:00:26.036707 13930 net.cpp:434] conv7/bn <- conv7
I0522 16:00:26.036711 13930 net.cpp:395] conv7/bn -> conv7 (in-place)
I0522 16:00:26.037477 13930 net.cpp:150] Setting up conv7/bn
I0522 16:00:26.037482 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.037483 13930 net.cpp:165] Memory required for data: 271351840
I0522 16:00:26.037488 13930 layer_factory.hpp:77] Creating layer conv7/scale
I0522 16:00:26.037493 13930 net.cpp:100] Creating Layer conv7/scale
I0522 16:00:26.037495 13930 net.cpp:434] conv7/scale <- conv7
I0522 16:00:26.037499 13930 net.cpp:395] conv7/scale -> conv7 (in-place)
I0522 16:00:26.037611 13930 layer_factory.hpp:77] Creating layer conv7/scale
I0522 16:00:26.038023 13930 net.cpp:150] Setting up conv7/scale
I0522 16:00:26.038028 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.038030 13930 net.cpp:165] Memory required for data: 272957472
I0522 16:00:26.038034 13930 layer_factory.hpp:77] Creating layer conv7/relu
I0522 16:00:26.038038 13930 net.cpp:100] Creating Layer conv7/relu
I0522 16:00:26.038040 13930 net.cpp:434] conv7/relu <- conv7
I0522 16:00:26.038043 13930 net.cpp:395] conv7/relu -> conv7 (in-place)
I0522 16:00:26.040932 13930 net.cpp:150] Setting up conv7/relu
I0522 16:00:26.040941 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.040944 13930 net.cpp:165] Memory required for data: 274563104
I0522 16:00:26.040946 13930 layer_factory.hpp:77] Creating layer conv8/dw
I0522 16:00:26.040956 13930 net.cpp:100] Creating Layer conv8/dw
I0522 16:00:26.040957 13930 net.cpp:434] conv8/dw <- conv7
I0522 16:00:26.040962 13930 net.cpp:408] conv8/dw -> conv8/dw
I0522 16:00:26.041715 13930 net.cpp:150] Setting up conv8/dw
I0522 16:00:26.041721 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.041724 13930 net.cpp:165] Memory required for data: 276168736
I0522 16:00:26.041728 13930 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0522 16:00:26.041730 13930 net.cpp:100] Creating Layer conv8/dw/bn
I0522 16:00:26.041733 13930 net.cpp:434] conv8/dw/bn <- conv8/dw
I0522 16:00:26.041736 13930 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0522 16:00:26.042493 13930 net.cpp:150] Setting up conv8/dw/bn
I0522 16:00:26.042498 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.042500 13930 net.cpp:165] Memory required for data: 277774368
I0522 16:00:26.042505 13930 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0522 16:00:26.042518 13930 net.cpp:100] Creating Layer conv8/dw/scale
I0522 16:00:26.042520 13930 net.cpp:434] conv8/dw/scale <- conv8/dw
I0522 16:00:26.042523 13930 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0522 16:00:26.042637 13930 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0522 16:00:26.043051 13930 net.cpp:150] Setting up conv8/dw/scale
I0522 16:00:26.043056 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.043066 13930 net.cpp:165] Memory required for data: 279380000
I0522 16:00:26.043071 13930 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0522 16:00:26.043073 13930 net.cpp:100] Creating Layer conv8/dw/relu
I0522 16:00:26.043076 13930 net.cpp:434] conv8/dw/relu <- conv8/dw
I0522 16:00:26.043079 13930 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0522 16:00:26.043509 13930 net.cpp:150] Setting up conv8/dw/relu
I0522 16:00:26.043516 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.043519 13930 net.cpp:165] Memory required for data: 280985632
I0522 16:00:26.043520 13930 layer_factory.hpp:77] Creating layer conv8
I0522 16:00:26.043526 13930 net.cpp:100] Creating Layer conv8
I0522 16:00:26.043529 13930 net.cpp:434] conv8 <- conv8/dw
I0522 16:00:26.043534 13930 net.cpp:408] conv8 -> conv8
I0522 16:00:26.047439 13930 net.cpp:150] Setting up conv8
I0522 16:00:26.047448 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.047451 13930 net.cpp:165] Memory required for data: 282591264
I0522 16:00:26.047454 13930 layer_factory.hpp:77] Creating layer conv8/bn
I0522 16:00:26.047459 13930 net.cpp:100] Creating Layer conv8/bn
I0522 16:00:26.047461 13930 net.cpp:434] conv8/bn <- conv8
I0522 16:00:26.047466 13930 net.cpp:395] conv8/bn -> conv8 (in-place)
I0522 16:00:26.048235 13930 net.cpp:150] Setting up conv8/bn
I0522 16:00:26.048243 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.048244 13930 net.cpp:165] Memory required for data: 284196896
I0522 16:00:26.048249 13930 layer_factory.hpp:77] Creating layer conv8/scale
I0522 16:00:26.048254 13930 net.cpp:100] Creating Layer conv8/scale
I0522 16:00:26.048255 13930 net.cpp:434] conv8/scale <- conv8
I0522 16:00:26.048259 13930 net.cpp:395] conv8/scale -> conv8 (in-place)
I0522 16:00:26.048373 13930 layer_factory.hpp:77] Creating layer conv8/scale
I0522 16:00:26.048868 13930 net.cpp:150] Setting up conv8/scale
I0522 16:00:26.048876 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.048877 13930 net.cpp:165] Memory required for data: 285802528
I0522 16:00:26.048882 13930 layer_factory.hpp:77] Creating layer conv8/relu
I0522 16:00:26.048884 13930 net.cpp:100] Creating Layer conv8/relu
I0522 16:00:26.048887 13930 net.cpp:434] conv8/relu <- conv8
I0522 16:00:26.048892 13930 net.cpp:395] conv8/relu -> conv8 (in-place)
I0522 16:00:26.049558 13930 net.cpp:150] Setting up conv8/relu
I0522 16:00:26.049566 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.049568 13930 net.cpp:165] Memory required for data: 287408160
I0522 16:00:26.049571 13930 layer_factory.hpp:77] Creating layer conv9/dw
I0522 16:00:26.049577 13930 net.cpp:100] Creating Layer conv9/dw
I0522 16:00:26.049580 13930 net.cpp:434] conv9/dw <- conv8
I0522 16:00:26.049585 13930 net.cpp:408] conv9/dw -> conv9/dw
I0522 16:00:26.050366 13930 net.cpp:150] Setting up conv9/dw
I0522 16:00:26.050372 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.050375 13930 net.cpp:165] Memory required for data: 289013792
I0522 16:00:26.050379 13930 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0522 16:00:26.050382 13930 net.cpp:100] Creating Layer conv9/dw/bn
I0522 16:00:26.050384 13930 net.cpp:434] conv9/dw/bn <- conv9/dw
I0522 16:00:26.050387 13930 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0522 16:00:26.051175 13930 net.cpp:150] Setting up conv9/dw/bn
I0522 16:00:26.051180 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.051183 13930 net.cpp:165] Memory required for data: 290619424
I0522 16:00:26.051187 13930 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0522 16:00:26.051192 13930 net.cpp:100] Creating Layer conv9/dw/scale
I0522 16:00:26.051194 13930 net.cpp:434] conv9/dw/scale <- conv9/dw
I0522 16:00:26.051198 13930 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0522 16:00:26.051342 13930 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0522 16:00:26.051787 13930 net.cpp:150] Setting up conv9/dw/scale
I0522 16:00:26.051792 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.051801 13930 net.cpp:165] Memory required for data: 292225056
I0522 16:00:26.051805 13930 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0522 16:00:26.051811 13930 net.cpp:100] Creating Layer conv9/dw/relu
I0522 16:00:26.051813 13930 net.cpp:434] conv9/dw/relu <- conv9/dw
I0522 16:00:26.051817 13930 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0522 16:00:26.052248 13930 net.cpp:150] Setting up conv9/dw/relu
I0522 16:00:26.052256 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.052258 13930 net.cpp:165] Memory required for data: 293830688
I0522 16:00:26.052261 13930 layer_factory.hpp:77] Creating layer conv9
I0522 16:00:26.052268 13930 net.cpp:100] Creating Layer conv9
I0522 16:00:26.052269 13930 net.cpp:434] conv9 <- conv9/dw
I0522 16:00:26.052274 13930 net.cpp:408] conv9 -> conv9
I0522 16:00:26.056753 13930 net.cpp:150] Setting up conv9
I0522 16:00:26.056762 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.056764 13930 net.cpp:165] Memory required for data: 295436320
I0522 16:00:26.056768 13930 layer_factory.hpp:77] Creating layer conv9/bn
I0522 16:00:26.056776 13930 net.cpp:100] Creating Layer conv9/bn
I0522 16:00:26.056778 13930 net.cpp:434] conv9/bn <- conv9
I0522 16:00:26.056782 13930 net.cpp:395] conv9/bn -> conv9 (in-place)
I0522 16:00:26.057698 13930 net.cpp:150] Setting up conv9/bn
I0522 16:00:26.057705 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.057708 13930 net.cpp:165] Memory required for data: 297041952
I0522 16:00:26.057713 13930 layer_factory.hpp:77] Creating layer conv9/scale
I0522 16:00:26.057716 13930 net.cpp:100] Creating Layer conv9/scale
I0522 16:00:26.057719 13930 net.cpp:434] conv9/scale <- conv9
I0522 16:00:26.057723 13930 net.cpp:395] conv9/scale -> conv9 (in-place)
I0522 16:00:26.057870 13930 layer_factory.hpp:77] Creating layer conv9/scale
I0522 16:00:26.058318 13930 net.cpp:150] Setting up conv9/scale
I0522 16:00:26.058324 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.058326 13930 net.cpp:165] Memory required for data: 298647584
I0522 16:00:26.058329 13930 layer_factory.hpp:77] Creating layer conv9/relu
I0522 16:00:26.058334 13930 net.cpp:100] Creating Layer conv9/relu
I0522 16:00:26.058336 13930 net.cpp:434] conv9/relu <- conv9
I0522 16:00:26.058339 13930 net.cpp:395] conv9/relu -> conv9 (in-place)
I0522 16:00:26.061040 13930 net.cpp:150] Setting up conv9/relu
I0522 16:00:26.061050 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.061053 13930 net.cpp:165] Memory required for data: 300253216
I0522 16:00:26.061055 13930 layer_factory.hpp:77] Creating layer conv10/dw
I0522 16:00:26.061061 13930 net.cpp:100] Creating Layer conv10/dw
I0522 16:00:26.061064 13930 net.cpp:434] conv10/dw <- conv9
I0522 16:00:26.061069 13930 net.cpp:408] conv10/dw -> conv10/dw
I0522 16:00:26.061858 13930 net.cpp:150] Setting up conv10/dw
I0522 16:00:26.061864 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.061867 13930 net.cpp:165] Memory required for data: 301858848
I0522 16:00:26.061870 13930 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0522 16:00:26.061890 13930 net.cpp:100] Creating Layer conv10/dw/bn
I0522 16:00:26.061892 13930 net.cpp:434] conv10/dw/bn <- conv10/dw
I0522 16:00:26.061895 13930 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0522 16:00:26.062883 13930 net.cpp:150] Setting up conv10/dw/bn
I0522 16:00:26.062888 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.062891 13930 net.cpp:165] Memory required for data: 303464480
I0522 16:00:26.062896 13930 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0522 16:00:26.062899 13930 net.cpp:100] Creating Layer conv10/dw/scale
I0522 16:00:26.062902 13930 net.cpp:434] conv10/dw/scale <- conv10/dw
I0522 16:00:26.062906 13930 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0522 16:00:26.063058 13930 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0522 16:00:26.063503 13930 net.cpp:150] Setting up conv10/dw/scale
I0522 16:00:26.063508 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.063517 13930 net.cpp:165] Memory required for data: 305070112
I0522 16:00:26.063521 13930 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0522 16:00:26.063529 13930 net.cpp:100] Creating Layer conv10/dw/relu
I0522 16:00:26.063531 13930 net.cpp:434] conv10/dw/relu <- conv10/dw
I0522 16:00:26.063535 13930 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0522 16:00:26.063972 13930 net.cpp:150] Setting up conv10/dw/relu
I0522 16:00:26.063985 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.063987 13930 net.cpp:165] Memory required for data: 306675744
I0522 16:00:26.063989 13930 layer_factory.hpp:77] Creating layer conv10
I0522 16:00:26.063995 13930 net.cpp:100] Creating Layer conv10
I0522 16:00:26.063998 13930 net.cpp:434] conv10 <- conv10/dw
I0522 16:00:26.064002 13930 net.cpp:408] conv10 -> conv10
I0522 16:00:26.068162 13930 net.cpp:150] Setting up conv10
I0522 16:00:26.068172 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.068176 13930 net.cpp:165] Memory required for data: 308281376
I0522 16:00:26.068179 13930 layer_factory.hpp:77] Creating layer conv10/bn
I0522 16:00:26.068183 13930 net.cpp:100] Creating Layer conv10/bn
I0522 16:00:26.068186 13930 net.cpp:434] conv10/bn <- conv10
I0522 16:00:26.068189 13930 net.cpp:395] conv10/bn -> conv10 (in-place)
I0522 16:00:26.068961 13930 net.cpp:150] Setting up conv10/bn
I0522 16:00:26.068967 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.068969 13930 net.cpp:165] Memory required for data: 309887008
I0522 16:00:26.068974 13930 layer_factory.hpp:77] Creating layer conv10/scale
I0522 16:00:26.068979 13930 net.cpp:100] Creating Layer conv10/scale
I0522 16:00:26.068980 13930 net.cpp:434] conv10/scale <- conv10
I0522 16:00:26.068984 13930 net.cpp:395] conv10/scale -> conv10 (in-place)
I0522 16:00:26.069099 13930 layer_factory.hpp:77] Creating layer conv10/scale
I0522 16:00:26.069514 13930 net.cpp:150] Setting up conv10/scale
I0522 16:00:26.069520 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.069522 13930 net.cpp:165] Memory required for data: 311492640
I0522 16:00:26.069526 13930 layer_factory.hpp:77] Creating layer conv10/relu
I0522 16:00:26.069530 13930 net.cpp:100] Creating Layer conv10/relu
I0522 16:00:26.069531 13930 net.cpp:434] conv10/relu <- conv10
I0522 16:00:26.069535 13930 net.cpp:395] conv10/relu -> conv10 (in-place)
I0522 16:00:26.070408 13930 net.cpp:150] Setting up conv10/relu
I0522 16:00:26.070417 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.070420 13930 net.cpp:165] Memory required for data: 313098272
I0522 16:00:26.070421 13930 layer_factory.hpp:77] Creating layer conv11/dw
I0522 16:00:26.070430 13930 net.cpp:100] Creating Layer conv11/dw
I0522 16:00:26.070431 13930 net.cpp:434] conv11/dw <- conv10
I0522 16:00:26.070436 13930 net.cpp:408] conv11/dw -> conv11/dw
I0522 16:00:26.071188 13930 net.cpp:150] Setting up conv11/dw
I0522 16:00:26.071194 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.071197 13930 net.cpp:165] Memory required for data: 314703904
I0522 16:00:26.071200 13930 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0522 16:00:26.071203 13930 net.cpp:100] Creating Layer conv11/dw/bn
I0522 16:00:26.071205 13930 net.cpp:434] conv11/dw/bn <- conv11/dw
I0522 16:00:26.071209 13930 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0522 16:00:26.071976 13930 net.cpp:150] Setting up conv11/dw/bn
I0522 16:00:26.071982 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.071985 13930 net.cpp:165] Memory required for data: 316309536
I0522 16:00:26.072001 13930 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0522 16:00:26.072007 13930 net.cpp:100] Creating Layer conv11/dw/scale
I0522 16:00:26.072010 13930 net.cpp:434] conv11/dw/scale <- conv11/dw
I0522 16:00:26.072012 13930 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0522 16:00:26.072127 13930 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0522 16:00:26.072543 13930 net.cpp:150] Setting up conv11/dw/scale
I0522 16:00:26.072548 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.072557 13930 net.cpp:165] Memory required for data: 317915168
I0522 16:00:26.072561 13930 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0522 16:00:26.072566 13930 net.cpp:100] Creating Layer conv11/dw/relu
I0522 16:00:26.072568 13930 net.cpp:434] conv11/dw/relu <- conv11/dw
I0522 16:00:26.072571 13930 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0522 16:00:26.072970 13930 net.cpp:150] Setting up conv11/dw/relu
I0522 16:00:26.072978 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.072980 13930 net.cpp:165] Memory required for data: 319520800
I0522 16:00:26.072983 13930 layer_factory.hpp:77] Creating layer conv11
I0522 16:00:26.072989 13930 net.cpp:100] Creating Layer conv11
I0522 16:00:26.072993 13930 net.cpp:434] conv11 <- conv11/dw
I0522 16:00:26.072999 13930 net.cpp:408] conv11 -> conv11
I0522 16:00:26.077468 13930 net.cpp:150] Setting up conv11
I0522 16:00:26.077478 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.077481 13930 net.cpp:165] Memory required for data: 321126432
I0522 16:00:26.077484 13930 layer_factory.hpp:77] Creating layer conv11/bn
I0522 16:00:26.077489 13930 net.cpp:100] Creating Layer conv11/bn
I0522 16:00:26.077492 13930 net.cpp:434] conv11/bn <- conv11
I0522 16:00:26.077497 13930 net.cpp:395] conv11/bn -> conv11 (in-place)
I0522 16:00:26.078270 13930 net.cpp:150] Setting up conv11/bn
I0522 16:00:26.078275 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.078279 13930 net.cpp:165] Memory required for data: 322732064
I0522 16:00:26.078282 13930 layer_factory.hpp:77] Creating layer conv11/scale
I0522 16:00:26.078287 13930 net.cpp:100] Creating Layer conv11/scale
I0522 16:00:26.078289 13930 net.cpp:434] conv11/scale <- conv11
I0522 16:00:26.078294 13930 net.cpp:395] conv11/scale -> conv11 (in-place)
I0522 16:00:26.078406 13930 layer_factory.hpp:77] Creating layer conv11/scale
I0522 16:00:26.078827 13930 net.cpp:150] Setting up conv11/scale
I0522 16:00:26.078833 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.078835 13930 net.cpp:165] Memory required for data: 324337696
I0522 16:00:26.078840 13930 layer_factory.hpp:77] Creating layer conv11/relu
I0522 16:00:26.078843 13930 net.cpp:100] Creating Layer conv11/relu
I0522 16:00:26.078845 13930 net.cpp:434] conv11/relu <- conv11
I0522 16:00:26.078850 13930 net.cpp:395] conv11/relu -> conv11 (in-place)
I0522 16:00:26.079695 13930 net.cpp:150] Setting up conv11/relu
I0522 16:00:26.079704 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:26.079706 13930 net.cpp:165] Memory required for data: 325943328
I0522 16:00:26.079710 13930 layer_factory.hpp:77] Creating layer conv12/dw
I0522 16:00:26.079715 13930 net.cpp:100] Creating Layer conv12/dw
I0522 16:00:26.079717 13930 net.cpp:434] conv12/dw <- conv11
I0522 16:00:26.079722 13930 net.cpp:408] conv12/dw -> conv12/dw
I0522 16:00:27.230203 13930 net.cpp:150] Setting up conv12/dw
I0522 16:00:27.230221 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:27.230224 13930 net.cpp:165] Memory required for data: 327548960
I0522 16:00:27.230231 13930 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0522 16:00:27.230237 13930 net.cpp:100] Creating Layer conv12/dw/bn
I0522 16:00:27.230240 13930 net.cpp:434] conv12/dw/bn <- conv12/dw
I0522 16:00:27.230245 13930 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0522 16:00:27.230923 13930 net.cpp:150] Setting up conv12/dw/bn
I0522 16:00:27.230931 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:27.230932 13930 net.cpp:165] Memory required for data: 329154592
I0522 16:00:27.230937 13930 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0522 16:00:27.230942 13930 net.cpp:100] Creating Layer conv12/dw/scale
I0522 16:00:27.230944 13930 net.cpp:434] conv12/dw/scale <- conv12/dw
I0522 16:00:27.230947 13930 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0522 16:00:27.231076 13930 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0522 16:00:27.231513 13930 net.cpp:150] Setting up conv12/dw/scale
I0522 16:00:27.231519 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:27.231530 13930 net.cpp:165] Memory required for data: 330760224
I0522 16:00:27.231534 13930 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0522 16:00:27.231539 13930 net.cpp:100] Creating Layer conv12/dw/relu
I0522 16:00:27.231541 13930 net.cpp:434] conv12/dw/relu <- conv12/dw
I0522 16:00:27.231545 13930 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0522 16:00:27.234939 13930 net.cpp:150] Setting up conv12/dw/relu
I0522 16:00:27.234949 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:27.234952 13930 net.cpp:165] Memory required for data: 332365856
I0522 16:00:27.234954 13930 layer_factory.hpp:77] Creating layer conv12/dw_conv12/dw/relu_0_split
I0522 16:00:27.234959 13930 net.cpp:100] Creating Layer conv12/dw_conv12/dw/relu_0_split
I0522 16:00:27.234961 13930 net.cpp:434] conv12/dw_conv12/dw/relu_0_split <- conv12/dw
I0522 16:00:27.234966 13930 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_0
I0522 16:00:27.234972 13930 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_1
I0522 16:00:27.234982 13930 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_2
I0522 16:00:27.235091 13930 net.cpp:150] Setting up conv12/dw_conv12/dw/relu_0_split
I0522 16:00:27.235097 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:27.235100 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:27.235103 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:27.235105 13930 net.cpp:165] Memory required for data: 337182752
I0522 16:00:27.235107 13930 layer_factory.hpp:77] Creating layer sample_pooling
I0522 16:00:27.235116 13930 net.cpp:100] Creating Layer sample_pooling
I0522 16:00:27.235118 13930 net.cpp:434] sample_pooling <- conv12/dw_conv12/dw/relu_0_split_0
I0522 16:00:27.235122 13930 net.cpp:408] sample_pooling -> sample_pooling
I0522 16:00:28.633829 13930 net.cpp:150] Setting up sample_pooling
I0522 16:00:28.633846 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:28.633849 13930 net.cpp:165] Memory required for data: 337584160
I0522 16:00:28.633855 13930 layer_factory.hpp:77] Creating layer conv12
I0522 16:00:28.633864 13930 net.cpp:100] Creating Layer conv12
I0522 16:00:28.633867 13930 net.cpp:434] conv12 <- sample_pooling
I0522 16:00:28.633874 13930 net.cpp:408] conv12 -> conv12
I0522 16:00:28.640610 13930 net.cpp:150] Setting up conv12
I0522 16:00:28.640620 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.640624 13930 net.cpp:165] Memory required for data: 338386976
I0522 16:00:28.640627 13930 layer_factory.hpp:77] Creating layer conv12/bn
I0522 16:00:28.640632 13930 net.cpp:100] Creating Layer conv12/bn
I0522 16:00:28.640635 13930 net.cpp:434] conv12/bn <- conv12
I0522 16:00:28.640640 13930 net.cpp:395] conv12/bn -> conv12 (in-place)
I0522 16:00:28.641851 13930 net.cpp:150] Setting up conv12/bn
I0522 16:00:28.641856 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.641860 13930 net.cpp:165] Memory required for data: 339189792
I0522 16:00:28.641863 13930 layer_factory.hpp:77] Creating layer conv12/scale
I0522 16:00:28.641870 13930 net.cpp:100] Creating Layer conv12/scale
I0522 16:00:28.641871 13930 net.cpp:434] conv12/scale <- conv12
I0522 16:00:28.641875 13930 net.cpp:395] conv12/scale -> conv12 (in-place)
I0522 16:00:28.642079 13930 layer_factory.hpp:77] Creating layer conv12/scale
I0522 16:00:28.642722 13930 net.cpp:150] Setting up conv12/scale
I0522 16:00:28.642727 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.642729 13930 net.cpp:165] Memory required for data: 339992608
I0522 16:00:28.642733 13930 layer_factory.hpp:77] Creating layer conv12/relu
I0522 16:00:28.642736 13930 net.cpp:100] Creating Layer conv12/relu
I0522 16:00:28.642738 13930 net.cpp:434] conv12/relu <- conv12
I0522 16:00:28.642743 13930 net.cpp:395] conv12/relu -> conv12 (in-place)
I0522 16:00:28.643172 13930 net.cpp:150] Setting up conv12/relu
I0522 16:00:28.643179 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.643191 13930 net.cpp:165] Memory required for data: 340795424
I0522 16:00:28.643194 13930 layer_factory.hpp:77] Creating layer conv13/dw
I0522 16:00:28.643201 13930 net.cpp:100] Creating Layer conv13/dw
I0522 16:00:28.643204 13930 net.cpp:434] conv13/dw <- conv12
I0522 16:00:28.643208 13930 net.cpp:408] conv13/dw -> conv13/dw
I0522 16:00:28.644338 13930 net.cpp:150] Setting up conv13/dw
I0522 16:00:28.644345 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.644346 13930 net.cpp:165] Memory required for data: 341598240
I0522 16:00:28.644349 13930 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0522 16:00:28.644354 13930 net.cpp:100] Creating Layer conv13/dw/bn
I0522 16:00:28.644356 13930 net.cpp:434] conv13/dw/bn <- conv13/dw
I0522 16:00:28.644359 13930 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0522 16:00:28.645684 13930 net.cpp:150] Setting up conv13/dw/bn
I0522 16:00:28.645689 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.645691 13930 net.cpp:165] Memory required for data: 342401056
I0522 16:00:28.645695 13930 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0522 16:00:28.645700 13930 net.cpp:100] Creating Layer conv13/dw/scale
I0522 16:00:28.645702 13930 net.cpp:434] conv13/dw/scale <- conv13/dw
I0522 16:00:28.645706 13930 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0522 16:00:28.645910 13930 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0522 16:00:28.646559 13930 net.cpp:150] Setting up conv13/dw/scale
I0522 16:00:28.646565 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.646569 13930 net.cpp:165] Memory required for data: 343203872
I0522 16:00:28.646572 13930 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0522 16:00:28.646579 13930 net.cpp:100] Creating Layer conv13/dw/relu
I0522 16:00:28.646580 13930 net.cpp:434] conv13/dw/relu <- conv13/dw
I0522 16:00:28.646584 13930 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0522 16:00:28.647819 13930 net.cpp:150] Setting up conv13/dw/relu
I0522 16:00:28.647828 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.647830 13930 net.cpp:165] Memory required for data: 344006688
I0522 16:00:28.647833 13930 layer_factory.hpp:77] Creating layer conv13
I0522 16:00:28.647840 13930 net.cpp:100] Creating Layer conv13
I0522 16:00:28.647843 13930 net.cpp:434] conv13 <- conv13/dw
I0522 16:00:28.647847 13930 net.cpp:408] conv13 -> conv13
I0522 16:00:28.657872 13930 net.cpp:150] Setting up conv13
I0522 16:00:28.657883 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.657886 13930 net.cpp:165] Memory required for data: 344809504
I0522 16:00:28.657891 13930 layer_factory.hpp:77] Creating layer conv13/bn
I0522 16:00:28.657894 13930 net.cpp:100] Creating Layer conv13/bn
I0522 16:00:28.657897 13930 net.cpp:434] conv13/bn <- conv13
I0522 16:00:28.657902 13930 net.cpp:395] conv13/bn -> conv13 (in-place)
I0522 16:00:28.659123 13930 net.cpp:150] Setting up conv13/bn
I0522 16:00:28.659129 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.659132 13930 net.cpp:165] Memory required for data: 345612320
I0522 16:00:28.659135 13930 layer_factory.hpp:77] Creating layer conv13/scale
I0522 16:00:28.659140 13930 net.cpp:100] Creating Layer conv13/scale
I0522 16:00:28.659142 13930 net.cpp:434] conv13/scale <- conv13
I0522 16:00:28.659147 13930 net.cpp:395] conv13/scale -> conv13 (in-place)
I0522 16:00:28.659349 13930 layer_factory.hpp:77] Creating layer conv13/scale
I0522 16:00:28.660038 13930 net.cpp:150] Setting up conv13/scale
I0522 16:00:28.660045 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.660048 13930 net.cpp:165] Memory required for data: 346415136
I0522 16:00:28.660050 13930 layer_factory.hpp:77] Creating layer conv13/relu
I0522 16:00:28.660054 13930 net.cpp:100] Creating Layer conv13/relu
I0522 16:00:28.660058 13930 net.cpp:434] conv13/relu <- conv13
I0522 16:00:28.660060 13930 net.cpp:395] conv13/relu -> conv13 (in-place)
I0522 16:00:28.660615 13930 net.cpp:150] Setting up conv13/relu
I0522 16:00:28.660630 13930 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0522 16:00:28.660634 13930 net.cpp:165] Memory required for data: 347217952
I0522 16:00:28.660635 13930 layer_factory.hpp:77] Creating layer ip6
I0522 16:00:28.660642 13930 net.cpp:100] Creating Layer ip6
I0522 16:00:28.660645 13930 net.cpp:434] ip6 <- conv13
I0522 16:00:28.660651 13930 net.cpp:408] ip6 -> ip6
I0522 16:00:28.679805 13930 net.cpp:150] Setting up ip6
I0522 16:00:28.679821 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:28.679822 13930 net.cpp:165] Memory required for data: 347418656
I0522 16:00:28.679829 13930 layer_factory.hpp:77] Creating layer relu6
I0522 16:00:28.679836 13930 net.cpp:100] Creating Layer relu6
I0522 16:00:28.679838 13930 net.cpp:434] relu6 <- ip6
I0522 16:00:28.679843 13930 net.cpp:395] relu6 -> ip6 (in-place)
I0522 16:00:28.680358 13930 net.cpp:150] Setting up relu6
I0522 16:00:28.680367 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:28.680369 13930 net.cpp:165] Memory required for data: 347619360
I0522 16:00:28.680371 13930 layer_factory.hpp:77] Creating layer ip7
I0522 16:00:28.680380 13930 net.cpp:100] Creating Layer ip7
I0522 16:00:28.680382 13930 net.cpp:434] ip7 <- ip6
I0522 16:00:28.680388 13930 net.cpp:408] ip7 -> ip7
I0522 16:00:28.684440 13930 net.cpp:150] Setting up ip7
I0522 16:00:28.684449 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:28.684453 13930 net.cpp:165] Memory required for data: 348020768
I0522 16:00:28.684458 13930 layer_factory.hpp:77] Creating layer relu7
I0522 16:00:28.684461 13930 net.cpp:100] Creating Layer relu7
I0522 16:00:28.684464 13930 net.cpp:434] relu7 <- ip7
I0522 16:00:28.684468 13930 net.cpp:395] relu7 -> ip7 (in-place)
I0522 16:00:28.685264 13930 net.cpp:150] Setting up relu7
I0522 16:00:28.685272 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:28.685274 13930 net.cpp:165] Memory required for data: 348422176
I0522 16:00:28.685277 13930 layer_factory.hpp:77] Creating layer ip7_relu7_0_split
I0522 16:00:28.685282 13930 net.cpp:100] Creating Layer ip7_relu7_0_split
I0522 16:00:28.685286 13930 net.cpp:434] ip7_relu7_0_split <- ip7
I0522 16:00:28.685289 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_0
I0522 16:00:28.685295 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_1
I0522 16:00:28.685299 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_2
I0522 16:00:28.685303 13930 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_3
I0522 16:00:28.685633 13930 net.cpp:150] Setting up ip7_relu7_0_split
I0522 16:00:28.685638 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:28.685642 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:28.685644 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:28.685647 13930 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0522 16:00:28.685648 13930 net.cpp:165] Memory required for data: 350027808
I0522 16:00:28.685650 13930 layer_factory.hpp:77] Creating layer conv6_1
I0522 16:00:28.685657 13930 net.cpp:100] Creating Layer conv6_1
I0522 16:00:28.685659 13930 net.cpp:434] conv6_1 <- ip7_relu7_0_split_0
I0522 16:00:28.685665 13930 net.cpp:408] conv6_1 -> conv6_1
I0522 16:00:28.693732 13930 net.cpp:150] Setting up conv6_1
I0522 16:00:28.693744 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:28.693747 13930 net.cpp:165] Memory required for data: 350228512
I0522 16:00:28.693753 13930 layer_factory.hpp:77] Creating layer conv6_1_relu
I0522 16:00:28.693786 13930 net.cpp:100] Creating Layer conv6_1_relu
I0522 16:00:28.693789 13930 net.cpp:434] conv6_1_relu <- conv6_1
I0522 16:00:28.693794 13930 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0522 16:00:28.694296 13930 net.cpp:150] Setting up conv6_1_relu
I0522 16:00:28.694304 13930 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0522 16:00:28.694321 13930 net.cpp:165] Memory required for data: 350429216
I0522 16:00:28.694324 13930 layer_factory.hpp:77] Creating layer conv6_2
I0522 16:00:28.694331 13930 net.cpp:100] Creating Layer conv6_2
I0522 16:00:28.694336 13930 net.cpp:434] conv6_2 <- conv6_1
I0522 16:00:28.694350 13930 net.cpp:408] conv6_2 -> conv6_2
I0522 16:00:28.700520 13930 net.cpp:150] Setting up conv6_2
I0522 16:00:28.700531 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:28.700533 13930 net.cpp:165] Memory required for data: 350479392
I0522 16:00:28.700538 13930 layer_factory.hpp:77] Creating layer conv6_2_relu
I0522 16:00:28.700542 13930 net.cpp:100] Creating Layer conv6_2_relu
I0522 16:00:28.700546 13930 net.cpp:434] conv6_2_relu <- conv6_2
I0522 16:00:28.700551 13930 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0522 16:00:28.701386 13930 net.cpp:150] Setting up conv6_2_relu
I0522 16:00:28.701395 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:28.701397 13930 net.cpp:165] Memory required for data: 350529568
I0522 16:00:28.701400 13930 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0522 16:00:28.701404 13930 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0522 16:00:28.701406 13930 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0522 16:00:28.701412 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0522 16:00:28.701417 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0522 16:00:28.701423 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0522 16:00:28.701427 13930 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0522 16:00:28.701776 13930 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0522 16:00:28.701782 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:28.701786 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:28.701787 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:28.701790 13930 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0522 16:00:28.701792 13930 net.cpp:165] Memory required for data: 350730272
I0522 16:00:28.701794 13930 layer_factory.hpp:77] Creating layer conv7_1
I0522 16:00:28.701802 13930 net.cpp:100] Creating Layer conv7_1
I0522 16:00:28.701805 13930 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0522 16:00:28.701810 13930 net.cpp:408] conv7_1 -> conv7_1
I0522 16:00:28.705210 13930 net.cpp:150] Setting up conv7_1
I0522 16:00:28.705219 13930 net.cpp:157] Top shape: 1 128 7 7 (6272)
I0522 16:00:28.705222 13930 net.cpp:165] Memory required for data: 350755360
I0522 16:00:28.705227 13930 layer_factory.hpp:77] Creating layer conv7_1_relu
I0522 16:00:28.705231 13930 net.cpp:100] Creating Layer conv7_1_relu
I0522 16:00:28.705233 13930 net.cpp:434] conv7_1_relu <- conv7_1
I0522 16:00:28.705238 13930 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0522 16:00:28.705687 13930 net.cpp:150] Setting up conv7_1_relu
I0522 16:00:28.705693 13930 net.cpp:157] Top shape: 1 128 7 7 (6272)
I0522 16:00:28.705696 13930 net.cpp:165] Memory required for data: 350780448
I0522 16:00:28.705699 13930 layer_factory.hpp:77] Creating layer conv7_2
I0522 16:00:28.705708 13930 net.cpp:100] Creating Layer conv7_2
I0522 16:00:28.705710 13930 net.cpp:434] conv7_2 <- conv7_1
I0522 16:00:28.705715 13930 net.cpp:408] conv7_2 -> conv7_2
I0522 16:00:28.715273 13930 net.cpp:150] Setting up conv7_2
I0522 16:00:28.715286 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:28.715288 13930 net.cpp:165] Memory required for data: 350796832
I0522 16:00:28.715293 13930 layer_factory.hpp:77] Creating layer conv7_2_relu
I0522 16:00:28.715299 13930 net.cpp:100] Creating Layer conv7_2_relu
I0522 16:00:28.715302 13930 net.cpp:434] conv7_2_relu <- conv7_2
I0522 16:00:28.715306 13930 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0522 16:00:28.715750 13930 net.cpp:150] Setting up conv7_2_relu
I0522 16:00:28.715759 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:28.715760 13930 net.cpp:165] Memory required for data: 350813216
I0522 16:00:28.715764 13930 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0522 16:00:28.715767 13930 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0522 16:00:28.715770 13930 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0522 16:00:28.715783 13930 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0522 16:00:28.715790 13930 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0522 16:00:28.715793 13930 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0522 16:00:28.716033 13930 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0522 16:00:28.716039 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:28.716042 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:28.716045 13930 net.cpp:157] Top shape: 1 256 4 4 (4096)
I0522 16:00:28.716048 13930 net.cpp:165] Memory required for data: 350862368
I0522 16:00:28.716049 13930 layer_factory.hpp:77] Creating layer conv12_norm
I0522 16:00:28.716054 13930 net.cpp:100] Creating Layer conv12_norm
I0522 16:00:28.716058 13930 net.cpp:434] conv12_norm <- conv12/dw_conv12/dw/relu_0_split_1
I0522 16:00:28.716061 13930 net.cpp:408] conv12_norm -> conv12_norm
I0522 16:00:28.717073 13930 net.cpp:150] Setting up conv12_norm
I0522 16:00:28.717079 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:28.717082 13930 net.cpp:165] Memory required for data: 352468000
I0522 16:00:28.717084 13930 layer_factory.hpp:77] Creating layer conv12_norm_conv12_norm_0_split
I0522 16:00:28.717098 13930 net.cpp:100] Creating Layer conv12_norm_conv12_norm_0_split
I0522 16:00:28.717100 13930 net.cpp:434] conv12_norm_conv12_norm_0_split <- conv12_norm
I0522 16:00:28.717104 13930 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_0
I0522 16:00:28.717108 13930 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_1
I0522 16:00:28.717264 13930 net.cpp:150] Setting up conv12_norm_conv12_norm_0_split
I0522 16:00:28.717269 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:28.717272 13930 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0522 16:00:28.717274 13930 net.cpp:165] Memory required for data: 355679264
I0522 16:00:28.717278 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc
I0522 16:00:28.717284 13930 net.cpp:100] Creating Layer conv12_norm_mbox_loc
I0522 16:00:28.717286 13930 net.cpp:434] conv12_norm_mbox_loc <- conv12_norm_conv12_norm_0_split_0
I0522 16:00:28.717291 13930 net.cpp:408] conv12_norm_mbox_loc -> conv12_norm_mbox_loc
I0522 16:00:28.721302 13930 net.cpp:150] Setting up conv12_norm_mbox_loc
I0522 16:00:28.721310 13930 net.cpp:157] Top shape: 1 24 28 28 (18816)
I0522 16:00:28.721312 13930 net.cpp:165] Memory required for data: 355754528
I0522 16:00:28.721318 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_perm
I0522 16:00:28.721323 13930 net.cpp:100] Creating Layer conv12_norm_mbox_loc_perm
I0522 16:00:28.721326 13930 net.cpp:434] conv12_norm_mbox_loc_perm <- conv12_norm_mbox_loc
I0522 16:00:28.721329 13930 net.cpp:408] conv12_norm_mbox_loc_perm -> conv12_norm_mbox_loc_perm
I0522 16:00:28.721868 13930 net.cpp:150] Setting up conv12_norm_mbox_loc_perm
I0522 16:00:28.721874 13930 net.cpp:157] Top shape: 1 28 28 24 (18816)
I0522 16:00:28.721876 13930 net.cpp:165] Memory required for data: 355829792
I0522 16:00:28.721879 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_flat
I0522 16:00:28.721884 13930 net.cpp:100] Creating Layer conv12_norm_mbox_loc_flat
I0522 16:00:28.721885 13930 net.cpp:434] conv12_norm_mbox_loc_flat <- conv12_norm_mbox_loc_perm
I0522 16:00:28.721889 13930 net.cpp:408] conv12_norm_mbox_loc_flat -> conv12_norm_mbox_loc_flat
I0522 16:00:28.721972 13930 net.cpp:150] Setting up conv12_norm_mbox_loc_flat
I0522 16:00:28.721977 13930 net.cpp:157] Top shape: 1 18816 (18816)
I0522 16:00:28.721979 13930 net.cpp:165] Memory required for data: 355905056
I0522 16:00:28.721982 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf
I0522 16:00:28.721987 13930 net.cpp:100] Creating Layer conv12_norm_mbox_conf
I0522 16:00:28.721990 13930 net.cpp:434] conv12_norm_mbox_conf <- conv12_norm_conv12_norm_0_split_1
I0522 16:00:28.721995 13930 net.cpp:408] conv12_norm_mbox_conf -> conv12_norm_mbox_conf
I0522 16:00:28.726763 13930 net.cpp:150] Setting up conv12_norm_mbox_conf
I0522 16:00:28.726771 13930 net.cpp:157] Top shape: 1 36 28 28 (28224)
I0522 16:00:28.726774 13930 net.cpp:165] Memory required for data: 356017952
I0522 16:00:28.726778 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_perm
I0522 16:00:28.726784 13930 net.cpp:100] Creating Layer conv12_norm_mbox_conf_perm
I0522 16:00:28.726788 13930 net.cpp:434] conv12_norm_mbox_conf_perm <- conv12_norm_mbox_conf
I0522 16:00:28.726791 13930 net.cpp:408] conv12_norm_mbox_conf_perm -> conv12_norm_mbox_conf_perm
I0522 16:00:28.727334 13930 net.cpp:150] Setting up conv12_norm_mbox_conf_perm
I0522 16:00:28.727339 13930 net.cpp:157] Top shape: 1 28 28 36 (28224)
I0522 16:00:28.727357 13930 net.cpp:165] Memory required for data: 356130848
I0522 16:00:28.727360 13930 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_flat
I0522 16:00:28.727365 13930 net.cpp:100] Creating Layer conv12_norm_mbox_conf_flat
I0522 16:00:28.727370 13930 net.cpp:434] conv12_norm_mbox_conf_flat <- conv12_norm_mbox_conf_perm
I0522 16:00:28.727375 13930 net.cpp:408] conv12_norm_mbox_conf_flat -> conv12_norm_mbox_conf_flat
I0522 16:00:28.727479 13930 net.cpp:150] Setting up conv12_norm_mbox_conf_flat
I0522 16:00:28.727484 13930 net.cpp:157] Top shape: 1 28224 (28224)
I0522 16:00:28.727488 13930 net.cpp:165] Memory required for data: 356243744
I0522 16:00:28.727489 13930 layer_factory.hpp:77] Creating layer ip7_mbox_loc
I0522 16:00:28.727501 13930 net.cpp:100] Creating Layer ip7_mbox_loc
I0522 16:00:28.727505 13930 net.cpp:434] ip7_mbox_loc <- ip7_relu7_0_split_1
I0522 16:00:28.727510 13930 net.cpp:408] ip7_mbox_loc -> ip7_mbox_loc
I0522 16:00:28.736934 13930 net.cpp:150] Setting up ip7_mbox_loc
I0522 16:00:28.736949 13930 net.cpp:157] Top shape: 1 24 14 14 (4704)
I0522 16:00:28.736951 13930 net.cpp:165] Memory required for data: 356262560
I0522 16:00:28.736958 13930 layer_factory.hpp:77] Creating layer ip7_mbox_loc_perm
I0522 16:00:28.736963 13930 net.cpp:100] Creating Layer ip7_mbox_loc_perm
I0522 16:00:28.736968 13930 net.cpp:434] ip7_mbox_loc_perm <- ip7_mbox_loc
I0522 16:00:28.736972 13930 net.cpp:408] ip7_mbox_loc_perm -> ip7_mbox_loc_perm
I0522 16:00:28.737519 13930 net.cpp:150] Setting up ip7_mbox_loc_perm
I0522 16:00:28.737525 13930 net.cpp:157] Top shape: 1 14 14 24 (4704)
I0522 16:00:28.737527 13930 net.cpp:165] Memory required for data: 356281376
I0522 16:00:28.737529 13930 layer_factory.hpp:77] Creating layer ip7_mbox_loc_flat
I0522 16:00:28.737534 13930 net.cpp:100] Creating Layer ip7_mbox_loc_flat
I0522 16:00:28.737536 13930 net.cpp:434] ip7_mbox_loc_flat <- ip7_mbox_loc_perm
I0522 16:00:28.737540 13930 net.cpp:408] ip7_mbox_loc_flat -> ip7_mbox_loc_flat
I0522 16:00:28.737622 13930 net.cpp:150] Setting up ip7_mbox_loc_flat
I0522 16:00:28.737628 13930 net.cpp:157] Top shape: 1 4704 (4704)
I0522 16:00:28.737630 13930 net.cpp:165] Memory required for data: 356300192
I0522 16:00:28.737632 13930 layer_factory.hpp:77] Creating layer ip7_mbox_conf
I0522 16:00:28.737640 13930 net.cpp:100] Creating Layer ip7_mbox_conf
I0522 16:00:28.737643 13930 net.cpp:434] ip7_mbox_conf <- ip7_relu7_0_split_2
I0522 16:00:28.737648 13930 net.cpp:408] ip7_mbox_conf -> ip7_mbox_conf
I0522 16:00:28.741852 13930 net.cpp:150] Setting up ip7_mbox_conf
I0522 16:00:28.741860 13930 net.cpp:157] Top shape: 1 36 14 14 (7056)
I0522 16:00:28.741863 13930 net.cpp:165] Memory required for data: 356328416
I0522 16:00:28.741868 13930 layer_factory.hpp:77] Creating layer ip7_mbox_conf_perm
I0522 16:00:28.741873 13930 net.cpp:100] Creating Layer ip7_mbox_conf_perm
I0522 16:00:28.741875 13930 net.cpp:434] ip7_mbox_conf_perm <- ip7_mbox_conf
I0522 16:00:28.741879 13930 net.cpp:408] ip7_mbox_conf_perm -> ip7_mbox_conf_perm
I0522 16:00:28.742424 13930 net.cpp:150] Setting up ip7_mbox_conf_perm
I0522 16:00:28.742430 13930 net.cpp:157] Top shape: 1 14 14 36 (7056)
I0522 16:00:28.742432 13930 net.cpp:165] Memory required for data: 356356640
I0522 16:00:28.742434 13930 layer_factory.hpp:77] Creating layer ip7_mbox_conf_flat
I0522 16:00:28.742447 13930 net.cpp:100] Creating Layer ip7_mbox_conf_flat
I0522 16:00:28.742450 13930 net.cpp:434] ip7_mbox_conf_flat <- ip7_mbox_conf_perm
I0522 16:00:28.742455 13930 net.cpp:408] ip7_mbox_conf_flat -> ip7_mbox_conf_flat
I0522 16:00:28.742537 13930 net.cpp:150] Setting up ip7_mbox_conf_flat
I0522 16:00:28.742543 13930 net.cpp:157] Top shape: 1 7056 (7056)
I0522 16:00:28.742545 13930 net.cpp:165] Memory required for data: 356384864
I0522 16:00:28.742547 13930 layer_factory.hpp:77] Creating layer conv12/dw_mbox_priorbox
I0522 16:00:28.742552 13930 net.cpp:100] Creating Layer conv12/dw_mbox_priorbox
I0522 16:00:28.742556 13930 net.cpp:434] conv12/dw_mbox_priorbox <- conv12/dw_conv12/dw/relu_0_split_2
I0522 16:00:28.742559 13930 net.cpp:434] conv12/dw_mbox_priorbox <- data_data_0_split_1
I0522 16:00:28.742564 13930 net.cpp:408] conv12/dw_mbox_priorbox -> conv12/dw_mbox_priorbox
I0522 16:00:28.742648 13930 net.cpp:150] Setting up conv12/dw_mbox_priorbox
I0522 16:00:28.742655 13930 net.cpp:157] Top shape: 1 2 18816 (37632)
I0522 16:00:28.742656 13930 net.cpp:165] Memory required for data: 356535392
I0522 16:00:28.742658 13930 layer_factory.hpp:77] Creating layer ip7_mbox_priorbox
I0522 16:00:28.742662 13930 net.cpp:100] Creating Layer ip7_mbox_priorbox
I0522 16:00:28.742666 13930 net.cpp:434] ip7_mbox_priorbox <- ip7_relu7_0_split_3
I0522 16:00:28.742668 13930 net.cpp:434] ip7_mbox_priorbox <- data_data_0_split_2
I0522 16:00:28.742673 13930 net.cpp:408] ip7_mbox_priorbox -> ip7_mbox_priorbox
I0522 16:00:28.742755 13930 net.cpp:150] Setting up ip7_mbox_priorbox
I0522 16:00:28.742760 13930 net.cpp:157] Top shape: 1 2 4704 (9408)
I0522 16:00:28.742763 13930 net.cpp:165] Memory required for data: 356573024
I0522 16:00:28.742764 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0522 16:00:28.742771 13930 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0522 16:00:28.742774 13930 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0522 16:00:28.742779 13930 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0522 16:00:28.746580 13930 net.cpp:150] Setting up conv6_2_mbox_loc
I0522 16:00:28.746589 13930 net.cpp:157] Top shape: 1 24 7 7 (1176)
I0522 16:00:28.746592 13930 net.cpp:165] Memory required for data: 356577728
I0522 16:00:28.746596 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0522 16:00:28.746601 13930 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0522 16:00:28.746604 13930 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0522 16:00:28.746609 13930 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0522 16:00:28.747153 13930 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0522 16:00:28.747159 13930 net.cpp:157] Top shape: 1 7 7 24 (1176)
I0522 16:00:28.747160 13930 net.cpp:165] Memory required for data: 356582432
I0522 16:00:28.747164 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0522 16:00:28.747166 13930 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0522 16:00:28.747169 13930 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0522 16:00:28.747174 13930 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0522 16:00:28.747257 13930 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0522 16:00:28.747262 13930 net.cpp:157] Top shape: 1 1176 (1176)
I0522 16:00:28.747263 13930 net.cpp:165] Memory required for data: 356587136
I0522 16:00:28.747265 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0522 16:00:28.747272 13930 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0522 16:00:28.747275 13930 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0522 16:00:28.747280 13930 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0522 16:00:28.755319 13930 net.cpp:150] Setting up conv6_2_mbox_conf
I0522 16:00:28.755331 13930 net.cpp:157] Top shape: 1 36 7 7 (1764)
I0522 16:00:28.755333 13930 net.cpp:165] Memory required for data: 356594192
I0522 16:00:28.755338 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0522 16:00:28.755344 13930 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0522 16:00:28.755355 13930 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0522 16:00:28.755360 13930 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0522 16:00:28.755908 13930 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0522 16:00:28.755914 13930 net.cpp:157] Top shape: 1 7 7 36 (1764)
I0522 16:00:28.755916 13930 net.cpp:165] Memory required for data: 356601248
I0522 16:00:28.755918 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0522 16:00:28.755923 13930 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0522 16:00:28.755925 13930 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0522 16:00:28.755929 13930 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0522 16:00:28.756013 13930 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0522 16:00:28.756018 13930 net.cpp:157] Top shape: 1 1764 (1764)
I0522 16:00:28.756021 13930 net.cpp:165] Memory required for data: 356608304
I0522 16:00:28.756022 13930 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0522 16:00:28.756029 13930 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0522 16:00:28.756032 13930 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0522 16:00:28.756036 13930 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0522 16:00:28.756040 13930 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0522 16:00:28.756126 13930 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0522 16:00:28.756131 13930 net.cpp:157] Top shape: 1 2 1176 (2352)
I0522 16:00:28.756134 13930 net.cpp:165] Memory required for data: 356617712
I0522 16:00:28.756135 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0522 16:00:28.756142 13930 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0522 16:00:28.756146 13930 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_0
I0522 16:00:28.756151 13930 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0522 16:00:28.760304 13930 net.cpp:150] Setting up conv7_2_mbox_loc
I0522 16:00:28.760313 13930 net.cpp:157] Top shape: 1 16 4 4 (256)
I0522 16:00:28.760318 13930 net.cpp:165] Memory required for data: 356618736
I0522 16:00:28.760322 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0522 16:00:28.760327 13930 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0522 16:00:28.760331 13930 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0522 16:00:28.760337 13930 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0522 16:00:28.760916 13930 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0522 16:00:28.760921 13930 net.cpp:157] Top shape: 1 4 4 16 (256)
I0522 16:00:28.760923 13930 net.cpp:165] Memory required for data: 356619760
I0522 16:00:28.760926 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0522 16:00:28.760931 13930 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0522 16:00:28.760933 13930 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0522 16:00:28.760938 13930 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0522 16:00:28.761023 13930 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0522 16:00:28.761027 13930 net.cpp:157] Top shape: 1 256 (256)
I0522 16:00:28.761029 13930 net.cpp:165] Memory required for data: 356620784
I0522 16:00:28.761031 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0522 16:00:28.761039 13930 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0522 16:00:28.761041 13930 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_1
I0522 16:00:28.761047 13930 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0522 16:00:28.764925 13930 net.cpp:150] Setting up conv7_2_mbox_conf
I0522 16:00:28.764935 13930 net.cpp:157] Top shape: 1 24 4 4 (384)
I0522 16:00:28.764938 13930 net.cpp:165] Memory required for data: 356622320
I0522 16:00:28.764942 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0522 16:00:28.764947 13930 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0522 16:00:28.764950 13930 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0522 16:00:28.764964 13930 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0522 16:00:28.765511 13930 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0522 16:00:28.765516 13930 net.cpp:157] Top shape: 1 4 4 24 (384)
I0522 16:00:28.765518 13930 net.cpp:165] Memory required for data: 356623856
I0522 16:00:28.765522 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0522 16:00:28.765525 13930 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0522 16:00:28.765529 13930 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0522 16:00:28.765533 13930 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0522 16:00:28.765617 13930 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0522 16:00:28.765622 13930 net.cpp:157] Top shape: 1 384 (384)
I0522 16:00:28.765625 13930 net.cpp:165] Memory required for data: 356625392
I0522 16:00:28.765626 13930 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0522 16:00:28.765633 13930 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0522 16:00:28.765636 13930 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_2
I0522 16:00:28.765640 13930 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0522 16:00:28.765645 13930 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0522 16:00:28.765731 13930 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0522 16:00:28.765735 13930 net.cpp:157] Top shape: 1 2 256 (512)
I0522 16:00:28.765738 13930 net.cpp:165] Memory required for data: 356627440
I0522 16:00:28.765739 13930 layer_factory.hpp:77] Creating layer mbox_loc
I0522 16:00:28.765746 13930 net.cpp:100] Creating Layer mbox_loc
I0522 16:00:28.765749 13930 net.cpp:434] mbox_loc <- conv12_norm_mbox_loc_flat
I0522 16:00:28.765753 13930 net.cpp:434] mbox_loc <- ip7_mbox_loc_flat
I0522 16:00:28.765758 13930 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0522 16:00:28.765761 13930 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0522 16:00:28.765765 13930 net.cpp:408] mbox_loc -> mbox_loc
I0522 16:00:28.765848 13930 net.cpp:150] Setting up mbox_loc
I0522 16:00:28.765852 13930 net.cpp:157] Top shape: 1 24952 (24952)
I0522 16:00:28.765856 13930 net.cpp:165] Memory required for data: 356727248
I0522 16:00:28.765858 13930 layer_factory.hpp:77] Creating layer mbox_conf
I0522 16:00:28.765862 13930 net.cpp:100] Creating Layer mbox_conf
I0522 16:00:28.765866 13930 net.cpp:434] mbox_conf <- conv12_norm_mbox_conf_flat
I0522 16:00:28.765870 13930 net.cpp:434] mbox_conf <- ip7_mbox_conf_flat
I0522 16:00:28.765873 13930 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0522 16:00:28.765877 13930 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0522 16:00:28.765882 13930 net.cpp:408] mbox_conf -> mbox_conf
I0522 16:00:28.765964 13930 net.cpp:150] Setting up mbox_conf
I0522 16:00:28.765969 13930 net.cpp:157] Top shape: 1 37428 (37428)
I0522 16:00:28.765970 13930 net.cpp:165] Memory required for data: 356876960
I0522 16:00:28.765974 13930 layer_factory.hpp:77] Creating layer mbox_priorbox
I0522 16:00:28.765977 13930 net.cpp:100] Creating Layer mbox_priorbox
I0522 16:00:28.765980 13930 net.cpp:434] mbox_priorbox <- conv12/dw_mbox_priorbox
I0522 16:00:28.765985 13930 net.cpp:434] mbox_priorbox <- ip7_mbox_priorbox
I0522 16:00:28.765987 13930 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0522 16:00:28.765991 13930 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0522 16:00:28.765995 13930 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0522 16:00:28.766077 13930 net.cpp:150] Setting up mbox_priorbox
I0522 16:00:28.766083 13930 net.cpp:157] Top shape: 1 2 24952 (49904)
I0522 16:00:28.766085 13930 net.cpp:165] Memory required for data: 357076576
I0522 16:00:28.766088 13930 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0522 16:00:28.766091 13930 net.cpp:100] Creating Layer mbox_conf_reshape
I0522 16:00:28.766094 13930 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0522 16:00:28.766099 13930 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0522 16:00:28.766187 13930 net.cpp:150] Setting up mbox_conf_reshape
I0522 16:00:28.766199 13930 net.cpp:157] Top shape: 1 6238 6 (37428)
I0522 16:00:28.766202 13930 net.cpp:165] Memory required for data: 357226288
I0522 16:00:28.766206 13930 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0522 16:00:28.766209 13930 net.cpp:100] Creating Layer mbox_conf_softmax
I0522 16:00:28.766212 13930 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0522 16:00:28.766216 13930 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0522 16:00:28.767127 13930 net.cpp:150] Setting up mbox_conf_softmax
I0522 16:00:28.767136 13930 net.cpp:157] Top shape: 1 6238 6 (37428)
I0522 16:00:28.767138 13930 net.cpp:165] Memory required for data: 357376000
I0522 16:00:28.767140 13930 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0522 16:00:28.767146 13930 net.cpp:100] Creating Layer mbox_conf_flatten
I0522 16:00:28.767149 13930 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0522 16:00:28.767153 13930 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0522 16:00:28.767236 13930 net.cpp:150] Setting up mbox_conf_flatten
I0522 16:00:28.767241 13930 net.cpp:157] Top shape: 1 37428 (37428)
I0522 16:00:28.767243 13930 net.cpp:165] Memory required for data: 357525712
I0522 16:00:28.767246 13930 layer_factory.hpp:77] Creating layer detection_out
I0522 16:00:28.767254 13930 net.cpp:100] Creating Layer detection_out
I0522 16:00:28.767258 13930 net.cpp:434] detection_out <- mbox_loc
I0522 16:00:28.767261 13930 net.cpp:434] detection_out <- mbox_conf_flatten
I0522 16:00:28.767264 13930 net.cpp:434] detection_out <- mbox_priorbox
I0522 16:00:28.767269 13930 net.cpp:408] detection_out -> detection_out
11111
I0522 16:00:28.767519 13930 net.cpp:150] Setting up detection_out
I0522 16:00:28.767524 13930 net.cpp:157] Top shape: 1 1 1 7 (7)
I0522 16:00:28.767526 13930 net.cpp:165] Memory required for data: 357525740
I0522 16:00:28.767529 13930 layer_factory.hpp:77] Creating layer detection_eval
I0522 16:00:28.767534 13930 net.cpp:100] Creating Layer detection_eval
I0522 16:00:28.767537 13930 net.cpp:434] detection_eval <- detection_out
I0522 16:00:28.767540 13930 net.cpp:434] detection_eval <- label
I0522 16:00:28.767545 13930 net.cpp:408] detection_eval -> detection_eval
I0522 16:00:28.767853 13930 net.cpp:150] Setting up detection_eval
I0522 16:00:28.767858 13930 net.cpp:157] Top shape: 1 1 6 5 (30)
I0522 16:00:28.767861 13930 net.cpp:165] Memory required for data: 357525860
I0522 16:00:28.767863 13930 net.cpp:228] detection_eval does not need backward computation.
I0522 16:00:28.767868 13930 net.cpp:228] detection_out does not need backward computation.
I0522 16:00:28.767874 13930 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0522 16:00:28.767877 13930 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0522 16:00:28.767880 13930 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0522 16:00:28.767884 13930 net.cpp:228] mbox_priorbox does not need backward computation.
I0522 16:00:28.767886 13930 net.cpp:228] mbox_conf does not need backward computation.
I0522 16:00:28.767889 13930 net.cpp:228] mbox_loc does not need backward computation.
I0522 16:00:28.767892 13930 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0522 16:00:28.767896 13930 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0522 16:00:28.767899 13930 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0522 16:00:28.767901 13930 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0522 16:00:28.767904 13930 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0522 16:00:28.767906 13930 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0522 16:00:28.767908 13930 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0522 16:00:28.767911 13930 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0522 16:00:28.767913 13930 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0522 16:00:28.767916 13930 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0522 16:00:28.767925 13930 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0522 16:00:28.767928 13930 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0522 16:00:28.767931 13930 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0522 16:00:28.767935 13930 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0522 16:00:28.767937 13930 net.cpp:228] ip7_mbox_priorbox does not need backward computation.
I0522 16:00:28.767940 13930 net.cpp:228] conv12/dw_mbox_priorbox does not need backward computation.
I0522 16:00:28.767944 13930 net.cpp:228] ip7_mbox_conf_flat does not need backward computation.
I0522 16:00:28.767947 13930 net.cpp:228] ip7_mbox_conf_perm does not need backward computation.
I0522 16:00:28.767951 13930 net.cpp:228] ip7_mbox_conf does not need backward computation.
I0522 16:00:28.767952 13930 net.cpp:228] ip7_mbox_loc_flat does not need backward computation.
I0522 16:00:28.767956 13930 net.cpp:228] ip7_mbox_loc_perm does not need backward computation.
I0522 16:00:28.767959 13930 net.cpp:228] ip7_mbox_loc does not need backward computation.
I0522 16:00:28.767961 13930 net.cpp:228] conv12_norm_mbox_conf_flat does not need backward computation.
I0522 16:00:28.767964 13930 net.cpp:228] conv12_norm_mbox_conf_perm does not need backward computation.
I0522 16:00:28.767966 13930 net.cpp:228] conv12_norm_mbox_conf does not need backward computation.
I0522 16:00:28.767971 13930 net.cpp:228] conv12_norm_mbox_loc_flat does not need backward computation.
I0522 16:00:28.767972 13930 net.cpp:228] conv12_norm_mbox_loc_perm does not need backward computation.
I0522 16:00:28.767974 13930 net.cpp:228] conv12_norm_mbox_loc does not need backward computation.
I0522 16:00:28.767977 13930 net.cpp:228] conv12_norm_conv12_norm_0_split does not need backward computation.
I0522 16:00:28.767980 13930 net.cpp:228] conv12_norm does not need backward computation.
I0522 16:00:28.767983 13930 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0522 16:00:28.767987 13930 net.cpp:228] conv7_2_relu does not need backward computation.
I0522 16:00:28.767988 13930 net.cpp:228] conv7_2 does not need backward computation.
I0522 16:00:28.767992 13930 net.cpp:228] conv7_1_relu does not need backward computation.
I0522 16:00:28.767993 13930 net.cpp:228] conv7_1 does not need backward computation.
I0522 16:00:28.767997 13930 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0522 16:00:28.767999 13930 net.cpp:228] conv6_2_relu does not need backward computation.
I0522 16:00:28.768002 13930 net.cpp:228] conv6_2 does not need backward computation.
I0522 16:00:28.768004 13930 net.cpp:228] conv6_1_relu does not need backward computation.
I0522 16:00:28.768007 13930 net.cpp:228] conv6_1 does not need backward computation.
I0522 16:00:28.768010 13930 net.cpp:228] ip7_relu7_0_split does not need backward computation.
I0522 16:00:28.768014 13930 net.cpp:228] relu7 does not need backward computation.
I0522 16:00:28.768016 13930 net.cpp:228] ip7 does not need backward computation.
I0522 16:00:28.768019 13930 net.cpp:228] relu6 does not need backward computation.
I0522 16:00:28.768021 13930 net.cpp:228] ip6 does not need backward computation.
I0522 16:00:28.768023 13930 net.cpp:228] conv13/relu does not need backward computation.
I0522 16:00:28.768025 13930 net.cpp:228] conv13/scale does not need backward computation.
I0522 16:00:28.768028 13930 net.cpp:228] conv13/bn does not need backward computation.
I0522 16:00:28.768029 13930 net.cpp:228] conv13 does not need backward computation.
I0522 16:00:28.768033 13930 net.cpp:228] conv13/dw/relu does not need backward computation.
I0522 16:00:28.768034 13930 net.cpp:228] conv13/dw/scale does not need backward computation.
I0522 16:00:28.768036 13930 net.cpp:228] conv13/dw/bn does not need backward computation.
I0522 16:00:28.768038 13930 net.cpp:228] conv13/dw does not need backward computation.
I0522 16:00:28.768041 13930 net.cpp:228] conv12/relu does not need backward computation.
I0522 16:00:28.768049 13930 net.cpp:228] conv12/scale does not need backward computation.
I0522 16:00:28.768050 13930 net.cpp:228] conv12/bn does not need backward computation.
I0522 16:00:28.768052 13930 net.cpp:228] conv12 does not need backward computation.
I0522 16:00:28.768055 13930 net.cpp:228] sample_pooling does not need backward computation.
I0522 16:00:28.768057 13930 net.cpp:228] conv12/dw_conv12/dw/relu_0_split does not need backward computation.
I0522 16:00:28.768060 13930 net.cpp:228] conv12/dw/relu does not need backward computation.
I0522 16:00:28.768062 13930 net.cpp:228] conv12/dw/scale does not need backward computation.
I0522 16:00:28.768064 13930 net.cpp:228] conv12/dw/bn does not need backward computation.
I0522 16:00:28.768066 13930 net.cpp:228] conv12/dw does not need backward computation.
I0522 16:00:28.768069 13930 net.cpp:228] conv11/relu does not need backward computation.
I0522 16:00:28.768071 13930 net.cpp:228] conv11/scale does not need backward computation.
I0522 16:00:28.768074 13930 net.cpp:228] conv11/bn does not need backward computation.
I0522 16:00:28.768076 13930 net.cpp:228] conv11 does not need backward computation.
I0522 16:00:28.768079 13930 net.cpp:228] conv11/dw/relu does not need backward computation.
I0522 16:00:28.768081 13930 net.cpp:228] conv11/dw/scale does not need backward computation.
I0522 16:00:28.768083 13930 net.cpp:228] conv11/dw/bn does not need backward computation.
I0522 16:00:28.768085 13930 net.cpp:228] conv11/dw does not need backward computation.
I0522 16:00:28.768087 13930 net.cpp:228] conv10/relu does not need backward computation.
I0522 16:00:28.768090 13930 net.cpp:228] conv10/scale does not need backward computation.
I0522 16:00:28.768092 13930 net.cpp:228] conv10/bn does not need backward computation.
I0522 16:00:28.768095 13930 net.cpp:228] conv10 does not need backward computation.
I0522 16:00:28.768096 13930 net.cpp:228] conv10/dw/relu does not need backward computation.
I0522 16:00:28.768098 13930 net.cpp:228] conv10/dw/scale does not need backward computation.
I0522 16:00:28.768100 13930 net.cpp:228] conv10/dw/bn does not need backward computation.
I0522 16:00:28.768102 13930 net.cpp:228] conv10/dw does not need backward computation.
I0522 16:00:28.768105 13930 net.cpp:228] conv9/relu does not need backward computation.
I0522 16:00:28.768107 13930 net.cpp:228] conv9/scale does not need backward computation.
I0522 16:00:28.768110 13930 net.cpp:228] conv9/bn does not need backward computation.
I0522 16:00:28.768111 13930 net.cpp:228] conv9 does not need backward computation.
I0522 16:00:28.768115 13930 net.cpp:228] conv9/dw/relu does not need backward computation.
I0522 16:00:28.768116 13930 net.cpp:228] conv9/dw/scale does not need backward computation.
I0522 16:00:28.768118 13930 net.cpp:228] conv9/dw/bn does not need backward computation.
I0522 16:00:28.768121 13930 net.cpp:228] conv9/dw does not need backward computation.
I0522 16:00:28.768122 13930 net.cpp:228] conv8/relu does not need backward computation.
I0522 16:00:28.768126 13930 net.cpp:228] conv8/scale does not need backward computation.
I0522 16:00:28.768127 13930 net.cpp:228] conv8/bn does not need backward computation.
I0522 16:00:28.768129 13930 net.cpp:228] conv8 does not need backward computation.
I0522 16:00:28.768131 13930 net.cpp:228] conv8/dw/relu does not need backward computation.
I0522 16:00:28.768133 13930 net.cpp:228] conv8/dw/scale does not need backward computation.
I0522 16:00:28.768136 13930 net.cpp:228] conv8/dw/bn does not need backward computation.
I0522 16:00:28.768138 13930 net.cpp:228] conv8/dw does not need backward computation.
I0522 16:00:28.768141 13930 net.cpp:228] conv7/relu does not need backward computation.
I0522 16:00:28.768142 13930 net.cpp:228] conv7/scale does not need backward computation.
I0522 16:00:28.768144 13930 net.cpp:228] conv7/bn does not need backward computation.
I0522 16:00:28.768146 13930 net.cpp:228] conv7 does not need backward computation.
I0522 16:00:28.768148 13930 net.cpp:228] conv7/dw/relu does not need backward computation.
I0522 16:00:28.768154 13930 net.cpp:228] conv7/dw/scale does not need backward computation.
I0522 16:00:28.768157 13930 net.cpp:228] conv7/dw/bn does not need backward computation.
I0522 16:00:28.768159 13930 net.cpp:228] conv7/dw does not need backward computation.
I0522 16:00:28.768162 13930 net.cpp:228] conv6/relu does not need backward computation.
I0522 16:00:28.768164 13930 net.cpp:228] conv6/scale does not need backward computation.
I0522 16:00:28.768167 13930 net.cpp:228] conv6/bn does not need backward computation.
I0522 16:00:28.768168 13930 net.cpp:228] conv6 does not need backward computation.
I0522 16:00:28.768172 13930 net.cpp:228] conv6/dw/relu does not need backward computation.
I0522 16:00:28.768173 13930 net.cpp:228] conv6/dw/scale does not need backward computation.
I0522 16:00:28.768177 13930 net.cpp:228] conv6/dw/bn does not need backward computation.
I0522 16:00:28.768178 13930 net.cpp:228] conv6/dw does not need backward computation.
I0522 16:00:28.768180 13930 net.cpp:228] conv5/relu does not need backward computation.
I0522 16:00:28.768183 13930 net.cpp:228] conv5/scale does not need backward computation.
I0522 16:00:28.768185 13930 net.cpp:228] conv5/bn does not need backward computation.
I0522 16:00:28.768187 13930 net.cpp:228] conv5 does not need backward computation.
I0522 16:00:28.768189 13930 net.cpp:228] conv5/dw/relu does not need backward computation.
I0522 16:00:28.768191 13930 net.cpp:228] conv5/dw/scale does not need backward computation.
I0522 16:00:28.768194 13930 net.cpp:228] conv5/dw/bn does not need backward computation.
I0522 16:00:28.768196 13930 net.cpp:228] conv5/dw does not need backward computation.
I0522 16:00:28.768198 13930 net.cpp:228] conv4/relu does not need backward computation.
I0522 16:00:28.768200 13930 net.cpp:228] conv4/scale does not need backward computation.
I0522 16:00:28.768203 13930 net.cpp:228] conv4/bn does not need backward computation.
I0522 16:00:28.768205 13930 net.cpp:228] conv4 does not need backward computation.
I0522 16:00:28.768208 13930 net.cpp:228] conv4/dw/relu does not need backward computation.
I0522 16:00:28.768209 13930 net.cpp:228] conv4/dw/scale does not need backward computation.
I0522 16:00:28.768213 13930 net.cpp:228] conv4/dw/bn does not need backward computation.
I0522 16:00:28.768214 13930 net.cpp:228] conv4/dw does not need backward computation.
I0522 16:00:28.768216 13930 net.cpp:228] conv3/relu does not need backward computation.
I0522 16:00:28.768218 13930 net.cpp:228] conv3/scale does not need backward computation.
I0522 16:00:28.768220 13930 net.cpp:228] conv3/bn does not need backward computation.
I0522 16:00:28.768222 13930 net.cpp:228] conv3 does not need backward computation.
I0522 16:00:28.768224 13930 net.cpp:228] conv3/dw/relu does not need backward computation.
I0522 16:00:28.768226 13930 net.cpp:228] conv3/dw/scale does not need backward computation.
I0522 16:00:28.768229 13930 net.cpp:228] conv3/dw/bn does not need backward computation.
I0522 16:00:28.768231 13930 net.cpp:228] conv3/dw does not need backward computation.
I0522 16:00:28.768234 13930 net.cpp:228] conv2/relu does not need backward computation.
I0522 16:00:28.768235 13930 net.cpp:228] conv2/scale does not need backward computation.
I0522 16:00:28.768239 13930 net.cpp:228] conv2/bn does not need backward computation.
I0522 16:00:28.768241 13930 net.cpp:228] conv2 does not need backward computation.
I0522 16:00:28.768244 13930 net.cpp:228] conv2/dw/relu does not need backward computation.
I0522 16:00:28.768245 13930 net.cpp:228] conv2/dw/scale does not need backward computation.
I0522 16:00:28.768249 13930 net.cpp:228] conv2/dw/bn does not need backward computation.
I0522 16:00:28.768250 13930 net.cpp:228] conv2/dw does not need backward computation.
I0522 16:00:28.768252 13930 net.cpp:228] conv1/relu does not need backward computation.
I0522 16:00:28.768254 13930 net.cpp:228] conv1/scale does not need backward computation.
I0522 16:00:28.768256 13930 net.cpp:228] conv1/bn does not need backward computation.
I0522 16:00:28.768260 13930 net.cpp:228] conv1 does not need backward computation.
I0522 16:00:28.768265 13930 net.cpp:228] conv1/dw/relu does not need backward computation.
I0522 16:00:28.768267 13930 net.cpp:228] conv1/dw/scale does not need backward computation.
I0522 16:00:28.768270 13930 net.cpp:228] conv1/dw/bn does not need backward computation.
I0522 16:00:28.768271 13930 net.cpp:228] conv1/dw does not need backward computation.
I0522 16:00:28.768275 13930 net.cpp:228] conv0/relu does not need backward computation.
I0522 16:00:28.768276 13930 net.cpp:228] conv0/scale does not need backward computation.
I0522 16:00:28.768278 13930 net.cpp:228] conv0/bn does not need backward computation.
I0522 16:00:28.768280 13930 net.cpp:228] conv0 does not need backward computation.
I0522 16:00:28.768283 13930 net.cpp:228] data_data_0_split does not need backward computation.
I0522 16:00:28.768286 13930 net.cpp:228] data does not need backward computation.
I0522 16:00:28.768290 13930 net.cpp:270] This network produces output detection_eval
I0522 16:00:28.768352 13930 net.cpp:283] Network initialization done.
I0522 16:00:28.768647 13930 solver.cpp:75] Solver scaffolding done.
I0522 16:00:28.812001 13930 caffe.cpp:155] Finetuning from mobilessd_step1/step1_iter_30000.caffemodel
I0522 16:00:28.824322 13930 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/step1_iter_30000.caffemodel
I0522 16:00:28.824347 13930 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0522 16:00:28.836235 13930 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/step1_iter_30000.caffemodel
I0522 16:00:28.836261 13930 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0522 16:00:28.840153 13930 net.cpp:761] Ignoring source layer mbox_loss
I0522 16:00:28.840332 13930 caffe.cpp:251] Starting Optimization
I0522 16:00:28.840339 13930 solver.cpp:294] Solving MobileNet-SSD
I0522 16:00:28.840342 13930 solver.cpp:295] Learning Rate Policy: multistep
I0522 16:00:29.085636 13930 solver.cpp:243] Iteration 0, loss = 5.60837
I0522 16:00:29.085657 13930 solver.cpp:259]     Train net output #0: mbox_loss = 5.60837 (* 1 = 5.60837 loss)
I0522 16:00:29.085666 13930 sgd_solver.cpp:138] Iteration 0, lr = 1e-05
I0522 16:00:47.456823 13930 solver.cpp:243] Iteration 100, loss = 6.24879
I0522 16:00:47.456859 13930 solver.cpp:259]     Train net output #0: mbox_loss = 6.67346 (* 1 = 6.67346 loss)
I0522 16:00:47.456864 13930 sgd_solver.cpp:138] Iteration 100, lr = 1e-05
I0522 16:01:06.030973 13930 solver.cpp:243] Iteration 200, loss = 5.87215
I0522 16:01:06.031034 13930 solver.cpp:259]     Train net output #0: mbox_loss = 4.70966 (* 1 = 4.70966 loss)
I0522 16:01:06.031039 13930 sgd_solver.cpp:138] Iteration 200, lr = 1e-05
I0522 16:01:25.045246 13930 solver.cpp:243] Iteration 300, loss = 5.93538
I0522 16:01:25.045266 13930 solver.cpp:259]     Train net output #0: mbox_loss = 7.49367 (* 1 = 7.49367 loss)
I0522 16:01:25.045289 13930 sgd_solver.cpp:138] Iteration 300, lr = 1e-05
I0522 16:01:43.967660 13930 solver.cpp:243] Iteration 400, loss = 5.17757
I0522 16:01:43.967761 13930 solver.cpp:259]     Train net output #0: mbox_loss = 6.37968 (* 1 = 6.37968 loss)
I0522 16:01:43.967767 13930 sgd_solver.cpp:138] Iteration 400, lr = 1e-05
I0522 16:02:02.651579 13930 solver.cpp:243] Iteration 500, loss = 4.28733
I0522 16:02:02.651600 13930 solver.cpp:259]     Train net output #0: mbox_loss = 6.26334 (* 1 = 6.26334 loss)
I0522 16:02:02.651605 13930 sgd_solver.cpp:138] Iteration 500, lr = 1e-05
I0522 16:02:21.385757 13930 solver.cpp:243] Iteration 600, loss = 4.49615
I0522 16:02:21.385890 13930 solver.cpp:259]     Train net output #0: mbox_loss = 5.0493 (* 1 = 5.0493 loss)
I0522 16:02:21.385895 13930 sgd_solver.cpp:138] Iteration 600, lr = 1e-05
I0522 16:02:40.168239 13930 solver.cpp:243] Iteration 700, loss = 5.68969
I0522 16:02:40.168258 13930 solver.cpp:259]     Train net output #0: mbox_loss = 6.59336 (* 1 = 6.59336 loss)
I0522 16:02:40.168262 13930 sgd_solver.cpp:138] Iteration 700, lr = 1e-05
I0522 16:02:58.947533 13930 solver.cpp:243] Iteration 800, loss = 3.7321
I0522 16:02:58.947639 13930 solver.cpp:259]     Train net output #0: mbox_loss = 5.00956 (* 1 = 5.00956 loss)
I0522 16:02:58.947644 13930 sgd_solver.cpp:138] Iteration 800, lr = 1e-05
I0522 16:03:17.739898 13930 solver.cpp:243] Iteration 900, loss = 6.19468
I0522 16:03:17.739918 13930 solver.cpp:259]     Train net output #0: mbox_loss = 6.19454 (* 1 = 6.19454 loss)
I0522 16:03:17.739923 13930 sgd_solver.cpp:138] Iteration 900, lr = 1e-05
I0522 16:03:36.371129 13930 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_1000.caffemodel
I0522 16:03:36.481415 13930 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_1000.solverstate
I0522 16:03:36.521381 13930 solver.cpp:433] Iteration 1000, Testing net (#0)
I0522 16:03:36.527462 13930 net.cpp:693] Ignoring source layer mbox_loss
I0522 16:03:43.233450 13930 solver.cpp:546]     Test net output #0: detection_eval = 0.131515
I0522 16:03:43.396878 13930 solver.cpp:243] Iteration 1000, loss = 5.45434
I0522 16:03:43.396898 13930 solver.cpp:259]     Train net output #0: mbox_loss = 4.98522 (* 1 = 4.98522 loss)
I0522 16:03:43.396903 13930 sgd_solver.cpp:138] Iteration 1000, lr = 1e-05
I0522 16:04:02.981158 13930 solver.cpp:243] Iteration 1100, loss = 4.68742
I0522 16:04:02.981179 13930 solver.cpp:259]     Train net output #0: mbox_loss = 6.44567 (* 1 = 6.44567 loss)
I0522 16:04:02.981184 13930 sgd_solver.cpp:138] Iteration 1100, lr = 1e-05
I0522 16:04:22.585685 13930 solver.cpp:243] Iteration 1200, loss = 4.60254
I0522 16:04:22.585806 13930 solver.cpp:259]     Train net output #0: mbox_loss = 6.01256 (* 1 = 6.01256 loss)
I0522 16:04:22.585811 13930 sgd_solver.cpp:138] Iteration 1200, lr = 1e-05
I0522 16:04:42.196089 13930 solver.cpp:243] Iteration 1300, loss = 4.23881
I0522 16:04:42.196110 13930 solver.cpp:259]     Train net output #0: mbox_loss = 5.86145 (* 1 = 5.86145 loss)
I0522 16:04:42.196115 13930 sgd_solver.cpp:138] Iteration 1300, lr = 1e-05
I0522 16:05:01.822891 13930 solver.cpp:243] Iteration 1400, loss = 6.52277
I0522 16:05:01.823011 13930 solver.cpp:259]     Train net output #0: mbox_loss = 5.73225 (* 1 = 5.73225 loss)
I0522 16:05:01.823017 13930 sgd_solver.cpp:138] Iteration 1400, lr = 1e-05
I0522 16:05:21.419191 13930 solver.cpp:243] Iteration 1500, loss = 4.58516
I0522 16:05:21.419211 13930 solver.cpp:259]     Train net output #0: mbox_loss = 5.17788 (* 1 = 5.17788 loss)
I0522 16:05:21.419216 13930 sgd_solver.cpp:138] Iteration 1500, lr = 1e-05
I0522 16:05:40.976181 13930 solver.cpp:243] Iteration 1600, loss = 5.01667
I0522 16:05:40.976300 13930 solver.cpp:259]     Train net output #0: mbox_loss = 5.57139 (* 1 = 5.57139 loss)
I0522 16:05:40.976306 13930 sgd_solver.cpp:138] Iteration 1600, lr = 1e-05
