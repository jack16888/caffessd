I0524 12:49:54.969101  9498 caffe.cpp:217] Using GPUs 0
I0524 12:49:55.037379  9498 caffe.cpp:222] GPU 0: GeForce RTX 2080 Ti
I0524 12:49:55.428685  9498 solver.cpp:63] Initializing solver from parameters: 
train_net: "mobilessd_step1/Mobilenet448_ssd_train.prototxt"
test_net: "mobilessd_step1/Mobilenet448_ssd_test.prototxt"
test_iter: 673
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.5
weight_decay: 5e-05
snapshot: 5000
snapshot_prefix: "mobilessd_step1/step1"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 20000
stepvalue: 40000
iter_size: 1
type: "RMSProp"
eval_type: "detection"
ap_version: "11point"
I0524 12:49:55.428820  9498 solver.cpp:96] Creating training net from train_net file: mobilessd_step1/Mobilenet448_ssd_train.prototxt
I0524 12:49:55.429646  9498 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/Mobilenet448_ssd_train.prototxt
I0524 12:49:55.429657  9498 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0524 12:49:55.430495  9498 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 448
      width: 448
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
    quant_enable: false
  }
  data_param {
    source: "/home/sx/data/VOCdevkit/VOC0712/lmdb/VOC0712_trainval_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/home/sx/data/VOCdevkit/VOC0712/lmdb/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "sample_pooling"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "sample_pooling"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 512
    stride: 2
    weight_filler {
      type: "constant_array"
      value_array: 1
      value_array: 0
      value_array: 0
      value_array: 0
    }
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "sample_pooling"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "ip6"
  type: "Convolution"
  bottom: "conv13"
  top: "ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip6"
  top: "ip6"
}
layer {
  name: "ip7"
  type: "Convolution"
  bottom: "ip6"
  top: "ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "ip7"
  top: "ip7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "ip7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv12_norm"
  type: "Normalize"
  bottom: "conv12/dw"
  top: "conv12_norm"
  norm_param {
    across_spatial: false
    channel_shared: false
  }
}
layer {
  name: "conv12_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_loc"
  top: "conv12_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_loc_perm"
  top: "conv12_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_conf"
  top: "conv12_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_conf_perm"
  top: "conv12_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_loc"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_loc_perm"
  type: "Permute"
  bottom: "ip7_mbox_loc"
  top: "ip7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_loc_flat"
  type: "Flatten"
  bottom: "ip7_mbox_loc_perm"
  top: "ip7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_conf"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_conf_perm"
  type: "Permute"
  bottom: "ip7_mbox_conf"
  top: "ip7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_conf_flat"
  type: "Flatten"
  bottom: "ip7_mbox_conf_perm"
  top: "ip7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12/dw_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv12/dw"
  bottom: "data"
  top: "conv12/dw_mbox_priorbox"
  prior_box_param {
    min_size: 44.8
    max_size: 89.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
  
I0524 12:49:55.430915  9498 layer_factory.hpp:77] Creating layer data
I0524 12:49:55.431075  9498 net.cpp:100] Creating Layer data
I0524 12:49:55.431133  9498 net.cpp:408] data -> data
I0524 12:49:55.431167  9498 net.cpp:408] data -> label
I0524 12:49:55.433199  9526 db_lmdb.cpp:35] Opened lmdb /home/sx/data/VOCdevkit/VOC0712/lmdb/VOC0712_trainval_lmdb
I0524 12:49:55.449358  9498 annotated_data_layer.cpp:62] output data size: 8,3,448,448
I0524 12:49:55.470108  9498 net.cpp:150] Setting up data
I0524 12:49:55.470135  9498 net.cpp:157] Top shape: 8 3 448 448 (4816896)
I0524 12:49:55.470141  9498 net.cpp:157] Top shape: 1 1 1 8 (8)
I0524 12:49:55.470144  9498 net.cpp:165] Memory required for data: 19267616
I0524 12:49:55.470155  9498 layer_factory.hpp:77] Creating layer data_data_0_split
I0524 12:49:55.470166  9498 net.cpp:100] Creating Layer data_data_0_split
I0524 12:49:55.470172  9498 net.cpp:434] data_data_0_split <- data
I0524 12:49:55.470185  9498 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0524 12:49:55.470194  9498 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0524 12:49:55.470199  9498 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0524 12:49:55.470206  9498 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0524 12:49:55.470211  9498 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0524 12:49:55.470261  9498 net.cpp:150] Setting up data_data_0_split
I0524 12:49:55.470268  9498 net.cpp:157] Top shape: 8 3 448 448 (4816896)
I0524 12:49:55.470271  9498 net.cpp:157] Top shape: 8 3 448 448 (4816896)
I0524 12:49:55.470274  9498 net.cpp:157] Top shape: 8 3 448 448 (4816896)
I0524 12:49:55.470295  9498 net.cpp:157] Top shape: 8 3 448 448 (4816896)
I0524 12:49:55.470299  9498 net.cpp:157] Top shape: 8 3 448 448 (4816896)
I0524 12:49:55.470301  9498 net.cpp:165] Memory required for data: 115605536
I0524 12:49:55.470304  9498 layer_factory.hpp:77] Creating layer conv0
I0524 12:49:55.470319  9498 net.cpp:100] Creating Layer conv0
I0524 12:49:55.470322  9498 net.cpp:434] conv0 <- data_data_0_split_0
I0524 12:49:55.470327  9498 net.cpp:408] conv0 -> conv0
I0524 12:49:56.474789  9498 net.cpp:150] Setting up conv0
I0524 12:49:56.474815  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.474819  9498 net.cpp:165] Memory required for data: 166985760
I0524 12:49:56.474834  9498 layer_factory.hpp:77] Creating layer conv0/bn
I0524 12:49:56.474843  9498 net.cpp:100] Creating Layer conv0/bn
I0524 12:49:56.474846  9498 net.cpp:434] conv0/bn <- conv0
I0524 12:49:56.474851  9498 net.cpp:395] conv0/bn -> conv0 (in-place)
I0524 12:49:56.475747  9498 net.cpp:150] Setting up conv0/bn
I0524 12:49:56.475760  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.475764  9498 net.cpp:165] Memory required for data: 218365984
I0524 12:49:56.475775  9498 layer_factory.hpp:77] Creating layer conv0/scale
I0524 12:49:56.475785  9498 net.cpp:100] Creating Layer conv0/scale
I0524 12:49:56.475788  9498 net.cpp:434] conv0/scale <- conv0
I0524 12:49:56.475793  9498 net.cpp:395] conv0/scale -> conv0 (in-place)
I0524 12:49:56.475836  9498 layer_factory.hpp:77] Creating layer conv0/scale
I0524 12:49:56.475963  9498 net.cpp:150] Setting up conv0/scale
I0524 12:49:56.475970  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.475973  9498 net.cpp:165] Memory required for data: 269746208
I0524 12:49:56.475978  9498 layer_factory.hpp:77] Creating layer conv0/relu
I0524 12:49:56.475984  9498 net.cpp:100] Creating Layer conv0/relu
I0524 12:49:56.475987  9498 net.cpp:434] conv0/relu <- conv0
I0524 12:49:56.475991  9498 net.cpp:395] conv0/relu -> conv0 (in-place)
I0524 12:49:56.476397  9498 net.cpp:150] Setting up conv0/relu
I0524 12:49:56.476408  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.476410  9498 net.cpp:165] Memory required for data: 321126432
I0524 12:49:56.476414  9498 layer_factory.hpp:77] Creating layer conv1/dw
I0524 12:49:56.476423  9498 net.cpp:100] Creating Layer conv1/dw
I0524 12:49:56.476426  9498 net.cpp:434] conv1/dw <- conv0
I0524 12:49:56.476433  9498 net.cpp:408] conv1/dw -> conv1/dw
I0524 12:49:56.476615  9498 net.cpp:150] Setting up conv1/dw
I0524 12:49:56.476621  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.476624  9498 net.cpp:165] Memory required for data: 372506656
I0524 12:49:56.476629  9498 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0524 12:49:56.476634  9498 net.cpp:100] Creating Layer conv1/dw/bn
I0524 12:49:56.476636  9498 net.cpp:434] conv1/dw/bn <- conv1/dw
I0524 12:49:56.476639  9498 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0524 12:49:56.476805  9498 net.cpp:150] Setting up conv1/dw/bn
I0524 12:49:56.476810  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.476814  9498 net.cpp:165] Memory required for data: 423886880
I0524 12:49:56.476820  9498 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0524 12:49:56.476826  9498 net.cpp:100] Creating Layer conv1/dw/scale
I0524 12:49:56.476830  9498 net.cpp:434] conv1/dw/scale <- conv1/dw
I0524 12:49:56.476833  9498 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0524 12:49:56.476871  9498 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0524 12:49:56.476990  9498 net.cpp:150] Setting up conv1/dw/scale
I0524 12:49:56.476996  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.476999  9498 net.cpp:165] Memory required for data: 475267104
I0524 12:49:56.477003  9498 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0524 12:49:56.477007  9498 net.cpp:100] Creating Layer conv1/dw/relu
I0524 12:49:56.477010  9498 net.cpp:434] conv1/dw/relu <- conv1/dw
I0524 12:49:56.477013  9498 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0524 12:49:56.477550  9498 net.cpp:150] Setting up conv1/dw/relu
I0524 12:49:56.477562  9498 net.cpp:157] Top shape: 8 32 224 224 (12845056)
I0524 12:49:56.477566  9498 net.cpp:165] Memory required for data: 526647328
I0524 12:49:56.477569  9498 layer_factory.hpp:77] Creating layer conv1
I0524 12:49:56.477577  9498 net.cpp:100] Creating Layer conv1
I0524 12:49:56.477581  9498 net.cpp:434] conv1 <- conv1/dw
I0524 12:49:56.477586  9498 net.cpp:408] conv1 -> conv1
I0524 12:49:56.479840  9498 net.cpp:150] Setting up conv1
I0524 12:49:56.479852  9498 net.cpp:157] Top shape: 8 64 224 224 (25690112)
I0524 12:49:56.479856  9498 net.cpp:165] Memory required for data: 629407776
I0524 12:49:56.479861  9498 layer_factory.hpp:77] Creating layer conv1/bn
I0524 12:49:56.479866  9498 net.cpp:100] Creating Layer conv1/bn
I0524 12:49:56.479868  9498 net.cpp:434] conv1/bn <- conv1
I0524 12:49:56.479873  9498 net.cpp:395] conv1/bn -> conv1 (in-place)
I0524 12:49:56.480055  9498 net.cpp:150] Setting up conv1/bn
I0524 12:49:56.480060  9498 net.cpp:157] Top shape: 8 64 224 224 (25690112)
I0524 12:49:56.480063  9498 net.cpp:165] Memory required for data: 732168224
I0524 12:49:56.480068  9498 layer_factory.hpp:77] Creating layer conv1/scale
I0524 12:49:56.480074  9498 net.cpp:100] Creating Layer conv1/scale
I0524 12:49:56.480077  9498 net.cpp:434] conv1/scale <- conv1
I0524 12:49:56.480082  9498 net.cpp:395] conv1/scale -> conv1 (in-place)
I0524 12:49:56.480108  9498 layer_factory.hpp:77] Creating layer conv1/scale
I0524 12:49:56.480257  9498 net.cpp:150] Setting up conv1/scale
I0524 12:49:56.480264  9498 net.cpp:157] Top shape: 8 64 224 224 (25690112)
I0524 12:49:56.480266  9498 net.cpp:165] Memory required for data: 834928672
I0524 12:49:56.480274  9498 layer_factory.hpp:77] Creating layer conv1/relu
I0524 12:49:56.480279  9498 net.cpp:100] Creating Layer conv1/relu
I0524 12:49:56.480283  9498 net.cpp:434] conv1/relu <- conv1
I0524 12:49:56.480285  9498 net.cpp:395] conv1/relu -> conv1 (in-place)
I0524 12:49:56.480650  9498 net.cpp:150] Setting up conv1/relu
I0524 12:49:56.480660  9498 net.cpp:157] Top shape: 8 64 224 224 (25690112)
I0524 12:49:56.480664  9498 net.cpp:165] Memory required for data: 937689120
I0524 12:49:56.480666  9498 layer_factory.hpp:77] Creating layer conv2/dw
I0524 12:49:56.480674  9498 net.cpp:100] Creating Layer conv2/dw
I0524 12:49:56.480679  9498 net.cpp:434] conv2/dw <- conv1
I0524 12:49:56.480684  9498 net.cpp:408] conv2/dw -> conv2/dw
I0524 12:49:56.480872  9498 net.cpp:150] Setting up conv2/dw
I0524 12:49:56.480878  9498 net.cpp:157] Top shape: 8 64 112 112 (6422528)
I0524 12:49:56.480881  9498 net.cpp:165] Memory required for data: 963379232
I0524 12:49:56.480885  9498 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0524 12:49:56.480890  9498 net.cpp:100] Creating Layer conv2/dw/bn
I0524 12:49:56.480892  9498 net.cpp:434] conv2/dw/bn <- conv2/dw
I0524 12:49:56.480897  9498 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0524 12:49:56.481688  9498 net.cpp:150] Setting up conv2/dw/bn
I0524 12:49:56.481698  9498 net.cpp:157] Top shape: 8 64 112 112 (6422528)
I0524 12:49:56.481701  9498 net.cpp:165] Memory required for data: 989069344
I0524 12:49:56.481724  9498 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0524 12:49:56.481732  9498 net.cpp:100] Creating Layer conv2/dw/scale
I0524 12:49:56.481735  9498 net.cpp:434] conv2/dw/scale <- conv2/dw
I0524 12:49:56.481740  9498 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0524 12:49:56.481773  9498 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0524 12:49:56.481873  9498 net.cpp:150] Setting up conv2/dw/scale
I0524 12:49:56.481878  9498 net.cpp:157] Top shape: 8 64 112 112 (6422528)
I0524 12:49:56.481881  9498 net.cpp:165] Memory required for data: 1014759456
I0524 12:49:56.481886  9498 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0524 12:49:56.481890  9498 net.cpp:100] Creating Layer conv2/dw/relu
I0524 12:49:56.481892  9498 net.cpp:434] conv2/dw/relu <- conv2/dw
I0524 12:49:56.481896  9498 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0524 12:49:56.483278  9498 net.cpp:150] Setting up conv2/dw/relu
I0524 12:49:56.483291  9498 net.cpp:157] Top shape: 8 64 112 112 (6422528)
I0524 12:49:56.483294  9498 net.cpp:165] Memory required for data: 1040449568
I0524 12:49:56.483297  9498 layer_factory.hpp:77] Creating layer conv2
I0524 12:49:56.483306  9498 net.cpp:100] Creating Layer conv2
I0524 12:49:56.483309  9498 net.cpp:434] conv2 <- conv2/dw
I0524 12:49:56.483314  9498 net.cpp:408] conv2 -> conv2
I0524 12:49:56.485137  9498 net.cpp:150] Setting up conv2
I0524 12:49:56.485150  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.485153  9498 net.cpp:165] Memory required for data: 1091829792
I0524 12:49:56.485158  9498 layer_factory.hpp:77] Creating layer conv2/bn
I0524 12:49:56.485163  9498 net.cpp:100] Creating Layer conv2/bn
I0524 12:49:56.485167  9498 net.cpp:434] conv2/bn <- conv2
I0524 12:49:56.485172  9498 net.cpp:395] conv2/bn -> conv2 (in-place)
I0524 12:49:56.485337  9498 net.cpp:150] Setting up conv2/bn
I0524 12:49:56.485342  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.485345  9498 net.cpp:165] Memory required for data: 1143210016
I0524 12:49:56.485350  9498 layer_factory.hpp:77] Creating layer conv2/scale
I0524 12:49:56.485357  9498 net.cpp:100] Creating Layer conv2/scale
I0524 12:49:56.485358  9498 net.cpp:434] conv2/scale <- conv2
I0524 12:49:56.485363  9498 net.cpp:395] conv2/scale -> conv2 (in-place)
I0524 12:49:56.485391  9498 layer_factory.hpp:77] Creating layer conv2/scale
I0524 12:49:56.485474  9498 net.cpp:150] Setting up conv2/scale
I0524 12:49:56.485479  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.485482  9498 net.cpp:165] Memory required for data: 1194590240
I0524 12:49:56.485487  9498 layer_factory.hpp:77] Creating layer conv2/relu
I0524 12:49:56.485491  9498 net.cpp:100] Creating Layer conv2/relu
I0524 12:49:56.485493  9498 net.cpp:434] conv2/relu <- conv2
I0524 12:49:56.485496  9498 net.cpp:395] conv2/relu -> conv2 (in-place)
I0524 12:49:56.485860  9498 net.cpp:150] Setting up conv2/relu
I0524 12:49:56.485870  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.485872  9498 net.cpp:165] Memory required for data: 1245970464
I0524 12:49:56.485877  9498 layer_factory.hpp:77] Creating layer conv3/dw
I0524 12:49:56.485883  9498 net.cpp:100] Creating Layer conv3/dw
I0524 12:49:56.485886  9498 net.cpp:434] conv3/dw <- conv2
I0524 12:49:56.485890  9498 net.cpp:408] conv3/dw -> conv3/dw
I0524 12:49:56.486068  9498 net.cpp:150] Setting up conv3/dw
I0524 12:49:56.486073  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.486076  9498 net.cpp:165] Memory required for data: 1297350688
I0524 12:49:56.486080  9498 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0524 12:49:56.486084  9498 net.cpp:100] Creating Layer conv3/dw/bn
I0524 12:49:56.486088  9498 net.cpp:434] conv3/dw/bn <- conv3/dw
I0524 12:49:56.486090  9498 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0524 12:49:56.486236  9498 net.cpp:150] Setting up conv3/dw/bn
I0524 12:49:56.486243  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.486245  9498 net.cpp:165] Memory required for data: 1348730912
I0524 12:49:56.486253  9498 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0524 12:49:56.486258  9498 net.cpp:100] Creating Layer conv3/dw/scale
I0524 12:49:56.486261  9498 net.cpp:434] conv3/dw/scale <- conv3/dw
I0524 12:49:56.486265  9498 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0524 12:49:56.486292  9498 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0524 12:49:56.486385  9498 net.cpp:150] Setting up conv3/dw/scale
I0524 12:49:56.486392  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.486394  9498 net.cpp:165] Memory required for data: 1400111136
I0524 12:49:56.486398  9498 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0524 12:49:56.486402  9498 net.cpp:100] Creating Layer conv3/dw/relu
I0524 12:49:56.486404  9498 net.cpp:434] conv3/dw/relu <- conv3/dw
I0524 12:49:56.486408  9498 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0524 12:49:56.486912  9498 net.cpp:150] Setting up conv3/dw/relu
I0524 12:49:56.486924  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.486927  9498 net.cpp:165] Memory required for data: 1451491360
I0524 12:49:56.486930  9498 layer_factory.hpp:77] Creating layer conv3
I0524 12:49:56.486937  9498 net.cpp:100] Creating Layer conv3
I0524 12:49:56.486940  9498 net.cpp:434] conv3 <- conv3/dw
I0524 12:49:56.486946  9498 net.cpp:408] conv3 -> conv3
I0524 12:49:56.488725  9498 net.cpp:150] Setting up conv3
I0524 12:49:56.488739  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.488741  9498 net.cpp:165] Memory required for data: 1502871584
I0524 12:49:56.488746  9498 layer_factory.hpp:77] Creating layer conv3/bn
I0524 12:49:56.488751  9498 net.cpp:100] Creating Layer conv3/bn
I0524 12:49:56.488754  9498 net.cpp:434] conv3/bn <- conv3
I0524 12:49:56.488759  9498 net.cpp:395] conv3/bn -> conv3 (in-place)
I0524 12:49:56.488927  9498 net.cpp:150] Setting up conv3/bn
I0524 12:49:56.488934  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.488935  9498 net.cpp:165] Memory required for data: 1554251808
I0524 12:49:56.488941  9498 layer_factory.hpp:77] Creating layer conv3/scale
I0524 12:49:56.488946  9498 net.cpp:100] Creating Layer conv3/scale
I0524 12:49:56.488950  9498 net.cpp:434] conv3/scale <- conv3
I0524 12:49:56.488952  9498 net.cpp:395] conv3/scale -> conv3 (in-place)
I0524 12:49:56.488981  9498 layer_factory.hpp:77] Creating layer conv3/scale
I0524 12:49:56.489065  9498 net.cpp:150] Setting up conv3/scale
I0524 12:49:56.489078  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.489080  9498 net.cpp:165] Memory required for data: 1605632032
I0524 12:49:56.489084  9498 layer_factory.hpp:77] Creating layer conv3/relu
I0524 12:49:56.489089  9498 net.cpp:100] Creating Layer conv3/relu
I0524 12:49:56.489090  9498 net.cpp:434] conv3/relu <- conv3
I0524 12:49:56.489094  9498 net.cpp:395] conv3/relu -> conv3 (in-place)
I0524 12:49:56.489449  9498 net.cpp:150] Setting up conv3/relu
I0524 12:49:56.489459  9498 net.cpp:157] Top shape: 8 128 112 112 (12845056)
I0524 12:49:56.489461  9498 net.cpp:165] Memory required for data: 1657012256
I0524 12:49:56.489464  9498 layer_factory.hpp:77] Creating layer conv4/dw
I0524 12:49:56.489472  9498 net.cpp:100] Creating Layer conv4/dw
I0524 12:49:56.489476  9498 net.cpp:434] conv4/dw <- conv3
I0524 12:49:56.489480  9498 net.cpp:408] conv4/dw -> conv4/dw
I0524 12:49:56.489656  9498 net.cpp:150] Setting up conv4/dw
I0524 12:49:56.489662  9498 net.cpp:157] Top shape: 8 128 56 56 (3211264)
I0524 12:49:56.489665  9498 net.cpp:165] Memory required for data: 1669857312
I0524 12:49:56.489670  9498 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0524 12:49:56.489675  9498 net.cpp:100] Creating Layer conv4/dw/bn
I0524 12:49:56.489676  9498 net.cpp:434] conv4/dw/bn <- conv4/dw
I0524 12:49:56.489681  9498 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0524 12:49:56.489850  9498 net.cpp:150] Setting up conv4/dw/bn
I0524 12:49:56.489856  9498 net.cpp:157] Top shape: 8 128 56 56 (3211264)
I0524 12:49:56.489858  9498 net.cpp:165] Memory required for data: 1682702368
I0524 12:49:56.489864  9498 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0524 12:49:56.489871  9498 net.cpp:100] Creating Layer conv4/dw/scale
I0524 12:49:56.489873  9498 net.cpp:434] conv4/dw/scale <- conv4/dw
I0524 12:49:56.489877  9498 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0524 12:49:56.489933  9498 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0524 12:49:56.490020  9498 net.cpp:150] Setting up conv4/dw/scale
I0524 12:49:56.490027  9498 net.cpp:157] Top shape: 8 128 56 56 (3211264)
I0524 12:49:56.490031  9498 net.cpp:165] Memory required for data: 1695547424
I0524 12:49:56.490036  9498 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0524 12:49:56.490039  9498 net.cpp:100] Creating Layer conv4/dw/relu
I0524 12:49:56.490041  9498 net.cpp:434] conv4/dw/relu <- conv4/dw
I0524 12:49:56.490046  9498 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0524 12:49:56.491531  9498 net.cpp:150] Setting up conv4/dw/relu
I0524 12:49:56.491544  9498 net.cpp:157] Top shape: 8 128 56 56 (3211264)
I0524 12:49:56.491547  9498 net.cpp:165] Memory required for data: 1708392480
I0524 12:49:56.491550  9498 layer_factory.hpp:77] Creating layer conv4
I0524 12:49:56.491559  9498 net.cpp:100] Creating Layer conv4
I0524 12:49:56.491562  9498 net.cpp:434] conv4 <- conv4/dw
I0524 12:49:56.491567  9498 net.cpp:408] conv4 -> conv4
I0524 12:49:56.493470  9498 net.cpp:150] Setting up conv4
I0524 12:49:56.493484  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.493487  9498 net.cpp:165] Memory required for data: 1734082592
I0524 12:49:56.493492  9498 layer_factory.hpp:77] Creating layer conv4/bn
I0524 12:49:56.493497  9498 net.cpp:100] Creating Layer conv4/bn
I0524 12:49:56.493501  9498 net.cpp:434] conv4/bn <- conv4
I0524 12:49:56.493506  9498 net.cpp:395] conv4/bn -> conv4 (in-place)
I0524 12:49:56.493680  9498 net.cpp:150] Setting up conv4/bn
I0524 12:49:56.493685  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.493690  9498 net.cpp:165] Memory required for data: 1759772704
I0524 12:49:56.493695  9498 layer_factory.hpp:77] Creating layer conv4/scale
I0524 12:49:56.493700  9498 net.cpp:100] Creating Layer conv4/scale
I0524 12:49:56.493702  9498 net.cpp:434] conv4/scale <- conv4
I0524 12:49:56.493706  9498 net.cpp:395] conv4/scale -> conv4 (in-place)
I0524 12:49:56.493737  9498 layer_factory.hpp:77] Creating layer conv4/scale
I0524 12:49:56.493825  9498 net.cpp:150] Setting up conv4/scale
I0524 12:49:56.493839  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.493842  9498 net.cpp:165] Memory required for data: 1785462816
I0524 12:49:56.493846  9498 layer_factory.hpp:77] Creating layer conv4/relu
I0524 12:49:56.493851  9498 net.cpp:100] Creating Layer conv4/relu
I0524 12:49:56.493854  9498 net.cpp:434] conv4/relu <- conv4
I0524 12:49:56.493857  9498 net.cpp:395] conv4/relu -> conv4 (in-place)
I0524 12:49:56.494235  9498 net.cpp:150] Setting up conv4/relu
I0524 12:49:56.494244  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.494247  9498 net.cpp:165] Memory required for data: 1811152928
I0524 12:49:56.494251  9498 layer_factory.hpp:77] Creating layer conv5/dw
I0524 12:49:56.494258  9498 net.cpp:100] Creating Layer conv5/dw
I0524 12:49:56.494261  9498 net.cpp:434] conv5/dw <- conv4
I0524 12:49:56.494266  9498 net.cpp:408] conv5/dw -> conv5/dw
I0524 12:49:56.494468  9498 net.cpp:150] Setting up conv5/dw
I0524 12:49:56.494474  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.494477  9498 net.cpp:165] Memory required for data: 1836843040
I0524 12:49:56.494482  9498 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0524 12:49:56.494487  9498 net.cpp:100] Creating Layer conv5/dw/bn
I0524 12:49:56.494489  9498 net.cpp:434] conv5/dw/bn <- conv5/dw
I0524 12:49:56.494493  9498 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0524 12:49:56.494664  9498 net.cpp:150] Setting up conv5/dw/bn
I0524 12:49:56.494670  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.494673  9498 net.cpp:165] Memory required for data: 1862533152
I0524 12:49:56.494678  9498 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0524 12:49:56.494683  9498 net.cpp:100] Creating Layer conv5/dw/scale
I0524 12:49:56.494686  9498 net.cpp:434] conv5/dw/scale <- conv5/dw
I0524 12:49:56.494689  9498 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0524 12:49:56.494717  9498 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0524 12:49:56.494799  9498 net.cpp:150] Setting up conv5/dw/scale
I0524 12:49:56.494805  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.494808  9498 net.cpp:165] Memory required for data: 1888223264
I0524 12:49:56.494812  9498 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0524 12:49:56.494815  9498 net.cpp:100] Creating Layer conv5/dw/relu
I0524 12:49:56.494818  9498 net.cpp:434] conv5/dw/relu <- conv5/dw
I0524 12:49:56.494822  9498 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0524 12:49:56.495384  9498 net.cpp:150] Setting up conv5/dw/relu
I0524 12:49:56.495396  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.495399  9498 net.cpp:165] Memory required for data: 1913913376
I0524 12:49:56.495404  9498 layer_factory.hpp:77] Creating layer conv5
I0524 12:49:56.495410  9498 net.cpp:100] Creating Layer conv5
I0524 12:49:56.495414  9498 net.cpp:434] conv5 <- conv5/dw
I0524 12:49:56.495419  9498 net.cpp:408] conv5 -> conv5
I0524 12:49:56.498033  9498 net.cpp:150] Setting up conv5
I0524 12:49:56.498045  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.498049  9498 net.cpp:165] Memory required for data: 1939603488
I0524 12:49:56.498054  9498 layer_factory.hpp:77] Creating layer conv5/bn
I0524 12:49:56.498059  9498 net.cpp:100] Creating Layer conv5/bn
I0524 12:49:56.498061  9498 net.cpp:434] conv5/bn <- conv5
I0524 12:49:56.498065  9498 net.cpp:395] conv5/bn -> conv5 (in-place)
I0524 12:49:56.498263  9498 net.cpp:150] Setting up conv5/bn
I0524 12:49:56.498270  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.498273  9498 net.cpp:165] Memory required for data: 1965293600
I0524 12:49:56.498279  9498 layer_factory.hpp:77] Creating layer conv5/scale
I0524 12:49:56.498286  9498 net.cpp:100] Creating Layer conv5/scale
I0524 12:49:56.498287  9498 net.cpp:434] conv5/scale <- conv5
I0524 12:49:56.498291  9498 net.cpp:395] conv5/scale -> conv5 (in-place)
I0524 12:49:56.498322  9498 layer_factory.hpp:77] Creating layer conv5/scale
I0524 12:49:56.498419  9498 net.cpp:150] Setting up conv5/scale
I0524 12:49:56.498425  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.498427  9498 net.cpp:165] Memory required for data: 1990983712
I0524 12:49:56.498437  9498 layer_factory.hpp:77] Creating layer conv5/relu
I0524 12:49:56.498442  9498 net.cpp:100] Creating Layer conv5/relu
I0524 12:49:56.498445  9498 net.cpp:434] conv5/relu <- conv5
I0524 12:49:56.498448  9498 net.cpp:395] conv5/relu -> conv5 (in-place)
I0524 12:49:56.498814  9498 net.cpp:150] Setting up conv5/relu
I0524 12:49:56.498824  9498 net.cpp:157] Top shape: 8 256 56 56 (6422528)
I0524 12:49:56.498827  9498 net.cpp:165] Memory required for data: 2016673824
I0524 12:49:56.498831  9498 layer_factory.hpp:77] Creating layer conv6/dw
I0524 12:49:56.498838  9498 net.cpp:100] Creating Layer conv6/dw
I0524 12:49:56.498842  9498 net.cpp:434] conv6/dw <- conv5
I0524 12:49:56.498847  9498 net.cpp:408] conv6/dw -> conv6/dw
I0524 12:49:56.499047  9498 net.cpp:150] Setting up conv6/dw
I0524 12:49:56.499053  9498 net.cpp:157] Top shape: 8 256 28 28 (1605632)
I0524 12:49:56.499058  9498 net.cpp:165] Memory required for data: 2023096352
I0524 12:49:56.499060  9498 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0524 12:49:56.499064  9498 net.cpp:100] Creating Layer conv6/dw/bn
I0524 12:49:56.499068  9498 net.cpp:434] conv6/dw/bn <- conv6/dw
I0524 12:49:56.499071  9498 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0524 12:49:56.499258  9498 net.cpp:150] Setting up conv6/dw/bn
I0524 12:49:56.499264  9498 net.cpp:157] Top shape: 8 256 28 28 (1605632)
I0524 12:49:56.499266  9498 net.cpp:165] Memory required for data: 2029518880
I0524 12:49:56.499272  9498 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0524 12:49:56.499277  9498 net.cpp:100] Creating Layer conv6/dw/scale
I0524 12:49:56.499279  9498 net.cpp:434] conv6/dw/scale <- conv6/dw
I0524 12:49:56.499284  9498 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0524 12:49:56.499313  9498 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0524 12:49:56.499415  9498 net.cpp:150] Setting up conv6/dw/scale
I0524 12:49:56.499421  9498 net.cpp:157] Top shape: 8 256 28 28 (1605632)
I0524 12:49:56.499423  9498 net.cpp:165] Memory required for data: 2035941408
I0524 12:49:56.499428  9498 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0524 12:49:56.499431  9498 net.cpp:100] Creating Layer conv6/dw/relu
I0524 12:49:56.499434  9498 net.cpp:434] conv6/dw/relu <- conv6/dw
I0524 12:49:56.499439  9498 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0524 12:49:56.500782  9498 net.cpp:150] Setting up conv6/dw/relu
I0524 12:49:56.500795  9498 net.cpp:157] Top shape: 8 256 28 28 (1605632)
I0524 12:49:56.500797  9498 net.cpp:165] Memory required for data: 2042363936
I0524 12:49:56.500800  9498 layer_factory.hpp:77] Creating layer conv6
I0524 12:49:56.500808  9498 net.cpp:100] Creating Layer conv6
I0524 12:49:56.500811  9498 net.cpp:434] conv6 <- conv6/dw
I0524 12:49:56.500816  9498 net.cpp:408] conv6 -> conv6
I0524 12:49:56.504173  9498 net.cpp:150] Setting up conv6
I0524 12:49:56.504185  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.504189  9498 net.cpp:165] Memory required for data: 2055208992
I0524 12:49:56.504194  9498 layer_factory.hpp:77] Creating layer conv6/bn
I0524 12:49:56.504199  9498 net.cpp:100] Creating Layer conv6/bn
I0524 12:49:56.504204  9498 net.cpp:434] conv6/bn <- conv6
I0524 12:49:56.504209  9498 net.cpp:395] conv6/bn -> conv6 (in-place)
I0524 12:49:56.504408  9498 net.cpp:150] Setting up conv6/bn
I0524 12:49:56.504413  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.504417  9498 net.cpp:165] Memory required for data: 2068054048
I0524 12:49:56.504422  9498 layer_factory.hpp:77] Creating layer conv6/scale
I0524 12:49:56.504427  9498 net.cpp:100] Creating Layer conv6/scale
I0524 12:49:56.504431  9498 net.cpp:434] conv6/scale <- conv6
I0524 12:49:56.504436  9498 net.cpp:395] conv6/scale -> conv6 (in-place)
I0524 12:49:56.504468  9498 layer_factory.hpp:77] Creating layer conv6/scale
I0524 12:49:56.504573  9498 net.cpp:150] Setting up conv6/scale
I0524 12:49:56.504580  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.504582  9498 net.cpp:165] Memory required for data: 2080899104
I0524 12:49:56.504586  9498 layer_factory.hpp:77] Creating layer conv6/relu
I0524 12:49:56.504590  9498 net.cpp:100] Creating Layer conv6/relu
I0524 12:49:56.504593  9498 net.cpp:434] conv6/relu <- conv6
I0524 12:49:56.504598  9498 net.cpp:395] conv6/relu -> conv6 (in-place)
I0524 12:49:56.505050  9498 net.cpp:150] Setting up conv6/relu
I0524 12:49:56.505064  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.505066  9498 net.cpp:165] Memory required for data: 2093744160
I0524 12:49:56.505069  9498 layer_factory.hpp:77] Creating layer conv7/dw
I0524 12:49:56.505079  9498 net.cpp:100] Creating Layer conv7/dw
I0524 12:49:56.505081  9498 net.cpp:434] conv7/dw <- conv6
I0524 12:49:56.505086  9498 net.cpp:408] conv7/dw -> conv7/dw
I0524 12:49:56.505300  9498 net.cpp:150] Setting up conv7/dw
I0524 12:49:56.505306  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.505309  9498 net.cpp:165] Memory required for data: 2106589216
I0524 12:49:56.505323  9498 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0524 12:49:56.505328  9498 net.cpp:100] Creating Layer conv7/dw/bn
I0524 12:49:56.505331  9498 net.cpp:434] conv7/dw/bn <- conv7/dw
I0524 12:49:56.505334  9498 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0524 12:49:56.505501  9498 net.cpp:150] Setting up conv7/dw/bn
I0524 12:49:56.505507  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.505511  9498 net.cpp:165] Memory required for data: 2119434272
I0524 12:49:56.505515  9498 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0524 12:49:56.505519  9498 net.cpp:100] Creating Layer conv7/dw/scale
I0524 12:49:56.505522  9498 net.cpp:434] conv7/dw/scale <- conv7/dw
I0524 12:49:56.505527  9498 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0524 12:49:56.505565  9498 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0524 12:49:56.505662  9498 net.cpp:150] Setting up conv7/dw/scale
I0524 12:49:56.505667  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.505671  9498 net.cpp:165] Memory required for data: 2132279328
I0524 12:49:56.505674  9498 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0524 12:49:56.505678  9498 net.cpp:100] Creating Layer conv7/dw/relu
I0524 12:49:56.505681  9498 net.cpp:434] conv7/dw/relu <- conv7/dw
I0524 12:49:56.505686  9498 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0524 12:49:56.506263  9498 net.cpp:150] Setting up conv7/dw/relu
I0524 12:49:56.506274  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.506278  9498 net.cpp:165] Memory required for data: 2145124384
I0524 12:49:56.506280  9498 layer_factory.hpp:77] Creating layer conv7
I0524 12:49:56.506289  9498 net.cpp:100] Creating Layer conv7
I0524 12:49:56.506291  9498 net.cpp:434] conv7 <- conv7/dw
I0524 12:49:56.506297  9498 net.cpp:408] conv7 -> conv7
I0524 12:49:56.509968  9498 net.cpp:150] Setting up conv7
I0524 12:49:56.509980  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.509984  9498 net.cpp:165] Memory required for data: 2157969440
I0524 12:49:56.509989  9498 layer_factory.hpp:77] Creating layer conv7/bn
I0524 12:49:56.509995  9498 net.cpp:100] Creating Layer conv7/bn
I0524 12:49:56.509999  9498 net.cpp:434] conv7/bn <- conv7
I0524 12:49:56.510002  9498 net.cpp:395] conv7/bn -> conv7 (in-place)
I0524 12:49:56.510203  9498 net.cpp:150] Setting up conv7/bn
I0524 12:49:56.510210  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.510211  9498 net.cpp:165] Memory required for data: 2170814496
I0524 12:49:56.510216  9498 layer_factory.hpp:77] Creating layer conv7/scale
I0524 12:49:56.510222  9498 net.cpp:100] Creating Layer conv7/scale
I0524 12:49:56.510224  9498 net.cpp:434] conv7/scale <- conv7
I0524 12:49:56.510228  9498 net.cpp:395] conv7/scale -> conv7 (in-place)
I0524 12:49:56.510262  9498 layer_factory.hpp:77] Creating layer conv7/scale
I0524 12:49:56.510375  9498 net.cpp:150] Setting up conv7/scale
I0524 12:49:56.510380  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.510382  9498 net.cpp:165] Memory required for data: 2183659552
I0524 12:49:56.510386  9498 layer_factory.hpp:77] Creating layer conv7/relu
I0524 12:49:56.510392  9498 net.cpp:100] Creating Layer conv7/relu
I0524 12:49:56.510394  9498 net.cpp:434] conv7/relu <- conv7
I0524 12:49:56.510398  9498 net.cpp:395] conv7/relu -> conv7 (in-place)
I0524 12:49:56.510851  9498 net.cpp:150] Setting up conv7/relu
I0524 12:49:56.510864  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.510866  9498 net.cpp:165] Memory required for data: 2196504608
I0524 12:49:56.510869  9498 layer_factory.hpp:77] Creating layer conv8/dw
I0524 12:49:56.510876  9498 net.cpp:100] Creating Layer conv8/dw
I0524 12:49:56.510880  9498 net.cpp:434] conv8/dw <- conv7
I0524 12:49:56.510885  9498 net.cpp:408] conv8/dw -> conv8/dw
I0524 12:49:56.511106  9498 net.cpp:150] Setting up conv8/dw
I0524 12:49:56.511117  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.511121  9498 net.cpp:165] Memory required for data: 2209349664
I0524 12:49:56.511126  9498 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0524 12:49:56.511129  9498 net.cpp:100] Creating Layer conv8/dw/bn
I0524 12:49:56.511132  9498 net.cpp:434] conv8/dw/bn <- conv8/dw
I0524 12:49:56.511137  9498 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0524 12:49:56.511325  9498 net.cpp:150] Setting up conv8/dw/bn
I0524 12:49:56.511330  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.511333  9498 net.cpp:165] Memory required for data: 2222194720
I0524 12:49:56.511339  9498 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0524 12:49:56.511349  9498 net.cpp:100] Creating Layer conv8/dw/scale
I0524 12:49:56.511360  9498 net.cpp:434] conv8/dw/scale <- conv8/dw
I0524 12:49:56.511364  9498 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0524 12:49:56.511397  9498 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0524 12:49:56.511490  9498 net.cpp:150] Setting up conv8/dw/scale
I0524 12:49:56.511497  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.511500  9498 net.cpp:165] Memory required for data: 2235039776
I0524 12:49:56.511504  9498 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0524 12:49:56.511508  9498 net.cpp:100] Creating Layer conv8/dw/relu
I0524 12:49:56.511512  9498 net.cpp:434] conv8/dw/relu <- conv8/dw
I0524 12:49:56.511514  9498 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0524 12:49:56.512204  9498 net.cpp:150] Setting up conv8/dw/relu
I0524 12:49:56.512217  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.512219  9498 net.cpp:165] Memory required for data: 2247884832
I0524 12:49:56.512223  9498 layer_factory.hpp:77] Creating layer conv8
I0524 12:49:56.512234  9498 net.cpp:100] Creating Layer conv8
I0524 12:49:56.512238  9498 net.cpp:434] conv8 <- conv8/dw
I0524 12:49:56.512243  9498 net.cpp:408] conv8 -> conv8
I0524 12:49:56.517189  9498 net.cpp:150] Setting up conv8
I0524 12:49:56.517201  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.517204  9498 net.cpp:165] Memory required for data: 2260729888
I0524 12:49:56.517208  9498 layer_factory.hpp:77] Creating layer conv8/bn
I0524 12:49:56.517216  9498 net.cpp:100] Creating Layer conv8/bn
I0524 12:49:56.517220  9498 net.cpp:434] conv8/bn <- conv8
I0524 12:49:56.517225  9498 net.cpp:395] conv8/bn -> conv8 (in-place)
I0524 12:49:56.517410  9498 net.cpp:150] Setting up conv8/bn
I0524 12:49:56.517416  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.517419  9498 net.cpp:165] Memory required for data: 2273574944
I0524 12:49:56.517424  9498 layer_factory.hpp:77] Creating layer conv8/scale
I0524 12:49:56.517431  9498 net.cpp:100] Creating Layer conv8/scale
I0524 12:49:56.517432  9498 net.cpp:434] conv8/scale <- conv8
I0524 12:49:56.517437  9498 net.cpp:395] conv8/scale -> conv8 (in-place)
I0524 12:49:56.517468  9498 layer_factory.hpp:77] Creating layer conv8/scale
I0524 12:49:56.517572  9498 net.cpp:150] Setting up conv8/scale
I0524 12:49:56.517577  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.517581  9498 net.cpp:165] Memory required for data: 2286420000
I0524 12:49:56.517585  9498 layer_factory.hpp:77] Creating layer conv8/relu
I0524 12:49:56.517590  9498 net.cpp:100] Creating Layer conv8/relu
I0524 12:49:56.517592  9498 net.cpp:434] conv8/relu <- conv8
I0524 12:49:56.517596  9498 net.cpp:395] conv8/relu -> conv8 (in-place)
I0524 12:49:56.518016  9498 net.cpp:150] Setting up conv8/relu
I0524 12:49:56.518025  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.518028  9498 net.cpp:165] Memory required for data: 2299265056
I0524 12:49:56.518031  9498 layer_factory.hpp:77] Creating layer conv9/dw
I0524 12:49:56.518039  9498 net.cpp:100] Creating Layer conv9/dw
I0524 12:49:56.518043  9498 net.cpp:434] conv9/dw <- conv8
I0524 12:49:56.518046  9498 net.cpp:408] conv9/dw -> conv9/dw
I0524 12:49:56.518254  9498 net.cpp:150] Setting up conv9/dw
I0524 12:49:56.518260  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.518262  9498 net.cpp:165] Memory required for data: 2312110112
I0524 12:49:56.518266  9498 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0524 12:49:56.518270  9498 net.cpp:100] Creating Layer conv9/dw/bn
I0524 12:49:56.518272  9498 net.cpp:434] conv9/dw/bn <- conv9/dw
I0524 12:49:56.518276  9498 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0524 12:49:56.518471  9498 net.cpp:150] Setting up conv9/dw/bn
I0524 12:49:56.518478  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.518481  9498 net.cpp:165] Memory required for data: 2324955168
I0524 12:49:56.518486  9498 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0524 12:49:56.518489  9498 net.cpp:100] Creating Layer conv9/dw/scale
I0524 12:49:56.518493  9498 net.cpp:434] conv9/dw/scale <- conv9/dw
I0524 12:49:56.518496  9498 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0524 12:49:56.518528  9498 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0524 12:49:56.518635  9498 net.cpp:150] Setting up conv9/dw/scale
I0524 12:49:56.518640  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.518643  9498 net.cpp:165] Memory required for data: 2337800224
I0524 12:49:56.518647  9498 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0524 12:49:56.518651  9498 net.cpp:100] Creating Layer conv9/dw/relu
I0524 12:49:56.518656  9498 net.cpp:434] conv9/dw/relu <- conv9/dw
I0524 12:49:56.518658  9498 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0524 12:49:56.519223  9498 net.cpp:150] Setting up conv9/dw/relu
I0524 12:49:56.519244  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.519248  9498 net.cpp:165] Memory required for data: 2350645280
I0524 12:49:56.519250  9498 layer_factory.hpp:77] Creating layer conv9
I0524 12:49:56.519259  9498 net.cpp:100] Creating Layer conv9
I0524 12:49:56.519263  9498 net.cpp:434] conv9 <- conv9/dw
I0524 12:49:56.519268  9498 net.cpp:408] conv9 -> conv9
I0524 12:49:56.522872  9498 net.cpp:150] Setting up conv9
I0524 12:49:56.522884  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.522887  9498 net.cpp:165] Memory required for data: 2363490336
I0524 12:49:56.522892  9498 layer_factory.hpp:77] Creating layer conv9/bn
I0524 12:49:56.522898  9498 net.cpp:100] Creating Layer conv9/bn
I0524 12:49:56.522902  9498 net.cpp:434] conv9/bn <- conv9
I0524 12:49:56.522905  9498 net.cpp:395] conv9/bn -> conv9 (in-place)
I0524 12:49:56.523092  9498 net.cpp:150] Setting up conv9/bn
I0524 12:49:56.523097  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.523099  9498 net.cpp:165] Memory required for data: 2376335392
I0524 12:49:56.523104  9498 layer_factory.hpp:77] Creating layer conv9/scale
I0524 12:49:56.523109  9498 net.cpp:100] Creating Layer conv9/scale
I0524 12:49:56.523116  9498 net.cpp:434] conv9/scale <- conv9
I0524 12:49:56.523121  9498 net.cpp:395] conv9/scale -> conv9 (in-place)
I0524 12:49:56.523154  9498 layer_factory.hpp:77] Creating layer conv9/scale
I0524 12:49:56.523259  9498 net.cpp:150] Setting up conv9/scale
I0524 12:49:56.523264  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.523267  9498 net.cpp:165] Memory required for data: 2389180448
I0524 12:49:56.523270  9498 layer_factory.hpp:77] Creating layer conv9/relu
I0524 12:49:56.523275  9498 net.cpp:100] Creating Layer conv9/relu
I0524 12:49:56.523277  9498 net.cpp:434] conv9/relu <- conv9
I0524 12:49:56.523283  9498 net.cpp:395] conv9/relu -> conv9 (in-place)
I0524 12:49:56.523741  9498 net.cpp:150] Setting up conv9/relu
I0524 12:49:56.523756  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.523758  9498 net.cpp:165] Memory required for data: 2402025504
I0524 12:49:56.523761  9498 layer_factory.hpp:77] Creating layer conv10/dw
I0524 12:49:56.523768  9498 net.cpp:100] Creating Layer conv10/dw
I0524 12:49:56.523772  9498 net.cpp:434] conv10/dw <- conv9
I0524 12:49:56.523777  9498 net.cpp:408] conv10/dw -> conv10/dw
I0524 12:49:56.523991  9498 net.cpp:150] Setting up conv10/dw
I0524 12:49:56.523998  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.524009  9498 net.cpp:165] Memory required for data: 2414870560
I0524 12:49:56.524013  9498 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0524 12:49:56.524017  9498 net.cpp:100] Creating Layer conv10/dw/bn
I0524 12:49:56.524020  9498 net.cpp:434] conv10/dw/bn <- conv10/dw
I0524 12:49:56.524024  9498 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0524 12:49:56.524204  9498 net.cpp:150] Setting up conv10/dw/bn
I0524 12:49:56.524209  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.524211  9498 net.cpp:165] Memory required for data: 2427715616
I0524 12:49:56.524217  9498 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0524 12:49:56.524222  9498 net.cpp:100] Creating Layer conv10/dw/scale
I0524 12:49:56.524225  9498 net.cpp:434] conv10/dw/scale <- conv10/dw
I0524 12:49:56.524228  9498 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0524 12:49:56.524274  9498 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0524 12:49:56.524376  9498 net.cpp:150] Setting up conv10/dw/scale
I0524 12:49:56.524381  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.524384  9498 net.cpp:165] Memory required for data: 2440560672
I0524 12:49:56.524389  9498 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0524 12:49:56.524392  9498 net.cpp:100] Creating Layer conv10/dw/relu
I0524 12:49:56.524395  9498 net.cpp:434] conv10/dw/relu <- conv10/dw
I0524 12:49:56.524399  9498 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0524 12:49:56.524845  9498 net.cpp:150] Setting up conv10/dw/relu
I0524 12:49:56.524855  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.524857  9498 net.cpp:165] Memory required for data: 2453405728
I0524 12:49:56.524860  9498 layer_factory.hpp:77] Creating layer conv10
I0524 12:49:56.524868  9498 net.cpp:100] Creating Layer conv10
I0524 12:49:56.524871  9498 net.cpp:434] conv10 <- conv10/dw
I0524 12:49:56.524878  9498 net.cpp:408] conv10 -> conv10
I0524 12:49:56.530160  9498 net.cpp:150] Setting up conv10
I0524 12:49:56.530174  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.530176  9498 net.cpp:165] Memory required for data: 2466250784
I0524 12:49:56.530180  9498 layer_factory.hpp:77] Creating layer conv10/bn
I0524 12:49:56.530186  9498 net.cpp:100] Creating Layer conv10/bn
I0524 12:49:56.530190  9498 net.cpp:434] conv10/bn <- conv10
I0524 12:49:56.530194  9498 net.cpp:395] conv10/bn -> conv10 (in-place)
I0524 12:49:56.530398  9498 net.cpp:150] Setting up conv10/bn
I0524 12:49:56.530405  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.530408  9498 net.cpp:165] Memory required for data: 2479095840
I0524 12:49:56.530413  9498 layer_factory.hpp:77] Creating layer conv10/scale
I0524 12:49:56.530418  9498 net.cpp:100] Creating Layer conv10/scale
I0524 12:49:56.530421  9498 net.cpp:434] conv10/scale <- conv10
I0524 12:49:56.530426  9498 net.cpp:395] conv10/scale -> conv10 (in-place)
I0524 12:49:56.530457  9498 layer_factory.hpp:77] Creating layer conv10/scale
I0524 12:49:56.530558  9498 net.cpp:150] Setting up conv10/scale
I0524 12:49:56.530565  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.530567  9498 net.cpp:165] Memory required for data: 2491940896
I0524 12:49:56.530570  9498 layer_factory.hpp:77] Creating layer conv10/relu
I0524 12:49:56.530575  9498 net.cpp:100] Creating Layer conv10/relu
I0524 12:49:56.530577  9498 net.cpp:434] conv10/relu <- conv10
I0524 12:49:56.530582  9498 net.cpp:395] conv10/relu -> conv10 (in-place)
I0524 12:49:56.531185  9498 net.cpp:150] Setting up conv10/relu
I0524 12:49:56.531198  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.531199  9498 net.cpp:165] Memory required for data: 2504785952
I0524 12:49:56.531204  9498 layer_factory.hpp:77] Creating layer conv11/dw
I0524 12:49:56.531213  9498 net.cpp:100] Creating Layer conv11/dw
I0524 12:49:56.531216  9498 net.cpp:434] conv11/dw <- conv10
I0524 12:49:56.531222  9498 net.cpp:408] conv11/dw -> conv11/dw
I0524 12:49:56.531460  9498 net.cpp:150] Setting up conv11/dw
I0524 12:49:56.531466  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.531467  9498 net.cpp:165] Memory required for data: 2517631008
I0524 12:49:56.531471  9498 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0524 12:49:56.531477  9498 net.cpp:100] Creating Layer conv11/dw/bn
I0524 12:49:56.531481  9498 net.cpp:434] conv11/dw/bn <- conv11/dw
I0524 12:49:56.531483  9498 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0524 12:49:56.531672  9498 net.cpp:150] Setting up conv11/dw/bn
I0524 12:49:56.531678  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.531680  9498 net.cpp:165] Memory required for data: 2530476064
I0524 12:49:56.531698  9498 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0524 12:49:56.531705  9498 net.cpp:100] Creating Layer conv11/dw/scale
I0524 12:49:56.531708  9498 net.cpp:434] conv11/dw/scale <- conv11/dw
I0524 12:49:56.531713  9498 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0524 12:49:56.531747  9498 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0524 12:49:56.531852  9498 net.cpp:150] Setting up conv11/dw/scale
I0524 12:49:56.531857  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.531860  9498 net.cpp:165] Memory required for data: 2543321120
I0524 12:49:56.531864  9498 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0524 12:49:56.531868  9498 net.cpp:100] Creating Layer conv11/dw/relu
I0524 12:49:56.531872  9498 net.cpp:434] conv11/dw/relu <- conv11/dw
I0524 12:49:56.531875  9498 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0524 12:49:56.532331  9498 net.cpp:150] Setting up conv11/dw/relu
I0524 12:49:56.532346  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.532348  9498 net.cpp:165] Memory required for data: 2556166176
I0524 12:49:56.532351  9498 layer_factory.hpp:77] Creating layer conv11
I0524 12:49:56.532359  9498 net.cpp:100] Creating Layer conv11
I0524 12:49:56.532362  9498 net.cpp:434] conv11 <- conv11/dw
I0524 12:49:56.532369  9498 net.cpp:408] conv11 -> conv11
I0524 12:49:56.536046  9498 net.cpp:150] Setting up conv11
I0524 12:49:56.536059  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.536062  9498 net.cpp:165] Memory required for data: 2569011232
I0524 12:49:56.536083  9498 layer_factory.hpp:77] Creating layer conv11/bn
I0524 12:49:56.536090  9498 net.cpp:100] Creating Layer conv11/bn
I0524 12:49:56.536093  9498 net.cpp:434] conv11/bn <- conv11
I0524 12:49:56.536099  9498 net.cpp:395] conv11/bn -> conv11 (in-place)
I0524 12:49:56.536294  9498 net.cpp:150] Setting up conv11/bn
I0524 12:49:56.536300  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.536303  9498 net.cpp:165] Memory required for data: 2581856288
I0524 12:49:56.536309  9498 layer_factory.hpp:77] Creating layer conv11/scale
I0524 12:49:56.536314  9498 net.cpp:100] Creating Layer conv11/scale
I0524 12:49:56.536317  9498 net.cpp:434] conv11/scale <- conv11
I0524 12:49:56.536321  9498 net.cpp:395] conv11/scale -> conv11 (in-place)
I0524 12:49:56.536355  9498 layer_factory.hpp:77] Creating layer conv11/scale
I0524 12:49:56.536479  9498 net.cpp:150] Setting up conv11/scale
I0524 12:49:56.536485  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.536487  9498 net.cpp:165] Memory required for data: 2594701344
I0524 12:49:56.536492  9498 layer_factory.hpp:77] Creating layer conv11/relu
I0524 12:49:56.536496  9498 net.cpp:100] Creating Layer conv11/relu
I0524 12:49:56.536499  9498 net.cpp:434] conv11/relu <- conv11
I0524 12:49:56.536502  9498 net.cpp:395] conv11/relu -> conv11 (in-place)
I0524 12:49:56.536939  9498 net.cpp:150] Setting up conv11/relu
I0524 12:49:56.536950  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.536952  9498 net.cpp:165] Memory required for data: 2607546400
I0524 12:49:56.536955  9498 layer_factory.hpp:77] Creating layer conv12/dw
I0524 12:49:56.536963  9498 net.cpp:100] Creating Layer conv12/dw
I0524 12:49:56.536967  9498 net.cpp:434] conv12/dw <- conv11
I0524 12:49:56.536973  9498 net.cpp:408] conv12/dw -> conv12/dw
I0524 12:49:56.537191  9498 net.cpp:150] Setting up conv12/dw
I0524 12:49:56.537197  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.537200  9498 net.cpp:165] Memory required for data: 2620391456
I0524 12:49:56.537204  9498 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0524 12:49:56.537209  9498 net.cpp:100] Creating Layer conv12/dw/bn
I0524 12:49:56.537212  9498 net.cpp:434] conv12/dw/bn <- conv12/dw
I0524 12:49:56.537216  9498 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0524 12:49:56.537386  9498 net.cpp:150] Setting up conv12/dw/bn
I0524 12:49:56.537391  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.537395  9498 net.cpp:165] Memory required for data: 2633236512
I0524 12:49:56.537400  9498 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0524 12:49:56.537405  9498 net.cpp:100] Creating Layer conv12/dw/scale
I0524 12:49:56.537407  9498 net.cpp:434] conv12/dw/scale <- conv12/dw
I0524 12:49:56.537410  9498 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0524 12:49:56.537451  9498 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0524 12:49:56.537547  9498 net.cpp:150] Setting up conv12/dw/scale
I0524 12:49:56.537552  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.537555  9498 net.cpp:165] Memory required for data: 2646081568
I0524 12:49:56.537559  9498 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0524 12:49:56.537564  9498 net.cpp:100] Creating Layer conv12/dw/relu
I0524 12:49:56.537566  9498 net.cpp:434] conv12/dw/relu <- conv12/dw
I0524 12:49:56.537580  9498 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0524 12:49:56.538008  9498 net.cpp:150] Setting up conv12/dw/relu
I0524 12:49:56.538019  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.538022  9498 net.cpp:165] Memory required for data: 2658926624
I0524 12:49:56.538024  9498 layer_factory.hpp:77] Creating layer conv12/dw_conv12/dw/relu_0_split
I0524 12:49:56.538030  9498 net.cpp:100] Creating Layer conv12/dw_conv12/dw/relu_0_split
I0524 12:49:56.538033  9498 net.cpp:434] conv12/dw_conv12/dw/relu_0_split <- conv12/dw
I0524 12:49:56.538039  9498 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_0
I0524 12:49:56.538044  9498 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_1
I0524 12:49:56.538055  9498 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_2
I0524 12:49:56.538105  9498 net.cpp:150] Setting up conv12/dw_conv12/dw/relu_0_split
I0524 12:49:56.538110  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.538115  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.538118  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:56.538121  9498 net.cpp:165] Memory required for data: 2697461792
I0524 12:49:56.538123  9498 layer_factory.hpp:77] Creating layer sample_pooling
I0524 12:49:56.538131  9498 net.cpp:100] Creating Layer sample_pooling
I0524 12:49:56.538134  9498 net.cpp:434] sample_pooling <- conv12/dw_conv12/dw/relu_0_split_0
I0524 12:49:56.538139  9498 net.cpp:408] sample_pooling -> sample_pooling
I0524 12:49:57.608001  9498 net.cpp:150] Setting up sample_pooling
I0524 12:49:57.608024  9498 net.cpp:157] Top shape: 8 512 14 14 (802816)
I0524 12:49:57.608028  9498 net.cpp:165] Memory required for data: 2700673056
I0524 12:49:57.608053  9498 layer_factory.hpp:77] Creating layer conv12
I0524 12:49:57.608067  9498 net.cpp:100] Creating Layer conv12
I0524 12:49:57.608072  9498 net.cpp:434] conv12 <- sample_pooling
I0524 12:49:57.608080  9498 net.cpp:408] conv12 -> conv12
I0524 12:49:57.617507  9498 net.cpp:150] Setting up conv12
I0524 12:49:57.617530  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.617533  9498 net.cpp:165] Memory required for data: 2707095584
I0524 12:49:57.617558  9498 layer_factory.hpp:77] Creating layer conv12/bn
I0524 12:49:57.617568  9498 net.cpp:100] Creating Layer conv12/bn
I0524 12:49:57.617571  9498 net.cpp:434] conv12/bn <- conv12
I0524 12:49:57.617578  9498 net.cpp:395] conv12/bn -> conv12 (in-place)
I0524 12:49:57.618150  9498 net.cpp:150] Setting up conv12/bn
I0524 12:49:57.618158  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.618161  9498 net.cpp:165] Memory required for data: 2713518112
I0524 12:49:57.618167  9498 layer_factory.hpp:77] Creating layer conv12/scale
I0524 12:49:57.618175  9498 net.cpp:100] Creating Layer conv12/scale
I0524 12:49:57.618178  9498 net.cpp:434] conv12/scale <- conv12
I0524 12:49:57.618182  9498 net.cpp:395] conv12/scale -> conv12 (in-place)
I0524 12:49:57.618268  9498 layer_factory.hpp:77] Creating layer conv12/scale
I0524 12:49:57.618558  9498 net.cpp:150] Setting up conv12/scale
I0524 12:49:57.618566  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.618568  9498 net.cpp:165] Memory required for data: 2719940640
I0524 12:49:57.618572  9498 layer_factory.hpp:77] Creating layer conv12/relu
I0524 12:49:57.618579  9498 net.cpp:100] Creating Layer conv12/relu
I0524 12:49:57.618582  9498 net.cpp:434] conv12/relu <- conv12
I0524 12:49:57.618585  9498 net.cpp:395] conv12/relu -> conv12 (in-place)
I0524 12:49:57.619065  9498 net.cpp:150] Setting up conv12/relu
I0524 12:49:57.619078  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.619081  9498 net.cpp:165] Memory required for data: 2726363168
I0524 12:49:57.619084  9498 layer_factory.hpp:77] Creating layer conv13/dw
I0524 12:49:57.619094  9498 net.cpp:100] Creating Layer conv13/dw
I0524 12:49:57.619099  9498 net.cpp:434] conv13/dw <- conv12
I0524 12:49:57.619132  9498 net.cpp:408] conv13/dw -> conv13/dw
I0524 12:49:57.619750  9498 net.cpp:150] Setting up conv13/dw
I0524 12:49:57.619758  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.619761  9498 net.cpp:165] Memory required for data: 2732785696
I0524 12:49:57.619765  9498 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0524 12:49:57.619771  9498 net.cpp:100] Creating Layer conv13/dw/bn
I0524 12:49:57.619774  9498 net.cpp:434] conv13/dw/bn <- conv13/dw
I0524 12:49:57.619778  9498 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0524 12:49:57.620326  9498 net.cpp:150] Setting up conv13/dw/bn
I0524 12:49:57.620333  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.620337  9498 net.cpp:165] Memory required for data: 2739208224
I0524 12:49:57.620342  9498 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0524 12:49:57.620348  9498 net.cpp:100] Creating Layer conv13/dw/scale
I0524 12:49:57.620352  9498 net.cpp:434] conv13/dw/scale <- conv13/dw
I0524 12:49:57.620355  9498 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0524 12:49:57.620438  9498 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0524 12:49:57.620741  9498 net.cpp:150] Setting up conv13/dw/scale
I0524 12:49:57.620748  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.620750  9498 net.cpp:165] Memory required for data: 2745630752
I0524 12:49:57.620755  9498 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0524 12:49:57.620761  9498 net.cpp:100] Creating Layer conv13/dw/relu
I0524 12:49:57.620764  9498 net.cpp:434] conv13/dw/relu <- conv13/dw
I0524 12:49:57.620767  9498 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0524 12:49:57.621266  9498 net.cpp:150] Setting up conv13/dw/relu
I0524 12:49:57.621279  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.621282  9498 net.cpp:165] Memory required for data: 2752053280
I0524 12:49:57.621285  9498 layer_factory.hpp:77] Creating layer conv13
I0524 12:49:57.621294  9498 net.cpp:100] Creating Layer conv13
I0524 12:49:57.621299  9498 net.cpp:434] conv13 <- conv13/dw
I0524 12:49:57.621304  9498 net.cpp:408] conv13 -> conv13
I0524 12:49:57.631917  9498 net.cpp:150] Setting up conv13
I0524 12:49:57.631935  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.631938  9498 net.cpp:165] Memory required for data: 2758475808
I0524 12:49:57.631944  9498 layer_factory.hpp:77] Creating layer conv13/bn
I0524 12:49:57.631950  9498 net.cpp:100] Creating Layer conv13/bn
I0524 12:49:57.631954  9498 net.cpp:434] conv13/bn <- conv13
I0524 12:49:57.631959  9498 net.cpp:395] conv13/bn -> conv13 (in-place)
I0524 12:49:57.632529  9498 net.cpp:150] Setting up conv13/bn
I0524 12:49:57.632535  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.632539  9498 net.cpp:165] Memory required for data: 2764898336
I0524 12:49:57.632544  9498 layer_factory.hpp:77] Creating layer conv13/scale
I0524 12:49:57.632550  9498 net.cpp:100] Creating Layer conv13/scale
I0524 12:49:57.632552  9498 net.cpp:434] conv13/scale <- conv13
I0524 12:49:57.632558  9498 net.cpp:395] conv13/scale -> conv13 (in-place)
I0524 12:49:57.632654  9498 layer_factory.hpp:77] Creating layer conv13/scale
I0524 12:49:57.632941  9498 net.cpp:150] Setting up conv13/scale
I0524 12:49:57.632948  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.632951  9498 net.cpp:165] Memory required for data: 2771320864
I0524 12:49:57.632956  9498 layer_factory.hpp:77] Creating layer conv13/relu
I0524 12:49:57.632961  9498 net.cpp:100] Creating Layer conv13/relu
I0524 12:49:57.632963  9498 net.cpp:434] conv13/relu <- conv13
I0524 12:49:57.632968  9498 net.cpp:395] conv13/relu -> conv13 (in-place)
I0524 12:49:57.633477  9498 net.cpp:150] Setting up conv13/relu
I0524 12:49:57.633488  9498 net.cpp:157] Top shape: 8 1024 14 14 (1605632)
I0524 12:49:57.633491  9498 net.cpp:165] Memory required for data: 2777743392
I0524 12:49:57.633494  9498 layer_factory.hpp:77] Creating layer ip6
I0524 12:49:57.633503  9498 net.cpp:100] Creating Layer ip6
I0524 12:49:57.633507  9498 net.cpp:434] ip6 <- conv13
I0524 12:49:57.633528  9498 net.cpp:408] ip6 -> ip6
I0524 12:49:57.644874  9498 net.cpp:150] Setting up ip6
I0524 12:49:57.644896  9498 net.cpp:157] Top shape: 8 256 14 14 (401408)
I0524 12:49:57.644898  9498 net.cpp:165] Memory required for data: 2779349024
I0524 12:49:57.644920  9498 layer_factory.hpp:77] Creating layer relu6
I0524 12:49:57.644928  9498 net.cpp:100] Creating Layer relu6
I0524 12:49:57.644933  9498 net.cpp:434] relu6 <- ip6
I0524 12:49:57.644938  9498 net.cpp:395] relu6 -> ip6 (in-place)
I0524 12:49:57.645556  9498 net.cpp:150] Setting up relu6
I0524 12:49:57.645570  9498 net.cpp:157] Top shape: 8 256 14 14 (401408)
I0524 12:49:57.645571  9498 net.cpp:165] Memory required for data: 2780954656
I0524 12:49:57.645576  9498 layer_factory.hpp:77] Creating layer ip7
I0524 12:49:57.645586  9498 net.cpp:100] Creating Layer ip7
I0524 12:49:57.645589  9498 net.cpp:434] ip7 <- ip6
I0524 12:49:57.645596  9498 net.cpp:408] ip7 -> ip7
I0524 12:49:57.646807  9498 net.cpp:150] Setting up ip7
I0524 12:49:57.646817  9498 net.cpp:157] Top shape: 8 512 14 14 (802816)
I0524 12:49:57.646821  9498 net.cpp:165] Memory required for data: 2784165920
I0524 12:49:57.646826  9498 layer_factory.hpp:77] Creating layer relu7
I0524 12:49:57.646831  9498 net.cpp:100] Creating Layer relu7
I0524 12:49:57.646833  9498 net.cpp:434] relu7 <- ip7
I0524 12:49:57.646838  9498 net.cpp:395] relu7 -> ip7 (in-place)
I0524 12:49:57.650629  9498 net.cpp:150] Setting up relu7
I0524 12:49:57.650642  9498 net.cpp:157] Top shape: 8 512 14 14 (802816)
I0524 12:49:57.650645  9498 net.cpp:165] Memory required for data: 2787377184
I0524 12:49:57.650648  9498 layer_factory.hpp:77] Creating layer ip7_relu7_0_split
I0524 12:49:57.650671  9498 net.cpp:100] Creating Layer ip7_relu7_0_split
I0524 12:49:57.650676  9498 net.cpp:434] ip7_relu7_0_split <- ip7
I0524 12:49:57.650681  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_0
I0524 12:49:57.650687  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_1
I0524 12:49:57.650692  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_2
I0524 12:49:57.650696  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_3
I0524 12:49:57.650910  9498 net.cpp:150] Setting up ip7_relu7_0_split
I0524 12:49:57.650918  9498 net.cpp:157] Top shape: 8 512 14 14 (802816)
I0524 12:49:57.650921  9498 net.cpp:157] Top shape: 8 512 14 14 (802816)
I0524 12:49:57.650924  9498 net.cpp:157] Top shape: 8 512 14 14 (802816)
I0524 12:49:57.650928  9498 net.cpp:157] Top shape: 8 512 14 14 (802816)
I0524 12:49:57.650930  9498 net.cpp:165] Memory required for data: 2800222240
I0524 12:49:57.650933  9498 layer_factory.hpp:77] Creating layer conv6_1
I0524 12:49:57.650943  9498 net.cpp:100] Creating Layer conv6_1
I0524 12:49:57.650946  9498 net.cpp:434] conv6_1 <- ip7_relu7_0_split_0
I0524 12:49:57.650952  9498 net.cpp:408] conv6_1 -> conv6_1
I0524 12:49:57.655064  9498 net.cpp:150] Setting up conv6_1
I0524 12:49:57.655077  9498 net.cpp:157] Top shape: 8 256 14 14 (401408)
I0524 12:49:57.655081  9498 net.cpp:165] Memory required for data: 2801827872
I0524 12:49:57.655102  9498 layer_factory.hpp:77] Creating layer conv6_1_relu
I0524 12:49:57.655108  9498 net.cpp:100] Creating Layer conv6_1_relu
I0524 12:49:57.655117  9498 net.cpp:434] conv6_1_relu <- conv6_1
I0524 12:49:57.655120  9498 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0524 12:49:57.655624  9498 net.cpp:150] Setting up conv6_1_relu
I0524 12:49:57.655635  9498 net.cpp:157] Top shape: 8 256 14 14 (401408)
I0524 12:49:57.655637  9498 net.cpp:165] Memory required for data: 2803433504
I0524 12:49:57.655642  9498 layer_factory.hpp:77] Creating layer conv6_2
I0524 12:49:57.655652  9498 net.cpp:100] Creating Layer conv6_2
I0524 12:49:57.655655  9498 net.cpp:434] conv6_2 <- conv6_1
I0524 12:49:57.655660  9498 net.cpp:408] conv6_2 -> conv6_2
I0524 12:49:57.661502  9498 net.cpp:150] Setting up conv6_2
I0524 12:49:57.661516  9498 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0524 12:49:57.661520  9498 net.cpp:165] Memory required for data: 2803834912
I0524 12:49:57.661537  9498 layer_factory.hpp:77] Creating layer conv6_2_relu
I0524 12:49:57.661545  9498 net.cpp:100] Creating Layer conv6_2_relu
I0524 12:49:57.661548  9498 net.cpp:434] conv6_2_relu <- conv6_2
I0524 12:49:57.661552  9498 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0524 12:49:57.662078  9498 net.cpp:150] Setting up conv6_2_relu
I0524 12:49:57.662089  9498 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0524 12:49:57.662092  9498 net.cpp:165] Memory required for data: 2804236320
I0524 12:49:57.662096  9498 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0524 12:49:57.662102  9498 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0524 12:49:57.662106  9498 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0524 12:49:57.662112  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0524 12:49:57.662118  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0524 12:49:57.662123  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0524 12:49:57.662129  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0524 12:49:57.662341  9498 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0524 12:49:57.662348  9498 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0524 12:49:57.662351  9498 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0524 12:49:57.662354  9498 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0524 12:49:57.662358  9498 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0524 12:49:57.662361  9498 net.cpp:165] Memory required for data: 2805841952
I0524 12:49:57.662364  9498 layer_factory.hpp:77] Creating layer conv7_1
I0524 12:49:57.662372  9498 net.cpp:100] Creating Layer conv7_1
I0524 12:49:57.662376  9498 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0524 12:49:57.662382  9498 net.cpp:408] conv7_1 -> conv7_1
I0524 12:49:57.668588  9498 net.cpp:150] Setting up conv7_1
I0524 12:49:57.668602  9498 net.cpp:157] Top shape: 8 128 7 7 (50176)
I0524 12:49:57.668606  9498 net.cpp:165] Memory required for data: 2806042656
I0524 12:49:57.668612  9498 layer_factory.hpp:77] Creating layer conv7_1_relu
I0524 12:49:57.668617  9498 net.cpp:100] Creating Layer conv7_1_relu
I0524 12:49:57.668620  9498 net.cpp:434] conv7_1_relu <- conv7_1
I0524 12:49:57.668625  9498 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0524 12:49:57.669344  9498 net.cpp:150] Setting up conv7_1_relu
I0524 12:49:57.669356  9498 net.cpp:157] Top shape: 8 128 7 7 (50176)
I0524 12:49:57.669359  9498 net.cpp:165] Memory required for data: 2806243360
I0524 12:49:57.669363  9498 layer_factory.hpp:77] Creating layer conv7_2
I0524 12:49:57.669371  9498 net.cpp:100] Creating Layer conv7_2
I0524 12:49:57.669375  9498 net.cpp:434] conv7_2 <- conv7_1
I0524 12:49:57.669381  9498 net.cpp:408] conv7_2 -> conv7_2
I0524 12:49:57.673116  9498 net.cpp:150] Setting up conv7_2
I0524 12:49:57.673128  9498 net.cpp:157] Top shape: 8 256 4 4 (32768)
I0524 12:49:57.673131  9498 net.cpp:165] Memory required for data: 2806374432
I0524 12:49:57.673136  9498 layer_factory.hpp:77] Creating layer conv7_2_relu
I0524 12:49:57.673143  9498 net.cpp:100] Creating Layer conv7_2_relu
I0524 12:49:57.673146  9498 net.cpp:434] conv7_2_relu <- conv7_2
I0524 12:49:57.673151  9498 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0524 12:49:57.673709  9498 net.cpp:150] Setting up conv7_2_relu
I0524 12:49:57.673720  9498 net.cpp:157] Top shape: 8 256 4 4 (32768)
I0524 12:49:57.673722  9498 net.cpp:165] Memory required for data: 2806505504
I0524 12:49:57.673725  9498 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0524 12:49:57.673732  9498 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0524 12:49:57.673735  9498 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0524 12:49:57.673740  9498 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0524 12:49:57.673748  9498 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0524 12:49:57.673753  9498 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0524 12:49:57.673928  9498 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0524 12:49:57.673935  9498 net.cpp:157] Top shape: 8 256 4 4 (32768)
I0524 12:49:57.673938  9498 net.cpp:157] Top shape: 8 256 4 4 (32768)
I0524 12:49:57.673941  9498 net.cpp:157] Top shape: 8 256 4 4 (32768)
I0524 12:49:57.673954  9498 net.cpp:165] Memory required for data: 2806898720
I0524 12:49:57.673957  9498 layer_factory.hpp:77] Creating layer conv12_norm
I0524 12:49:57.673964  9498 net.cpp:100] Creating Layer conv12_norm
I0524 12:49:57.673967  9498 net.cpp:434] conv12_norm <- conv12/dw_conv12/dw/relu_0_split_1
I0524 12:49:57.673974  9498 net.cpp:408] conv12_norm -> conv12_norm
I0524 12:49:57.674382  9498 net.cpp:150] Setting up conv12_norm
I0524 12:49:57.674388  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:57.674391  9498 net.cpp:165] Memory required for data: 2819743776
I0524 12:49:57.674396  9498 layer_factory.hpp:77] Creating layer conv12_norm_conv12_norm_0_split
I0524 12:49:57.674410  9498 net.cpp:100] Creating Layer conv12_norm_conv12_norm_0_split
I0524 12:49:57.674413  9498 net.cpp:434] conv12_norm_conv12_norm_0_split <- conv12_norm
I0524 12:49:57.674418  9498 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_0
I0524 12:49:57.674423  9498 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_1
I0524 12:49:57.674510  9498 net.cpp:150] Setting up conv12_norm_conv12_norm_0_split
I0524 12:49:57.674515  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:57.674518  9498 net.cpp:157] Top shape: 8 512 28 28 (3211264)
I0524 12:49:57.674521  9498 net.cpp:165] Memory required for data: 2845433888
I0524 12:49:57.674525  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc
I0524 12:49:57.674533  9498 net.cpp:100] Creating Layer conv12_norm_mbox_loc
I0524 12:49:57.674536  9498 net.cpp:434] conv12_norm_mbox_loc <- conv12_norm_conv12_norm_0_split_0
I0524 12:49:57.674543  9498 net.cpp:408] conv12_norm_mbox_loc -> conv12_norm_mbox_loc
I0524 12:49:57.678459  9498 net.cpp:150] Setting up conv12_norm_mbox_loc
I0524 12:49:57.678472  9498 net.cpp:157] Top shape: 8 24 28 28 (150528)
I0524 12:49:57.678474  9498 net.cpp:165] Memory required for data: 2846036000
I0524 12:49:57.678480  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_perm
I0524 12:49:57.678488  9498 net.cpp:100] Creating Layer conv12_norm_mbox_loc_perm
I0524 12:49:57.678491  9498 net.cpp:434] conv12_norm_mbox_loc_perm <- conv12_norm_mbox_loc
I0524 12:49:57.678498  9498 net.cpp:408] conv12_norm_mbox_loc_perm -> conv12_norm_mbox_loc_perm
I0524 12:49:57.678815  9498 net.cpp:150] Setting up conv12_norm_mbox_loc_perm
I0524 12:49:57.678824  9498 net.cpp:157] Top shape: 8 28 28 24 (150528)
I0524 12:49:57.678828  9498 net.cpp:165] Memory required for data: 2846638112
I0524 12:49:57.678829  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_flat
I0524 12:49:57.678835  9498 net.cpp:100] Creating Layer conv12_norm_mbox_loc_flat
I0524 12:49:57.678838  9498 net.cpp:434] conv12_norm_mbox_loc_flat <- conv12_norm_mbox_loc_perm
I0524 12:49:57.678841  9498 net.cpp:408] conv12_norm_mbox_loc_flat -> conv12_norm_mbox_loc_flat
I0524 12:49:57.678887  9498 net.cpp:150] Setting up conv12_norm_mbox_loc_flat
I0524 12:49:57.678894  9498 net.cpp:157] Top shape: 8 18816 (150528)
I0524 12:49:57.678896  9498 net.cpp:165] Memory required for data: 2847240224
I0524 12:49:57.678900  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf
I0524 12:49:57.678906  9498 net.cpp:100] Creating Layer conv12_norm_mbox_conf
I0524 12:49:57.678910  9498 net.cpp:434] conv12_norm_mbox_conf <- conv12_norm_conv12_norm_0_split_1
I0524 12:49:57.678915  9498 net.cpp:408] conv12_norm_mbox_conf -> conv12_norm_mbox_conf
I0524 12:49:57.685282  9498 net.cpp:150] Setting up conv12_norm_mbox_conf
I0524 12:49:57.685297  9498 net.cpp:157] Top shape: 8 36 28 28 (225792)
I0524 12:49:57.685299  9498 net.cpp:165] Memory required for data: 2848143392
I0524 12:49:57.685305  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_perm
I0524 12:49:57.685324  9498 net.cpp:100] Creating Layer conv12_norm_mbox_conf_perm
I0524 12:49:57.685328  9498 net.cpp:434] conv12_norm_mbox_conf_perm <- conv12_norm_mbox_conf
I0524 12:49:57.685333  9498 net.cpp:408] conv12_norm_mbox_conf_perm -> conv12_norm_mbox_conf_perm
I0524 12:49:57.685648  9498 net.cpp:150] Setting up conv12_norm_mbox_conf_perm
I0524 12:49:57.685655  9498 net.cpp:157] Top shape: 8 28 28 36 (225792)
I0524 12:49:57.685658  9498 net.cpp:165] Memory required for data: 2849046560
I0524 12:49:57.685662  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_flat
I0524 12:49:57.685667  9498 net.cpp:100] Creating Layer conv12_norm_mbox_conf_flat
I0524 12:49:57.685669  9498 net.cpp:434] conv12_norm_mbox_conf_flat <- conv12_norm_mbox_conf_perm
I0524 12:49:57.685674  9498 net.cpp:408] conv12_norm_mbox_conf_flat -> conv12_norm_mbox_conf_flat
I0524 12:49:57.685719  9498 net.cpp:150] Setting up conv12_norm_mbox_conf_flat
I0524 12:49:57.685724  9498 net.cpp:157] Top shape: 8 28224 (225792)
I0524 12:49:57.685727  9498 net.cpp:165] Memory required for data: 2849949728
I0524 12:49:57.685729  9498 layer_factory.hpp:77] Creating layer ip7_mbox_loc
I0524 12:49:57.685739  9498 net.cpp:100] Creating Layer ip7_mbox_loc
I0524 12:49:57.685741  9498 net.cpp:434] ip7_mbox_loc <- ip7_relu7_0_split_1
I0524 12:49:57.685747  9498 net.cpp:408] ip7_mbox_loc -> ip7_mbox_loc
I0524 12:49:57.689029  9498 net.cpp:150] Setting up ip7_mbox_loc
I0524 12:49:57.689043  9498 net.cpp:157] Top shape: 8 24 14 14 (37632)
I0524 12:49:57.689045  9498 net.cpp:165] Memory required for data: 2850100256
I0524 12:49:57.689051  9498 layer_factory.hpp:77] Creating layer ip7_mbox_loc_perm
I0524 12:49:57.689059  9498 net.cpp:100] Creating Layer ip7_mbox_loc_perm
I0524 12:49:57.689062  9498 net.cpp:434] ip7_mbox_loc_perm <- ip7_mbox_loc
I0524 12:49:57.689066  9498 net.cpp:408] ip7_mbox_loc_perm -> ip7_mbox_loc_perm
I0524 12:49:57.689359  9498 net.cpp:150] Setting up ip7_mbox_loc_perm
I0524 12:49:57.689366  9498 net.cpp:157] Top shape: 8 14 14 24 (37632)
I0524 12:49:57.689369  9498 net.cpp:165] Memory required for data: 2850250784
I0524 12:49:57.689373  9498 layer_factory.hpp:77] Creating layer ip7_mbox_loc_flat
I0524 12:49:57.689376  9498 net.cpp:100] Creating Layer ip7_mbox_loc_flat
I0524 12:49:57.689379  9498 net.cpp:434] ip7_mbox_loc_flat <- ip7_mbox_loc_perm
I0524 12:49:57.689385  9498 net.cpp:408] ip7_mbox_loc_flat -> ip7_mbox_loc_flat
I0524 12:49:57.689429  9498 net.cpp:150] Setting up ip7_mbox_loc_flat
I0524 12:49:57.689433  9498 net.cpp:157] Top shape: 8 4704 (37632)
I0524 12:49:57.689435  9498 net.cpp:165] Memory required for data: 2850401312
I0524 12:49:57.689438  9498 layer_factory.hpp:77] Creating layer ip7_mbox_conf
I0524 12:49:57.689455  9498 net.cpp:100] Creating Layer ip7_mbox_conf
I0524 12:49:57.689461  9498 net.cpp:434] ip7_mbox_conf <- ip7_relu7_0_split_2
I0524 12:49:57.689468  9498 net.cpp:408] ip7_mbox_conf -> ip7_mbox_conf
I0524 12:49:57.693634  9498 net.cpp:150] Setting up ip7_mbox_conf
I0524 12:49:57.693646  9498 net.cpp:157] Top shape: 8 36 14 14 (56448)
I0524 12:49:57.693648  9498 net.cpp:165] Memory required for data: 2850627104
I0524 12:49:57.693655  9498 layer_factory.hpp:77] Creating layer ip7_mbox_conf_perm
I0524 12:49:57.693677  9498 net.cpp:100] Creating Layer ip7_mbox_conf_perm
I0524 12:49:57.693681  9498 net.cpp:434] ip7_mbox_conf_perm <- ip7_mbox_conf
I0524 12:49:57.693686  9498 net.cpp:408] ip7_mbox_conf_perm -> ip7_mbox_conf_perm
I0524 12:49:57.693985  9498 net.cpp:150] Setting up ip7_mbox_conf_perm
I0524 12:49:57.693992  9498 net.cpp:157] Top shape: 8 14 14 36 (56448)
I0524 12:49:57.693994  9498 net.cpp:165] Memory required for data: 2850852896
I0524 12:49:57.693997  9498 layer_factory.hpp:77] Creating layer ip7_mbox_conf_flat
I0524 12:49:57.694002  9498 net.cpp:100] Creating Layer ip7_mbox_conf_flat
I0524 12:49:57.694006  9498 net.cpp:434] ip7_mbox_conf_flat <- ip7_mbox_conf_perm
I0524 12:49:57.694010  9498 net.cpp:408] ip7_mbox_conf_flat -> ip7_mbox_conf_flat
I0524 12:49:57.694065  9498 net.cpp:150] Setting up ip7_mbox_conf_flat
I0524 12:49:57.694070  9498 net.cpp:157] Top shape: 8 7056 (56448)
I0524 12:49:57.694074  9498 net.cpp:165] Memory required for data: 2851078688
I0524 12:49:57.694077  9498 layer_factory.hpp:77] Creating layer conv12/dw_mbox_priorbox
I0524 12:49:57.694083  9498 net.cpp:100] Creating Layer conv12/dw_mbox_priorbox
I0524 12:49:57.694095  9498 net.cpp:434] conv12/dw_mbox_priorbox <- conv12/dw_conv12/dw/relu_0_split_2
I0524 12:49:57.694100  9498 net.cpp:434] conv12/dw_mbox_priorbox <- data_data_0_split_1
I0524 12:49:57.694105  9498 net.cpp:408] conv12/dw_mbox_priorbox -> conv12/dw_mbox_priorbox
I0524 12:49:57.694157  9498 net.cpp:150] Setting up conv12/dw_mbox_priorbox
I0524 12:49:57.694164  9498 net.cpp:157] Top shape: 1 2 18816 (37632)
I0524 12:49:57.694166  9498 net.cpp:165] Memory required for data: 2851229216
I0524 12:49:57.694169  9498 layer_factory.hpp:77] Creating layer ip7_mbox_priorbox
I0524 12:49:57.694175  9498 net.cpp:100] Creating Layer ip7_mbox_priorbox
I0524 12:49:57.694177  9498 net.cpp:434] ip7_mbox_priorbox <- ip7_relu7_0_split_3
I0524 12:49:57.694180  9498 net.cpp:434] ip7_mbox_priorbox <- data_data_0_split_2
I0524 12:49:57.694185  9498 net.cpp:408] ip7_mbox_priorbox -> ip7_mbox_priorbox
I0524 12:49:57.694231  9498 net.cpp:150] Setting up ip7_mbox_priorbox
I0524 12:49:57.694234  9498 net.cpp:157] Top shape: 1 2 4704 (9408)
I0524 12:49:57.694237  9498 net.cpp:165] Memory required for data: 2851266848
I0524 12:49:57.694241  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0524 12:49:57.694247  9498 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0524 12:49:57.694249  9498 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0524 12:49:57.694257  9498 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0524 12:49:57.699965  9498 net.cpp:150] Setting up conv6_2_mbox_loc
I0524 12:49:57.699980  9498 net.cpp:157] Top shape: 8 24 7 7 (9408)
I0524 12:49:57.699982  9498 net.cpp:165] Memory required for data: 2851304480
I0524 12:49:57.699990  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0524 12:49:57.699995  9498 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0524 12:49:57.699998  9498 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0524 12:49:57.700006  9498 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0524 12:49:57.700302  9498 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0524 12:49:57.700309  9498 net.cpp:157] Top shape: 8 7 7 24 (9408)
I0524 12:49:57.700310  9498 net.cpp:165] Memory required for data: 2851342112
I0524 12:49:57.700314  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0524 12:49:57.700320  9498 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0524 12:49:57.700322  9498 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0524 12:49:57.700330  9498 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0524 12:49:57.700376  9498 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0524 12:49:57.700382  9498 net.cpp:157] Top shape: 8 1176 (9408)
I0524 12:49:57.700384  9498 net.cpp:165] Memory required for data: 2851379744
I0524 12:49:57.700387  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0524 12:49:57.700395  9498 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0524 12:49:57.700399  9498 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0524 12:49:57.700404  9498 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0524 12:49:57.703521  9498 net.cpp:150] Setting up conv6_2_mbox_conf
I0524 12:49:57.703533  9498 net.cpp:157] Top shape: 8 36 7 7 (14112)
I0524 12:49:57.703536  9498 net.cpp:165] Memory required for data: 2851436192
I0524 12:49:57.703542  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0524 12:49:57.703549  9498 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0524 12:49:57.703553  9498 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0524 12:49:57.703558  9498 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0524 12:49:57.703862  9498 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0524 12:49:57.703882  9498 net.cpp:157] Top shape: 8 7 7 36 (14112)
I0524 12:49:57.703886  9498 net.cpp:165] Memory required for data: 2851492640
I0524 12:49:57.703888  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0524 12:49:57.703893  9498 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0524 12:49:57.703896  9498 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0524 12:49:57.703902  9498 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0524 12:49:57.703950  9498 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0524 12:49:57.703956  9498 net.cpp:157] Top shape: 8 1764 (14112)
I0524 12:49:57.703958  9498 net.cpp:165] Memory required for data: 2851549088
I0524 12:49:57.703961  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0524 12:49:57.703969  9498 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0524 12:49:57.703971  9498 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0524 12:49:57.703975  9498 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0524 12:49:57.703980  9498 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0524 12:49:57.704030  9498 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0524 12:49:57.704035  9498 net.cpp:157] Top shape: 1 2 1176 (2352)
I0524 12:49:57.704038  9498 net.cpp:165] Memory required for data: 2851558496
I0524 12:49:57.704041  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0524 12:49:57.704051  9498 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0524 12:49:57.704053  9498 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_0
I0524 12:49:57.704059  9498 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0524 12:49:57.707094  9498 net.cpp:150] Setting up conv7_2_mbox_loc
I0524 12:49:57.707106  9498 net.cpp:157] Top shape: 8 16 4 4 (2048)
I0524 12:49:57.707109  9498 net.cpp:165] Memory required for data: 2851566688
I0524 12:49:57.707120  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0524 12:49:57.707126  9498 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0524 12:49:57.707130  9498 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0524 12:49:57.707136  9498 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0524 12:49:57.707429  9498 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0524 12:49:57.707435  9498 net.cpp:157] Top shape: 8 4 4 16 (2048)
I0524 12:49:57.707438  9498 net.cpp:165] Memory required for data: 2851574880
I0524 12:49:57.707442  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0524 12:49:57.707446  9498 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0524 12:49:57.707449  9498 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0524 12:49:57.707455  9498 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0524 12:49:57.707504  9498 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0524 12:49:57.707509  9498 net.cpp:157] Top shape: 8 256 (2048)
I0524 12:49:57.707512  9498 net.cpp:165] Memory required for data: 2851583072
I0524 12:49:57.707515  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0524 12:49:57.707523  9498 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0524 12:49:57.707526  9498 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_1
I0524 12:49:57.707533  9498 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0524 12:49:57.713282  9498 net.cpp:150] Setting up conv7_2_mbox_conf
I0524 12:49:57.713295  9498 net.cpp:157] Top shape: 8 24 4 4 (3072)
I0524 12:49:57.713299  9498 net.cpp:165] Memory required for data: 2851595360
I0524 12:49:57.713304  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0524 12:49:57.713310  9498 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0524 12:49:57.713315  9498 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0524 12:49:57.713320  9498 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0524 12:49:57.713615  9498 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0524 12:49:57.713623  9498 net.cpp:157] Top shape: 8 4 4 24 (3072)
I0524 12:49:57.713634  9498 net.cpp:165] Memory required for data: 2851607648
I0524 12:49:57.713637  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0524 12:49:57.713642  9498 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0524 12:49:57.713646  9498 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0524 12:49:57.713652  9498 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0524 12:49:57.713696  9498 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0524 12:49:57.713701  9498 net.cpp:157] Top shape: 8 384 (3072)
I0524 12:49:57.713704  9498 net.cpp:165] Memory required for data: 2851619936
I0524 12:49:57.713707  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0524 12:49:57.713713  9498 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0524 12:49:57.713716  9498 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_2
I0524 12:49:57.713721  9498 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0524 12:49:57.713726  9498 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0524 12:49:57.713778  9498 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0524 12:49:57.713783  9498 net.cpp:157] Top shape: 1 2 256 (512)
I0524 12:49:57.713785  9498 net.cpp:165] Memory required for data: 2851621984
I0524 12:49:57.713804  9498 layer_factory.hpp:77] Creating layer mbox_loc
I0524 12:49:57.713809  9498 net.cpp:100] Creating Layer mbox_loc
I0524 12:49:57.713814  9498 net.cpp:434] mbox_loc <- conv12_norm_mbox_loc_flat
I0524 12:49:57.713819  9498 net.cpp:434] mbox_loc <- ip7_mbox_loc_flat
I0524 12:49:57.713821  9498 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0524 12:49:57.713825  9498 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0524 12:49:57.713830  9498 net.cpp:408] mbox_loc -> mbox_loc
I0524 12:49:57.713881  9498 net.cpp:150] Setting up mbox_loc
I0524 12:49:57.713886  9498 net.cpp:157] Top shape: 8 24952 (199616)
I0524 12:49:57.713888  9498 net.cpp:165] Memory required for data: 2852420448
I0524 12:49:57.713891  9498 layer_factory.hpp:77] Creating layer mbox_conf
I0524 12:49:57.713897  9498 net.cpp:100] Creating Layer mbox_conf
I0524 12:49:57.713901  9498 net.cpp:434] mbox_conf <- conv12_norm_mbox_conf_flat
I0524 12:49:57.713904  9498 net.cpp:434] mbox_conf <- ip7_mbox_conf_flat
I0524 12:49:57.713907  9498 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0524 12:49:57.713912  9498 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0524 12:49:57.713915  9498 net.cpp:408] mbox_conf -> mbox_conf
I0524 12:49:57.713959  9498 net.cpp:150] Setting up mbox_conf
I0524 12:49:57.713964  9498 net.cpp:157] Top shape: 8 37428 (299424)
I0524 12:49:57.713968  9498 net.cpp:165] Memory required for data: 2853618144
I0524 12:49:57.713969  9498 layer_factory.hpp:77] Creating layer mbox_priorbox
I0524 12:49:57.713974  9498 net.cpp:100] Creating Layer mbox_priorbox
I0524 12:49:57.713979  9498 net.cpp:434] mbox_priorbox <- conv12/dw_mbox_priorbox
I0524 12:49:57.713982  9498 net.cpp:434] mbox_priorbox <- ip7_mbox_priorbox
I0524 12:49:57.713985  9498 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0524 12:49:57.713989  9498 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0524 12:49:57.713992  9498 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0524 12:49:57.714058  9498 net.cpp:150] Setting up mbox_priorbox
I0524 12:49:57.714064  9498 net.cpp:157] Top shape: 1 2 24952 (49904)
I0524 12:49:57.714066  9498 net.cpp:165] Memory required for data: 2853817760
I0524 12:49:57.714069  9498 layer_factory.hpp:77] Creating layer mbox_loss
I0524 12:49:57.714079  9498 net.cpp:100] Creating Layer mbox_loss
I0524 12:49:57.714082  9498 net.cpp:434] mbox_loss <- mbox_loc
I0524 12:49:57.714087  9498 net.cpp:434] mbox_loss <- mbox_conf
I0524 12:49:57.714089  9498 net.cpp:434] mbox_loss <- mbox_priorbox
I0524 12:49:57.714092  9498 net.cpp:434] mbox_loss <- label
I0524 12:49:57.714098  9498 net.cpp:408] mbox_loss -> mbox_loss
I0524 12:49:57.714226  9498 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0524 12:49:57.714470  9498 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0524 12:49:57.714488  9498 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0524 12:49:57.715540  9498 net.cpp:150] Setting up mbox_loss
I0524 12:49:57.715553  9498 net.cpp:157] Top shape: (1)
I0524 12:49:57.715555  9498 net.cpp:160]     with loss weight 1
I0524 12:49:57.715571  9498 net.cpp:165] Memory required for data: 2853817764
I0524 12:49:57.715574  9498 net.cpp:226] mbox_loss needs backward computation.
I0524 12:49:57.715581  9498 net.cpp:228] mbox_priorbox does not need backward computation.
I0524 12:49:57.715587  9498 net.cpp:226] mbox_conf needs backward computation.
I0524 12:49:57.715591  9498 net.cpp:226] mbox_loc needs backward computation.
I0524 12:49:57.715595  9498 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0524 12:49:57.715600  9498 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0524 12:49:57.715602  9498 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0524 12:49:57.715606  9498 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0524 12:49:57.715610  9498 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0524 12:49:57.715613  9498 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0524 12:49:57.715616  9498 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0524 12:49:57.715620  9498 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0524 12:49:57.715623  9498 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0524 12:49:57.715626  9498 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0524 12:49:57.715629  9498 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0524 12:49:57.715637  9498 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0524 12:49:57.715641  9498 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0524 12:49:57.715643  9498 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0524 12:49:57.715646  9498 net.cpp:228] ip7_mbox_priorbox does not need backward computation.
I0524 12:49:57.715651  9498 net.cpp:228] conv12/dw_mbox_priorbox does not need backward computation.
I0524 12:49:57.715656  9498 net.cpp:226] ip7_mbox_conf_flat needs backward computation.
I0524 12:49:57.715659  9498 net.cpp:226] ip7_mbox_conf_perm needs backward computation.
I0524 12:49:57.715662  9498 net.cpp:226] ip7_mbox_conf needs backward computation.
I0524 12:49:57.715667  9498 net.cpp:226] ip7_mbox_loc_flat needs backward computation.
I0524 12:49:57.715668  9498 net.cpp:226] ip7_mbox_loc_perm needs backward computation.
I0524 12:49:57.715672  9498 net.cpp:226] ip7_mbox_loc needs backward computation.
I0524 12:49:57.715675  9498 net.cpp:226] conv12_norm_mbox_conf_flat needs backward computation.
I0524 12:49:57.715679  9498 net.cpp:226] conv12_norm_mbox_conf_perm needs backward computation.
I0524 12:49:57.715682  9498 net.cpp:226] conv12_norm_mbox_conf needs backward computation.
I0524 12:49:57.715685  9498 net.cpp:226] conv12_norm_mbox_loc_flat needs backward computation.
I0524 12:49:57.715688  9498 net.cpp:226] conv12_norm_mbox_loc_perm needs backward computation.
I0524 12:49:57.715692  9498 net.cpp:226] conv12_norm_mbox_loc needs backward computation.
I0524 12:49:57.715695  9498 net.cpp:226] conv12_norm_conv12_norm_0_split needs backward computation.
I0524 12:49:57.715699  9498 net.cpp:226] conv12_norm needs backward computation.
I0524 12:49:57.715703  9498 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0524 12:49:57.715706  9498 net.cpp:226] conv7_2_relu needs backward computation.
I0524 12:49:57.715710  9498 net.cpp:226] conv7_2 needs backward computation.
I0524 12:49:57.715713  9498 net.cpp:226] conv7_1_relu needs backward computation.
I0524 12:49:57.715716  9498 net.cpp:226] conv7_1 needs backward computation.
I0524 12:49:57.715719  9498 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0524 12:49:57.715723  9498 net.cpp:226] conv6_2_relu needs backward computation.
I0524 12:49:57.715725  9498 net.cpp:226] conv6_2 needs backward computation.
I0524 12:49:57.715735  9498 net.cpp:226] conv6_1_relu needs backward computation.
I0524 12:49:57.715739  9498 net.cpp:226] conv6_1 needs backward computation.
I0524 12:49:57.715742  9498 net.cpp:226] ip7_relu7_0_split needs backward computation.
I0524 12:49:57.715745  9498 net.cpp:226] relu7 needs backward computation.
I0524 12:49:57.715749  9498 net.cpp:226] ip7 needs backward computation.
I0524 12:49:57.715752  9498 net.cpp:226] relu6 needs backward computation.
I0524 12:49:57.715754  9498 net.cpp:226] ip6 needs backward computation.
I0524 12:49:57.715757  9498 net.cpp:226] conv13/relu needs backward computation.
I0524 12:49:57.715760  9498 net.cpp:226] conv13/scale needs backward computation.
I0524 12:49:57.715764  9498 net.cpp:226] conv13/bn needs backward computation.
I0524 12:49:57.715766  9498 net.cpp:226] conv13 needs backward computation.
I0524 12:49:57.715770  9498 net.cpp:226] conv13/dw/relu needs backward computation.
I0524 12:49:57.715772  9498 net.cpp:226] conv13/dw/scale needs backward computation.
I0524 12:49:57.715776  9498 net.cpp:226] conv13/dw/bn needs backward computation.
I0524 12:49:57.715780  9498 net.cpp:226] conv13/dw needs backward computation.
I0524 12:49:57.715782  9498 net.cpp:226] conv12/relu needs backward computation.
I0524 12:49:57.715785  9498 net.cpp:226] conv12/scale needs backward computation.
I0524 12:49:57.715788  9498 net.cpp:226] conv12/bn needs backward computation.
I0524 12:49:57.715791  9498 net.cpp:226] conv12 needs backward computation.
I0524 12:49:57.715795  9498 net.cpp:226] sample_pooling needs backward computation.
I0524 12:49:57.715797  9498 net.cpp:226] conv12/dw_conv12/dw/relu_0_split needs backward computation.
I0524 12:49:57.715801  9498 net.cpp:226] conv12/dw/relu needs backward computation.
I0524 12:49:57.715804  9498 net.cpp:226] conv12/dw/scale needs backward computation.
I0524 12:49:57.715807  9498 net.cpp:226] conv12/dw/bn needs backward computation.
I0524 12:49:57.715809  9498 net.cpp:226] conv12/dw needs backward computation.
I0524 12:49:57.715813  9498 net.cpp:226] conv11/relu needs backward computation.
I0524 12:49:57.715816  9498 net.cpp:226] conv11/scale needs backward computation.
I0524 12:49:57.715819  9498 net.cpp:226] conv11/bn needs backward computation.
I0524 12:49:57.715822  9498 net.cpp:226] conv11 needs backward computation.
I0524 12:49:57.715826  9498 net.cpp:226] conv11/dw/relu needs backward computation.
I0524 12:49:57.715828  9498 net.cpp:226] conv11/dw/scale needs backward computation.
I0524 12:49:57.715831  9498 net.cpp:226] conv11/dw/bn needs backward computation.
I0524 12:49:57.715834  9498 net.cpp:226] conv11/dw needs backward computation.
I0524 12:49:57.715837  9498 net.cpp:226] conv10/relu needs backward computation.
I0524 12:49:57.715840  9498 net.cpp:226] conv10/scale needs backward computation.
I0524 12:49:57.715843  9498 net.cpp:226] conv10/bn needs backward computation.
I0524 12:49:57.715847  9498 net.cpp:226] conv10 needs backward computation.
I0524 12:49:57.715850  9498 net.cpp:226] conv10/dw/relu needs backward computation.
I0524 12:49:57.715852  9498 net.cpp:226] conv10/dw/scale needs backward computation.
I0524 12:49:57.715855  9498 net.cpp:226] conv10/dw/bn needs backward computation.
I0524 12:49:57.715858  9498 net.cpp:226] conv10/dw needs backward computation.
I0524 12:49:57.715862  9498 net.cpp:226] conv9/relu needs backward computation.
I0524 12:49:57.715864  9498 net.cpp:226] conv9/scale needs backward computation.
I0524 12:49:57.715867  9498 net.cpp:226] conv9/bn needs backward computation.
I0524 12:49:57.715869  9498 net.cpp:226] conv9 needs backward computation.
I0524 12:49:57.715873  9498 net.cpp:226] conv9/dw/relu needs backward computation.
I0524 12:49:57.715876  9498 net.cpp:226] conv9/dw/scale needs backward computation.
I0524 12:49:57.715879  9498 net.cpp:226] conv9/dw/bn needs backward computation.
I0524 12:49:57.715883  9498 net.cpp:226] conv9/dw needs backward computation.
I0524 12:49:57.715901  9498 net.cpp:226] conv8/relu needs backward computation.
I0524 12:49:57.715904  9498 net.cpp:226] conv8/scale needs backward computation.
I0524 12:49:57.715910  9498 net.cpp:226] conv8/bn needs backward computation.
I0524 12:49:57.715912  9498 net.cpp:226] conv8 needs backward computation.
I0524 12:49:57.715916  9498 net.cpp:226] conv8/dw/relu needs backward computation.
I0524 12:49:57.715919  9498 net.cpp:226] conv8/dw/scale needs backward computation.
I0524 12:49:57.715921  9498 net.cpp:226] conv8/dw/bn needs backward computation.
I0524 12:49:57.715924  9498 net.cpp:226] conv8/dw needs backward computation.
I0524 12:49:57.715929  9498 net.cpp:226] conv7/relu needs backward computation.
I0524 12:49:57.715930  9498 net.cpp:226] conv7/scale needs backward computation.
I0524 12:49:57.715934  9498 net.cpp:226] conv7/bn needs backward computation.
I0524 12:49:57.715936  9498 net.cpp:226] conv7 needs backward computation.
I0524 12:49:57.715939  9498 net.cpp:226] conv7/dw/relu needs backward computation.
I0524 12:49:57.715942  9498 net.cpp:226] conv7/dw/scale needs backward computation.
I0524 12:49:57.715945  9498 net.cpp:226] conv7/dw/bn needs backward computation.
I0524 12:49:57.715948  9498 net.cpp:226] conv7/dw needs backward computation.
I0524 12:49:57.715951  9498 net.cpp:226] conv6/relu needs backward computation.
I0524 12:49:57.715955  9498 net.cpp:226] conv6/scale needs backward computation.
I0524 12:49:57.715957  9498 net.cpp:226] conv6/bn needs backward computation.
I0524 12:49:57.715960  9498 net.cpp:226] conv6 needs backward computation.
I0524 12:49:57.715963  9498 net.cpp:226] conv6/dw/relu needs backward computation.
I0524 12:49:57.715966  9498 net.cpp:226] conv6/dw/scale needs backward computation.
I0524 12:49:57.715970  9498 net.cpp:226] conv6/dw/bn needs backward computation.
I0524 12:49:57.715972  9498 net.cpp:226] conv6/dw needs backward computation.
I0524 12:49:57.715975  9498 net.cpp:226] conv5/relu needs backward computation.
I0524 12:49:57.715978  9498 net.cpp:226] conv5/scale needs backward computation.
I0524 12:49:57.715981  9498 net.cpp:226] conv5/bn needs backward computation.
I0524 12:49:57.715983  9498 net.cpp:226] conv5 needs backward computation.
I0524 12:49:57.715987  9498 net.cpp:226] conv5/dw/relu needs backward computation.
I0524 12:49:57.715989  9498 net.cpp:226] conv5/dw/scale needs backward computation.
I0524 12:49:57.715992  9498 net.cpp:226] conv5/dw/bn needs backward computation.
I0524 12:49:57.715996  9498 net.cpp:226] conv5/dw needs backward computation.
I0524 12:49:57.715999  9498 net.cpp:226] conv4/relu needs backward computation.
I0524 12:49:57.716002  9498 net.cpp:226] conv4/scale needs backward computation.
I0524 12:49:57.716006  9498 net.cpp:226] conv4/bn needs backward computation.
I0524 12:49:57.716007  9498 net.cpp:226] conv4 needs backward computation.
I0524 12:49:57.716012  9498 net.cpp:226] conv4/dw/relu needs backward computation.
I0524 12:49:57.716014  9498 net.cpp:226] conv4/dw/scale needs backward computation.
I0524 12:49:57.716017  9498 net.cpp:226] conv4/dw/bn needs backward computation.
I0524 12:49:57.716019  9498 net.cpp:226] conv4/dw needs backward computation.
I0524 12:49:57.716023  9498 net.cpp:226] conv3/relu needs backward computation.
I0524 12:49:57.716025  9498 net.cpp:226] conv3/scale needs backward computation.
I0524 12:49:57.716028  9498 net.cpp:226] conv3/bn needs backward computation.
I0524 12:49:57.716030  9498 net.cpp:226] conv3 needs backward computation.
I0524 12:49:57.716034  9498 net.cpp:226] conv3/dw/relu needs backward computation.
I0524 12:49:57.716037  9498 net.cpp:226] conv3/dw/scale needs backward computation.
I0524 12:49:57.716039  9498 net.cpp:226] conv3/dw/bn needs backward computation.
I0524 12:49:57.716042  9498 net.cpp:226] conv3/dw needs backward computation.
I0524 12:49:57.716045  9498 net.cpp:226] conv2/relu needs backward computation.
I0524 12:49:57.716048  9498 net.cpp:226] conv2/scale needs backward computation.
I0524 12:49:57.716051  9498 net.cpp:226] conv2/bn needs backward computation.
I0524 12:49:57.716053  9498 net.cpp:226] conv2 needs backward computation.
I0524 12:49:57.716058  9498 net.cpp:226] conv2/dw/relu needs backward computation.
I0524 12:49:57.716063  9498 net.cpp:226] conv2/dw/scale needs backward computation.
I0524 12:49:57.716065  9498 net.cpp:226] conv2/dw/bn needs backward computation.
I0524 12:49:57.716068  9498 net.cpp:226] conv2/dw needs backward computation.
I0524 12:49:57.716073  9498 net.cpp:226] conv1/relu needs backward computation.
I0524 12:49:57.716074  9498 net.cpp:226] conv1/scale needs backward computation.
I0524 12:49:57.716078  9498 net.cpp:226] conv1/bn needs backward computation.
I0524 12:49:57.716080  9498 net.cpp:226] conv1 needs backward computation.
I0524 12:49:57.716084  9498 net.cpp:226] conv1/dw/relu needs backward computation.
I0524 12:49:57.716087  9498 net.cpp:226] conv1/dw/scale needs backward computation.
I0524 12:49:57.716090  9498 net.cpp:226] conv1/dw/bn needs backward computation.
I0524 12:49:57.716092  9498 net.cpp:226] conv1/dw needs backward computation.
I0524 12:49:57.716096  9498 net.cpp:226] conv0/relu needs backward computation.
I0524 12:49:57.716099  9498 net.cpp:226] conv0/scale needs backward computation.
I0524 12:49:57.716101  9498 net.cpp:226] conv0/bn needs backward computation.
I0524 12:49:57.716104  9498 net.cpp:226] conv0 needs backward computation.
I0524 12:49:57.716109  9498 net.cpp:228] data_data_0_split does not need backward computation.
I0524 12:49:57.716114  9498 net.cpp:228] data does not need backward computation.
I0524 12:49:57.716115  9498 net.cpp:270] This network produces output mbox_loss
I0524 12:49:57.716195  9498 net.cpp:283] Network initialization done.
I0524 12:49:57.717290  9498 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/Mobilenet448_ssd_test.prototxt
I0524 12:49:57.717301  9498 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0524 12:49:57.717308  9498 solver.cpp:196] Creating test net (#0) specified by test_net file: mobilessd_step1/Mobilenet448_ssd_test.prototxt
I0524 12:49:57.717998  9498 net.cpp:58] Initializing net from parameters: 
name: "MobileNet-SSD"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 448
      width: 448
      interp_mode: LINEAR
    }
    quant_enable: false
  }
  data_param {
    source: "/home/sx/data/VOCdevkit/VOC0712/lmdb/VOC0712_test_lmdb"
    batch_size: 2
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/home/sx/data/VOCdevkit/VOC0712/lmdb/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv0/bn"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv0/relu"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/dw/relu"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2/dw/scale"
  type: "Scale"
  bottom: "conv2/dw"
  top: "conv2/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/dw/relu"
  type: "ReLU"
  bottom: "conv2/dw"
  top: "conv2/dw"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv2/dw"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3/dw"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3/dw/scale"
  type: "Scale"
  bottom: "conv3/dw"
  top: "conv3/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/dw/relu"
  type: "ReLU"
  bottom: "conv3/dw"
  top: "conv3/dw"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv3/dw"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4/dw"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4/dw/bn"
  type: "BatchNorm"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4/dw/scale"
  type: "Scale"
  bottom: "conv4/dw"
  top: "conv4/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/dw/relu"
  type: "ReLU"
  bottom: "conv4/dw"
  top: "conv4/dw"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv4/dw"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4/bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv4/scale"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5/dw"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5/dw/scale"
  type: "Scale"
  bottom: "conv5/dw"
  top: "conv5/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/dw/relu"
  type: "ReLU"
  bottom: "conv5/dw"
  top: "conv5/dw"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv5/dw"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5/bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv5/scale"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/dw/relu"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv6/scale"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv6/relu"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7/dw"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv7/dw/bn"
  type: "BatchNorm"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7/dw/scale"
  type: "Scale"
  bottom: "conv7/dw"
  top: "conv7/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/dw/relu"
  type: "ReLU"
  bottom: "conv7/dw"
  top: "conv7/dw"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv7/dw"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7/bn"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv7/scale"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv7/relu"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8/dw"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv8/dw/bn"
  type: "BatchNorm"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8/dw/scale"
  type: "Scale"
  bottom: "conv8/dw"
  top: "conv8/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/dw/relu"
  type: "ReLU"
  bottom: "conv8/dw"
  top: "conv8/dw"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv8/dw"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv8/bn"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv8/scale"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv8/relu"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9/dw"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv9/dw/bn"
  type: "BatchNorm"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9/dw/scale"
  type: "Scale"
  bottom: "conv9/dw"
  top: "conv9/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/dw/relu"
  type: "ReLU"
  bottom: "conv9/dw"
  top: "conv9/dw"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv9/dw"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv9/bn"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv9/scale"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv9/relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv10/dw"
  type: "Convolution"
  bottom: "conv9"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv10/dw/bn"
  type: "BatchNorm"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10/dw/scale"
  type: "Scale"
  bottom: "conv10/dw"
  top: "conv10/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/dw/relu"
  type: "ReLU"
  bottom: "conv10/dw"
  top: "conv10/dw"
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "conv10/dw"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv10/bn"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv10/scale"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv10/relu"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11/dw"
  type: "Convolution"
  bottom: "conv10"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv11/dw/bn"
  type: "BatchNorm"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11/dw/scale"
  type: "Scale"
  bottom: "conv11/dw"
  top: "conv11/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/dw/relu"
  type: "ReLU"
  bottom: "conv11/dw"
  top: "conv11/dw"
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "conv11/dw"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv11/bn"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv11/scale"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv11/relu"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12/dw"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv12/dw/bn"
  type: "BatchNorm"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "conv12/dw/scale"
  type: "Scale"
  bottom: "conv12/dw"
  top: "conv12/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/dw/relu"
  type: "ReLU"
  bottom: "conv12/dw"
  top: "conv12/dw"
}
layer {
  name: "sample_pooling"
  type: "Convolution"
  bottom: "conv12/dw"
  top: "sample_pooling"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 2
    group: 512
    stride: 2
    weight_filler {
      type: "constant_array"
      value_array: 1
      value_array: 0
      value_array: 0
      value_array: 0
    }
  }
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "sample_pooling"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv12/bn"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv12/scale"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv12/relu"
  type: "ReLU"
  bottom: "conv12"
  top: "conv12"
}
layer {
  name: "conv13/dw"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv13/dw/bn"
  type: "BatchNorm"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13/dw/scale"
  type: "Scale"
  bottom: "conv13/dw"
  top: "conv13/dw"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/dw/relu"
  type: "ReLU"
  bottom: "conv13/dw"
  top: "conv13/dw"
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv13/dw"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0.1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv13/bn"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv13/scale"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "conv13/relu"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "ip6"
  type: "Convolution"
  bottom: "conv13"
  top: "ip6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip6"
  top: "ip6"
}
layer {
  name: "ip7"
  type: "Convolution"
  bottom: "ip6"
  top: "ip7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CAFFE
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "ip7"
  top: "ip7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "ip7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv12_norm"
  type: "Normalize"
  bottom: "conv12/dw"
  top: "conv12_norm"
  norm_param {
    across_spatial: false
    channel_shared: false
  }
}
layer {
  name: "conv12_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_loc"
  top: "conv12_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_loc_perm"
  top: "conv12_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv12_norm"
  top: "conv12_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv12_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv12_norm_mbox_conf"
  top: "conv12_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv12_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv12_norm_mbox_conf_perm"
  top: "conv12_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_loc"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_loc_perm"
  type: "Permute"
  bottom: "ip7_mbox_loc"
  top: "ip7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_loc_flat"
  type: "Flatten"
  bottom: "ip7_mbox_loc_perm"
  top: "ip7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "ip7_mbox_conf"
  type: "Convolution"
  bottom: "ip7"
  top: "ip7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip7_mbox_conf_perm"
  type: "Permute"
  bottom: "ip7_mbox_conf"
  top: "ip7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "ip7_mbox_conf_flat"
  type: "Flatten"
  bottom: "ip7_mbox_conf_perm"
  top: "ip7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv12/dw_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv12/dw"
  bottom: "data"
  top: "conv12/dw_mbox_priorbox"
  prior_box_param {
    min_size: 44.8
    max_size: 89.6
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "ip7_mbox_priorbox"
  type: "PriorBox"
  bottom: "ip7"
  bottom: "data"
  top: "ip7_mbox_priorbox"
  prior_box_param {
    min_size: 89.6
    max_size: 246.4
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 246.4
    max_size: 403.2
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
   
I0524 12:49:57.718341  9498 layer_factory.hpp:77] Creating layer data
I0524 12:49:57.718412  9498 net.cpp:100] Creating Layer data
I0524 12:49:57.718420  9498 net.cpp:408] data -> data
I0524 12:49:57.718442  9498 net.cpp:408] data -> label
I0524 12:49:57.720752  9547 db_lmdb.cpp:35] Opened lmdb /home/sx/data/VOCdevkit/VOC0712/lmdb/VOC0712_test_lmdb
I0524 12:49:57.723532  9498 annotated_data_layer.cpp:62] output data size: 2,3,448,448
I0524 12:49:57.729851  9498 net.cpp:150] Setting up data
I0524 12:49:57.729871  9498 net.cpp:157] Top shape: 2 3 448 448 (1204224)
I0524 12:49:57.729874  9498 net.cpp:157] Top shape: 1 1 1 8 (8)
I0524 12:49:57.729876  9498 net.cpp:165] Memory required for data: 4816928
I0524 12:49:57.729882  9498 layer_factory.hpp:77] Creating layer data_data_0_split
I0524 12:49:57.729892  9498 net.cpp:100] Creating Layer data_data_0_split
I0524 12:49:57.729907  9498 net.cpp:434] data_data_0_split <- data
I0524 12:49:57.729913  9498 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0524 12:49:57.729923  9498 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0524 12:49:57.729926  9498 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0524 12:49:57.729933  9498 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0524 12:49:57.729936  9498 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0524 12:49:57.730222  9498 net.cpp:150] Setting up data_data_0_split
I0524 12:49:57.730231  9498 net.cpp:157] Top shape: 2 3 448 448 (1204224)
I0524 12:49:57.730235  9498 net.cpp:157] Top shape: 2 3 448 448 (1204224)
I0524 12:49:57.730238  9498 net.cpp:157] Top shape: 2 3 448 448 (1204224)
I0524 12:49:57.730242  9498 net.cpp:157] Top shape: 2 3 448 448 (1204224)
I0524 12:49:57.730244  9498 net.cpp:157] Top shape: 2 3 448 448 (1204224)
I0524 12:49:57.730247  9498 net.cpp:165] Memory required for data: 28901408
I0524 12:49:57.730252  9498 layer_factory.hpp:77] Creating layer conv0
I0524 12:49:57.730262  9498 net.cpp:100] Creating Layer conv0
I0524 12:49:57.730264  9498 net.cpp:434] conv0 <- data_data_0_split_0
I0524 12:49:57.730270  9498 net.cpp:408] conv0 -> conv0
I0524 12:49:57.733619  9498 net.cpp:150] Setting up conv0
I0524 12:49:57.733634  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.733637  9498 net.cpp:165] Memory required for data: 41746464
I0524 12:49:57.733647  9498 layer_factory.hpp:77] Creating layer conv0/bn
I0524 12:49:57.733654  9498 net.cpp:100] Creating Layer conv0/bn
I0524 12:49:57.733656  9498 net.cpp:434] conv0/bn <- conv0
I0524 12:49:57.733660  9498 net.cpp:395] conv0/bn -> conv0 (in-place)
I0524 12:49:57.734313  9498 net.cpp:150] Setting up conv0/bn
I0524 12:49:57.734323  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.734336  9498 net.cpp:165] Memory required for data: 54591520
I0524 12:49:57.734345  9498 layer_factory.hpp:77] Creating layer conv0/scale
I0524 12:49:57.734354  9498 net.cpp:100] Creating Layer conv0/scale
I0524 12:49:57.734356  9498 net.cpp:434] conv0/scale <- conv0
I0524 12:49:57.734360  9498 net.cpp:395] conv0/scale -> conv0 (in-place)
I0524 12:49:57.734450  9498 layer_factory.hpp:77] Creating layer conv0/scale
I0524 12:49:57.734803  9498 net.cpp:150] Setting up conv0/scale
I0524 12:49:57.734812  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.734814  9498 net.cpp:165] Memory required for data: 67436576
I0524 12:49:57.734820  9498 layer_factory.hpp:77] Creating layer conv0/relu
I0524 12:49:57.734827  9498 net.cpp:100] Creating Layer conv0/relu
I0524 12:49:57.734829  9498 net.cpp:434] conv0/relu <- conv0
I0524 12:49:57.734833  9498 net.cpp:395] conv0/relu -> conv0 (in-place)
I0524 12:49:57.735584  9498 net.cpp:150] Setting up conv0/relu
I0524 12:49:57.735597  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.735600  9498 net.cpp:165] Memory required for data: 80281632
I0524 12:49:57.735603  9498 layer_factory.hpp:77] Creating layer conv1/dw
I0524 12:49:57.735613  9498 net.cpp:100] Creating Layer conv1/dw
I0524 12:49:57.735617  9498 net.cpp:434] conv1/dw <- conv0
I0524 12:49:57.735622  9498 net.cpp:408] conv1/dw -> conv1/dw
I0524 12:49:57.736238  9498 net.cpp:150] Setting up conv1/dw
I0524 12:49:57.736248  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.736250  9498 net.cpp:165] Memory required for data: 93126688
I0524 12:49:57.736255  9498 layer_factory.hpp:77] Creating layer conv1/dw/bn
I0524 12:49:57.736260  9498 net.cpp:100] Creating Layer conv1/dw/bn
I0524 12:49:57.736263  9498 net.cpp:434] conv1/dw/bn <- conv1/dw
I0524 12:49:57.736268  9498 net.cpp:395] conv1/dw/bn -> conv1/dw (in-place)
I0524 12:49:57.736857  9498 net.cpp:150] Setting up conv1/dw/bn
I0524 12:49:57.736865  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.736867  9498 net.cpp:165] Memory required for data: 105971744
I0524 12:49:57.736876  9498 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0524 12:49:57.736892  9498 net.cpp:100] Creating Layer conv1/dw/scale
I0524 12:49:57.736896  9498 net.cpp:434] conv1/dw/scale <- conv1/dw
I0524 12:49:57.736901  9498 net.cpp:395] conv1/dw/scale -> conv1/dw (in-place)
I0524 12:49:57.737001  9498 layer_factory.hpp:77] Creating layer conv1/dw/scale
I0524 12:49:57.737951  9498 net.cpp:150] Setting up conv1/dw/scale
I0524 12:49:57.737962  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.737964  9498 net.cpp:165] Memory required for data: 118816800
I0524 12:49:57.737972  9498 layer_factory.hpp:77] Creating layer conv1/dw/relu
I0524 12:49:57.737977  9498 net.cpp:100] Creating Layer conv1/dw/relu
I0524 12:49:57.737979  9498 net.cpp:434] conv1/dw/relu <- conv1/dw
I0524 12:49:57.737985  9498 net.cpp:395] conv1/dw/relu -> conv1/dw (in-place)
I0524 12:49:57.738538  9498 net.cpp:150] Setting up conv1/dw/relu
I0524 12:49:57.738549  9498 net.cpp:157] Top shape: 2 32 224 224 (3211264)
I0524 12:49:57.738553  9498 net.cpp:165] Memory required for data: 131661856
I0524 12:49:57.738555  9498 layer_factory.hpp:77] Creating layer conv1
I0524 12:49:57.738574  9498 net.cpp:100] Creating Layer conv1
I0524 12:49:57.738576  9498 net.cpp:434] conv1 <- conv1/dw
I0524 12:49:57.738581  9498 net.cpp:408] conv1 -> conv1
I0524 12:49:57.741499  9498 net.cpp:150] Setting up conv1
I0524 12:49:57.741514  9498 net.cpp:157] Top shape: 2 64 224 224 (6422528)
I0524 12:49:57.741518  9498 net.cpp:165] Memory required for data: 157351968
I0524 12:49:57.741524  9498 layer_factory.hpp:77] Creating layer conv1/bn
I0524 12:49:57.741531  9498 net.cpp:100] Creating Layer conv1/bn
I0524 12:49:57.741535  9498 net.cpp:434] conv1/bn <- conv1
I0524 12:49:57.741540  9498 net.cpp:395] conv1/bn -> conv1 (in-place)
I0524 12:49:57.742197  9498 net.cpp:150] Setting up conv1/bn
I0524 12:49:57.742206  9498 net.cpp:157] Top shape: 2 64 224 224 (6422528)
I0524 12:49:57.742209  9498 net.cpp:165] Memory required for data: 183042080
I0524 12:49:57.742215  9498 layer_factory.hpp:77] Creating layer conv1/scale
I0524 12:49:57.742223  9498 net.cpp:100] Creating Layer conv1/scale
I0524 12:49:57.742225  9498 net.cpp:434] conv1/scale <- conv1
I0524 12:49:57.742230  9498 net.cpp:395] conv1/scale -> conv1 (in-place)
I0524 12:49:57.742322  9498 layer_factory.hpp:77] Creating layer conv1/scale
I0524 12:49:57.742630  9498 net.cpp:150] Setting up conv1/scale
I0524 12:49:57.742638  9498 net.cpp:157] Top shape: 2 64 224 224 (6422528)
I0524 12:49:57.742641  9498 net.cpp:165] Memory required for data: 208732192
I0524 12:49:57.742650  9498 layer_factory.hpp:77] Creating layer conv1/relu
I0524 12:49:57.742664  9498 net.cpp:100] Creating Layer conv1/relu
I0524 12:49:57.742667  9498 net.cpp:434] conv1/relu <- conv1
I0524 12:49:57.742672  9498 net.cpp:395] conv1/relu -> conv1 (in-place)
I0524 12:49:57.746260  9498 net.cpp:150] Setting up conv1/relu
I0524 12:49:57.746274  9498 net.cpp:157] Top shape: 2 64 224 224 (6422528)
I0524 12:49:57.746277  9498 net.cpp:165] Memory required for data: 234422304
I0524 12:49:57.746281  9498 layer_factory.hpp:77] Creating layer conv2/dw
I0524 12:49:57.746290  9498 net.cpp:100] Creating Layer conv2/dw
I0524 12:49:57.746294  9498 net.cpp:434] conv2/dw <- conv1
I0524 12:49:57.746304  9498 net.cpp:408] conv2/dw -> conv2/dw
I0524 12:49:57.746919  9498 net.cpp:150] Setting up conv2/dw
I0524 12:49:57.746928  9498 net.cpp:157] Top shape: 2 64 112 112 (1605632)
I0524 12:49:57.746932  9498 net.cpp:165] Memory required for data: 240844832
I0524 12:49:57.746937  9498 layer_factory.hpp:77] Creating layer conv2/dw/bn
I0524 12:49:57.746942  9498 net.cpp:100] Creating Layer conv2/dw/bn
I0524 12:49:57.746944  9498 net.cpp:434] conv2/dw/bn <- conv2/dw
I0524 12:49:57.746949  9498 net.cpp:395] conv2/dw/bn -> conv2/dw (in-place)
I0524 12:49:57.747540  9498 net.cpp:150] Setting up conv2/dw/bn
I0524 12:49:57.747550  9498 net.cpp:157] Top shape: 2 64 112 112 (1605632)
I0524 12:49:57.747552  9498 net.cpp:165] Memory required for data: 247267360
I0524 12:49:57.747558  9498 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0524 12:49:57.747576  9498 net.cpp:100] Creating Layer conv2/dw/scale
I0524 12:49:57.747579  9498 net.cpp:434] conv2/dw/scale <- conv2/dw
I0524 12:49:57.747583  9498 net.cpp:395] conv2/dw/scale -> conv2/dw (in-place)
I0524 12:49:57.747684  9498 layer_factory.hpp:77] Creating layer conv2/dw/scale
I0524 12:49:57.748005  9498 net.cpp:150] Setting up conv2/dw/scale
I0524 12:49:57.748014  9498 net.cpp:157] Top shape: 2 64 112 112 (1605632)
I0524 12:49:57.748018  9498 net.cpp:165] Memory required for data: 253689888
I0524 12:49:57.748021  9498 layer_factory.hpp:77] Creating layer conv2/dw/relu
I0524 12:49:57.748026  9498 net.cpp:100] Creating Layer conv2/dw/relu
I0524 12:49:57.748029  9498 net.cpp:434] conv2/dw/relu <- conv2/dw
I0524 12:49:57.748034  9498 net.cpp:395] conv2/dw/relu -> conv2/dw (in-place)
I0524 12:49:57.748566  9498 net.cpp:150] Setting up conv2/dw/relu
I0524 12:49:57.748577  9498 net.cpp:157] Top shape: 2 64 112 112 (1605632)
I0524 12:49:57.748581  9498 net.cpp:165] Memory required for data: 260112416
I0524 12:49:57.748584  9498 layer_factory.hpp:77] Creating layer conv2
I0524 12:49:57.748592  9498 net.cpp:100] Creating Layer conv2
I0524 12:49:57.748595  9498 net.cpp:434] conv2 <- conv2/dw
I0524 12:49:57.748602  9498 net.cpp:408] conv2 -> conv2
I0524 12:49:57.751319  9498 net.cpp:150] Setting up conv2
I0524 12:49:57.751332  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.751335  9498 net.cpp:165] Memory required for data: 272957472
I0524 12:49:57.751340  9498 layer_factory.hpp:77] Creating layer conv2/bn
I0524 12:49:57.751346  9498 net.cpp:100] Creating Layer conv2/bn
I0524 12:49:57.751349  9498 net.cpp:434] conv2/bn <- conv2
I0524 12:49:57.751353  9498 net.cpp:395] conv2/bn -> conv2 (in-place)
I0524 12:49:57.751951  9498 net.cpp:150] Setting up conv2/bn
I0524 12:49:57.751962  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.751965  9498 net.cpp:165] Memory required for data: 285802528
I0524 12:49:57.751971  9498 layer_factory.hpp:77] Creating layer conv2/scale
I0524 12:49:57.751977  9498 net.cpp:100] Creating Layer conv2/scale
I0524 12:49:57.751981  9498 net.cpp:434] conv2/scale <- conv2
I0524 12:49:57.751986  9498 net.cpp:395] conv2/scale -> conv2 (in-place)
I0524 12:49:57.752077  9498 layer_factory.hpp:77] Creating layer conv2/scale
I0524 12:49:57.752414  9498 net.cpp:150] Setting up conv2/scale
I0524 12:49:57.752427  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.752430  9498 net.cpp:165] Memory required for data: 298647584
I0524 12:49:57.752436  9498 layer_factory.hpp:77] Creating layer conv2/relu
I0524 12:49:57.752447  9498 net.cpp:100] Creating Layer conv2/relu
I0524 12:49:57.752452  9498 net.cpp:434] conv2/relu <- conv2
I0524 12:49:57.752456  9498 net.cpp:395] conv2/relu -> conv2 (in-place)
I0524 12:49:57.753234  9498 net.cpp:150] Setting up conv2/relu
I0524 12:49:57.753248  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.753252  9498 net.cpp:165] Memory required for data: 311492640
I0524 12:49:57.753254  9498 layer_factory.hpp:77] Creating layer conv3/dw
I0524 12:49:57.753263  9498 net.cpp:100] Creating Layer conv3/dw
I0524 12:49:57.753268  9498 net.cpp:434] conv3/dw <- conv2
I0524 12:49:57.753273  9498 net.cpp:408] conv3/dw -> conv3/dw
I0524 12:49:57.753881  9498 net.cpp:150] Setting up conv3/dw
I0524 12:49:57.753890  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.753892  9498 net.cpp:165] Memory required for data: 324337696
I0524 12:49:57.753896  9498 layer_factory.hpp:77] Creating layer conv3/dw/bn
I0524 12:49:57.753901  9498 net.cpp:100] Creating Layer conv3/dw/bn
I0524 12:49:57.753903  9498 net.cpp:434] conv3/dw/bn <- conv3/dw
I0524 12:49:57.753909  9498 net.cpp:395] conv3/dw/bn -> conv3/dw (in-place)
I0524 12:49:57.754472  9498 net.cpp:150] Setting up conv3/dw/bn
I0524 12:49:57.754478  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.754482  9498 net.cpp:165] Memory required for data: 337182752
I0524 12:49:57.754492  9498 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0524 12:49:57.754508  9498 net.cpp:100] Creating Layer conv3/dw/scale
I0524 12:49:57.754511  9498 net.cpp:434] conv3/dw/scale <- conv3/dw
I0524 12:49:57.754514  9498 net.cpp:395] conv3/dw/scale -> conv3/dw (in-place)
I0524 12:49:57.754604  9498 layer_factory.hpp:77] Creating layer conv3/dw/scale
I0524 12:49:57.754904  9498 net.cpp:150] Setting up conv3/dw/scale
I0524 12:49:57.754909  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.754912  9498 net.cpp:165] Memory required for data: 350027808
I0524 12:49:57.754917  9498 layer_factory.hpp:77] Creating layer conv3/dw/relu
I0524 12:49:57.754925  9498 net.cpp:100] Creating Layer conv3/dw/relu
I0524 12:49:57.754927  9498 net.cpp:434] conv3/dw/relu <- conv3/dw
I0524 12:49:57.754930  9498 net.cpp:395] conv3/dw/relu -> conv3/dw (in-place)
I0524 12:49:57.755430  9498 net.cpp:150] Setting up conv3/dw/relu
I0524 12:49:57.755442  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.755445  9498 net.cpp:165] Memory required for data: 362872864
I0524 12:49:57.755448  9498 layer_factory.hpp:77] Creating layer conv3
I0524 12:49:57.755456  9498 net.cpp:100] Creating Layer conv3
I0524 12:49:57.755458  9498 net.cpp:434] conv3 <- conv3/dw
I0524 12:49:57.755465  9498 net.cpp:408] conv3 -> conv3
I0524 12:49:57.758249  9498 net.cpp:150] Setting up conv3
I0524 12:49:57.758261  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.758265  9498 net.cpp:165] Memory required for data: 375717920
I0524 12:49:57.758270  9498 layer_factory.hpp:77] Creating layer conv3/bn
I0524 12:49:57.758275  9498 net.cpp:100] Creating Layer conv3/bn
I0524 12:49:57.758278  9498 net.cpp:434] conv3/bn <- conv3
I0524 12:49:57.758285  9498 net.cpp:395] conv3/bn -> conv3 (in-place)
I0524 12:49:57.758870  9498 net.cpp:150] Setting up conv3/bn
I0524 12:49:57.758878  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.758882  9498 net.cpp:165] Memory required for data: 388562976
I0524 12:49:57.758886  9498 layer_factory.hpp:77] Creating layer conv3/scale
I0524 12:49:57.758893  9498 net.cpp:100] Creating Layer conv3/scale
I0524 12:49:57.758895  9498 net.cpp:434] conv3/scale <- conv3
I0524 12:49:57.758899  9498 net.cpp:395] conv3/scale -> conv3 (in-place)
I0524 12:49:57.758988  9498 layer_factory.hpp:77] Creating layer conv3/scale
I0524 12:49:57.759310  9498 net.cpp:150] Setting up conv3/scale
I0524 12:49:57.759317  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.759320  9498 net.cpp:165] Memory required for data: 401408032
I0524 12:49:57.759325  9498 layer_factory.hpp:77] Creating layer conv3/relu
I0524 12:49:57.759330  9498 net.cpp:100] Creating Layer conv3/relu
I0524 12:49:57.759332  9498 net.cpp:434] conv3/relu <- conv3
I0524 12:49:57.759338  9498 net.cpp:395] conv3/relu -> conv3 (in-place)
I0524 12:49:57.762956  9498 net.cpp:150] Setting up conv3/relu
I0524 12:49:57.762970  9498 net.cpp:157] Top shape: 2 128 112 112 (3211264)
I0524 12:49:57.762974  9498 net.cpp:165] Memory required for data: 414253088
I0524 12:49:57.762977  9498 layer_factory.hpp:77] Creating layer conv4/dw
I0524 12:49:57.762987  9498 net.cpp:100] Creating Layer conv4/dw
I0524 12:49:57.762990  9498 net.cpp:434] conv4/dw <- conv3
I0524 12:49:57.762995  9498 net.cpp:408] conv4/dw -> conv4/dw
I0524 12:49:57.763640  9498 net.cpp:150] Setting up conv4/dw
I0524 12:49:57.763666  9498 net.cpp:157] Top shape: 2 128 56 56 (802816)
I0524 12:49:57.763669  9498 net.cpp:165] Memory required for data: 417464352
I0524 12:49:57.763674  9498 layer_factory.hpp:77] Creating layer conv4/dw/bn
I0524 12:49:57.763679  9498 net.cpp:100] Creating Layer conv4/dw/bn
I0524 12:49:57.763682  9498 net.cpp:434] conv4/dw/bn <- conv4/dw
I0524 12:49:57.763686  9498 net.cpp:395] conv4/dw/bn -> conv4/dw (in-place)
I0524 12:49:57.764233  9498 net.cpp:150] Setting up conv4/dw/bn
I0524 12:49:57.764240  9498 net.cpp:157] Top shape: 2 128 56 56 (802816)
I0524 12:49:57.764242  9498 net.cpp:165] Memory required for data: 420675616
I0524 12:49:57.764247  9498 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0524 12:49:57.764269  9498 net.cpp:100] Creating Layer conv4/dw/scale
I0524 12:49:57.764272  9498 net.cpp:434] conv4/dw/scale <- conv4/dw
I0524 12:49:57.764276  9498 net.cpp:395] conv4/dw/scale -> conv4/dw (in-place)
I0524 12:49:57.764379  9498 layer_factory.hpp:77] Creating layer conv4/dw/scale
I0524 12:49:57.764691  9498 net.cpp:150] Setting up conv4/dw/scale
I0524 12:49:57.764700  9498 net.cpp:157] Top shape: 2 128 56 56 (802816)
I0524 12:49:57.764703  9498 net.cpp:165] Memory required for data: 423886880
I0524 12:49:57.764708  9498 layer_factory.hpp:77] Creating layer conv4/dw/relu
I0524 12:49:57.764712  9498 net.cpp:100] Creating Layer conv4/dw/relu
I0524 12:49:57.764715  9498 net.cpp:434] conv4/dw/relu <- conv4/dw
I0524 12:49:57.764719  9498 net.cpp:395] conv4/dw/relu -> conv4/dw (in-place)
I0524 12:49:57.765229  9498 net.cpp:150] Setting up conv4/dw/relu
I0524 12:49:57.765241  9498 net.cpp:157] Top shape: 2 128 56 56 (802816)
I0524 12:49:57.765244  9498 net.cpp:165] Memory required for data: 427098144
I0524 12:49:57.765247  9498 layer_factory.hpp:77] Creating layer conv4
I0524 12:49:57.765256  9498 net.cpp:100] Creating Layer conv4
I0524 12:49:57.765259  9498 net.cpp:434] conv4 <- conv4/dw
I0524 12:49:57.765264  9498 net.cpp:408] conv4 -> conv4
I0524 12:49:57.768057  9498 net.cpp:150] Setting up conv4
I0524 12:49:57.768069  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.768072  9498 net.cpp:165] Memory required for data: 433520672
I0524 12:49:57.768079  9498 layer_factory.hpp:77] Creating layer conv4/bn
I0524 12:49:57.768083  9498 net.cpp:100] Creating Layer conv4/bn
I0524 12:49:57.768086  9498 net.cpp:434] conv4/bn <- conv4
I0524 12:49:57.768092  9498 net.cpp:395] conv4/bn -> conv4 (in-place)
I0524 12:49:57.768668  9498 net.cpp:150] Setting up conv4/bn
I0524 12:49:57.768676  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.768677  9498 net.cpp:165] Memory required for data: 439943200
I0524 12:49:57.768683  9498 layer_factory.hpp:77] Creating layer conv4/scale
I0524 12:49:57.768689  9498 net.cpp:100] Creating Layer conv4/scale
I0524 12:49:57.768692  9498 net.cpp:434] conv4/scale <- conv4
I0524 12:49:57.768697  9498 net.cpp:395] conv4/scale -> conv4 (in-place)
I0524 12:49:57.768785  9498 layer_factory.hpp:77] Creating layer conv4/scale
I0524 12:49:57.769098  9498 net.cpp:150] Setting up conv4/scale
I0524 12:49:57.769104  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.769107  9498 net.cpp:165] Memory required for data: 446365728
I0524 12:49:57.769111  9498 layer_factory.hpp:77] Creating layer conv4/relu
I0524 12:49:57.769117  9498 net.cpp:100] Creating Layer conv4/relu
I0524 12:49:57.769120  9498 net.cpp:434] conv4/relu <- conv4
I0524 12:49:57.769124  9498 net.cpp:395] conv4/relu -> conv4 (in-place)
I0524 12:49:57.769862  9498 net.cpp:150] Setting up conv4/relu
I0524 12:49:57.769876  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.769877  9498 net.cpp:165] Memory required for data: 452788256
I0524 12:49:57.769881  9498 layer_factory.hpp:77] Creating layer conv5/dw
I0524 12:49:57.769889  9498 net.cpp:100] Creating Layer conv5/dw
I0524 12:49:57.769892  9498 net.cpp:434] conv5/dw <- conv4
I0524 12:49:57.769898  9498 net.cpp:408] conv5/dw -> conv5/dw
I0524 12:49:57.770510  9498 net.cpp:150] Setting up conv5/dw
I0524 12:49:57.770519  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.770522  9498 net.cpp:165] Memory required for data: 459210784
I0524 12:49:57.770527  9498 layer_factory.hpp:77] Creating layer conv5/dw/bn
I0524 12:49:57.770532  9498 net.cpp:100] Creating Layer conv5/dw/bn
I0524 12:49:57.770535  9498 net.cpp:434] conv5/dw/bn <- conv5/dw
I0524 12:49:57.770540  9498 net.cpp:395] conv5/dw/bn -> conv5/dw (in-place)
I0524 12:49:57.771081  9498 net.cpp:150] Setting up conv5/dw/bn
I0524 12:49:57.771087  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.771090  9498 net.cpp:165] Memory required for data: 465633312
I0524 12:49:57.771096  9498 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0524 12:49:57.771102  9498 net.cpp:100] Creating Layer conv5/dw/scale
I0524 12:49:57.771121  9498 net.cpp:434] conv5/dw/scale <- conv5/dw
I0524 12:49:57.771127  9498 net.cpp:395] conv5/dw/scale -> conv5/dw (in-place)
I0524 12:49:57.771224  9498 layer_factory.hpp:77] Creating layer conv5/dw/scale
I0524 12:49:57.771517  9498 net.cpp:150] Setting up conv5/dw/scale
I0524 12:49:57.771523  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.771525  9498 net.cpp:165] Memory required for data: 472055840
I0524 12:49:57.771530  9498 layer_factory.hpp:77] Creating layer conv5/dw/relu
I0524 12:49:57.771534  9498 net.cpp:100] Creating Layer conv5/dw/relu
I0524 12:49:57.771538  9498 net.cpp:434] conv5/dw/relu <- conv5/dw
I0524 12:49:57.771544  9498 net.cpp:395] conv5/dw/relu -> conv5/dw (in-place)
I0524 12:49:57.772025  9498 net.cpp:150] Setting up conv5/dw/relu
I0524 12:49:57.772037  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.772038  9498 net.cpp:165] Memory required for data: 478478368
I0524 12:49:57.772042  9498 layer_factory.hpp:77] Creating layer conv5
I0524 12:49:57.772049  9498 net.cpp:100] Creating Layer conv5
I0524 12:49:57.772053  9498 net.cpp:434] conv5 <- conv5/dw
I0524 12:49:57.772078  9498 net.cpp:408] conv5 -> conv5
I0524 12:49:57.775491  9498 net.cpp:150] Setting up conv5
I0524 12:49:57.775504  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.775507  9498 net.cpp:165] Memory required for data: 484900896
I0524 12:49:57.775512  9498 layer_factory.hpp:77] Creating layer conv5/bn
I0524 12:49:57.775517  9498 net.cpp:100] Creating Layer conv5/bn
I0524 12:49:57.775521  9498 net.cpp:434] conv5/bn <- conv5
I0524 12:49:57.775527  9498 net.cpp:395] conv5/bn -> conv5 (in-place)
I0524 12:49:57.776113  9498 net.cpp:150] Setting up conv5/bn
I0524 12:49:57.776119  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.776123  9498 net.cpp:165] Memory required for data: 491323424
I0524 12:49:57.776129  9498 layer_factory.hpp:77] Creating layer conv5/scale
I0524 12:49:57.776134  9498 net.cpp:100] Creating Layer conv5/scale
I0524 12:49:57.776136  9498 net.cpp:434] conv5/scale <- conv5
I0524 12:49:57.776142  9498 net.cpp:395] conv5/scale -> conv5 (in-place)
I0524 12:49:57.776232  9498 layer_factory.hpp:77] Creating layer conv5/scale
I0524 12:49:57.776537  9498 net.cpp:150] Setting up conv5/scale
I0524 12:49:57.776544  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.776547  9498 net.cpp:165] Memory required for data: 497745952
I0524 12:49:57.776562  9498 layer_factory.hpp:77] Creating layer conv5/relu
I0524 12:49:57.776567  9498 net.cpp:100] Creating Layer conv5/relu
I0524 12:49:57.776571  9498 net.cpp:434] conv5/relu <- conv5
I0524 12:49:57.776576  9498 net.cpp:395] conv5/relu -> conv5 (in-place)
I0524 12:49:57.780577  9498 net.cpp:150] Setting up conv5/relu
I0524 12:49:57.780592  9498 net.cpp:157] Top shape: 2 256 56 56 (1605632)
I0524 12:49:57.780596  9498 net.cpp:165] Memory required for data: 504168480
I0524 12:49:57.780599  9498 layer_factory.hpp:77] Creating layer conv6/dw
I0524 12:49:57.780609  9498 net.cpp:100] Creating Layer conv6/dw
I0524 12:49:57.780614  9498 net.cpp:434] conv6/dw <- conv5
I0524 12:49:57.780622  9498 net.cpp:408] conv6/dw -> conv6/dw
I0524 12:49:57.781273  9498 net.cpp:150] Setting up conv6/dw
I0524 12:49:57.781281  9498 net.cpp:157] Top shape: 2 256 28 28 (401408)
I0524 12:49:57.781284  9498 net.cpp:165] Memory required for data: 505774112
I0524 12:49:57.781289  9498 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0524 12:49:57.781296  9498 net.cpp:100] Creating Layer conv6/dw/bn
I0524 12:49:57.781298  9498 net.cpp:434] conv6/dw/bn <- conv6/dw
I0524 12:49:57.781301  9498 net.cpp:395] conv6/dw/bn -> conv6/dw (in-place)
I0524 12:49:57.781872  9498 net.cpp:150] Setting up conv6/dw/bn
I0524 12:49:57.781879  9498 net.cpp:157] Top shape: 2 256 28 28 (401408)
I0524 12:49:57.781881  9498 net.cpp:165] Memory required for data: 507379744
I0524 12:49:57.781886  9498 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0524 12:49:57.781893  9498 net.cpp:100] Creating Layer conv6/dw/scale
I0524 12:49:57.781906  9498 net.cpp:434] conv6/dw/scale <- conv6/dw
I0524 12:49:57.781910  9498 net.cpp:395] conv6/dw/scale -> conv6/dw (in-place)
I0524 12:49:57.782006  9498 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0524 12:49:57.782316  9498 net.cpp:150] Setting up conv6/dw/scale
I0524 12:49:57.782323  9498 net.cpp:157] Top shape: 2 256 28 28 (401408)
I0524 12:49:57.782325  9498 net.cpp:165] Memory required for data: 508985376
I0524 12:49:57.782330  9498 layer_factory.hpp:77] Creating layer conv6/dw/relu
I0524 12:49:57.782335  9498 net.cpp:100] Creating Layer conv6/dw/relu
I0524 12:49:57.782339  9498 net.cpp:434] conv6/dw/relu <- conv6/dw
I0524 12:49:57.782342  9498 net.cpp:395] conv6/dw/relu -> conv6/dw (in-place)
I0524 12:49:57.782872  9498 net.cpp:150] Setting up conv6/dw/relu
I0524 12:49:57.782882  9498 net.cpp:157] Top shape: 2 256 28 28 (401408)
I0524 12:49:57.782886  9498 net.cpp:165] Memory required for data: 510591008
I0524 12:49:57.782889  9498 layer_factory.hpp:77] Creating layer conv6
I0524 12:49:57.782897  9498 net.cpp:100] Creating Layer conv6
I0524 12:49:57.782902  9498 net.cpp:434] conv6 <- conv6/dw
I0524 12:49:57.782908  9498 net.cpp:408] conv6 -> conv6
I0524 12:49:57.786535  9498 net.cpp:150] Setting up conv6
I0524 12:49:57.786550  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.786552  9498 net.cpp:165] Memory required for data: 513802272
I0524 12:49:57.786558  9498 layer_factory.hpp:77] Creating layer conv6/bn
I0524 12:49:57.786566  9498 net.cpp:100] Creating Layer conv6/bn
I0524 12:49:57.786568  9498 net.cpp:434] conv6/bn <- conv6
I0524 12:49:57.786572  9498 net.cpp:395] conv6/bn -> conv6 (in-place)
I0524 12:49:57.787180  9498 net.cpp:150] Setting up conv6/bn
I0524 12:49:57.787189  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.787191  9498 net.cpp:165] Memory required for data: 517013536
I0524 12:49:57.787197  9498 layer_factory.hpp:77] Creating layer conv6/scale
I0524 12:49:57.787204  9498 net.cpp:100] Creating Layer conv6/scale
I0524 12:49:57.787209  9498 net.cpp:434] conv6/scale <- conv6
I0524 12:49:57.787212  9498 net.cpp:395] conv6/scale -> conv6 (in-place)
I0524 12:49:57.787312  9498 layer_factory.hpp:77] Creating layer conv6/scale
I0524 12:49:57.787626  9498 net.cpp:150] Setting up conv6/scale
I0524 12:49:57.787632  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.787634  9498 net.cpp:165] Memory required for data: 520224800
I0524 12:49:57.787639  9498 layer_factory.hpp:77] Creating layer conv6/relu
I0524 12:49:57.787644  9498 net.cpp:100] Creating Layer conv6/relu
I0524 12:49:57.787647  9498 net.cpp:434] conv6/relu <- conv6
I0524 12:49:57.787652  9498 net.cpp:395] conv6/relu -> conv6 (in-place)
I0524 12:49:57.788393  9498 net.cpp:150] Setting up conv6/relu
I0524 12:49:57.788404  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.788408  9498 net.cpp:165] Memory required for data: 523436064
I0524 12:49:57.788410  9498 layer_factory.hpp:77] Creating layer conv7/dw
I0524 12:49:57.788419  9498 net.cpp:100] Creating Layer conv7/dw
I0524 12:49:57.788424  9498 net.cpp:434] conv7/dw <- conv6
I0524 12:49:57.788429  9498 net.cpp:408] conv7/dw -> conv7/dw
I0524 12:49:57.789059  9498 net.cpp:150] Setting up conv7/dw
I0524 12:49:57.789067  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.789070  9498 net.cpp:165] Memory required for data: 526647328
I0524 12:49:57.789074  9498 layer_factory.hpp:77] Creating layer conv7/dw/bn
I0524 12:49:57.789080  9498 net.cpp:100] Creating Layer conv7/dw/bn
I0524 12:49:57.789083  9498 net.cpp:434] conv7/dw/bn <- conv7/dw
I0524 12:49:57.789088  9498 net.cpp:395] conv7/dw/bn -> conv7/dw (in-place)
I0524 12:49:57.789664  9498 net.cpp:150] Setting up conv7/dw/bn
I0524 12:49:57.789670  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.789672  9498 net.cpp:165] Memory required for data: 529858592
I0524 12:49:57.789678  9498 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0524 12:49:57.789685  9498 net.cpp:100] Creating Layer conv7/dw/scale
I0524 12:49:57.789697  9498 net.cpp:434] conv7/dw/scale <- conv7/dw
I0524 12:49:57.789701  9498 net.cpp:395] conv7/dw/scale -> conv7/dw (in-place)
I0524 12:49:57.789799  9498 layer_factory.hpp:77] Creating layer conv7/dw/scale
I0524 12:49:57.790179  9498 net.cpp:150] Setting up conv7/dw/scale
I0524 12:49:57.790186  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.790189  9498 net.cpp:165] Memory required for data: 533069856
I0524 12:49:57.790194  9498 layer_factory.hpp:77] Creating layer conv7/dw/relu
I0524 12:49:57.790199  9498 net.cpp:100] Creating Layer conv7/dw/relu
I0524 12:49:57.790201  9498 net.cpp:434] conv7/dw/relu <- conv7/dw
I0524 12:49:57.790205  9498 net.cpp:395] conv7/dw/relu -> conv7/dw (in-place)
I0524 12:49:57.790719  9498 net.cpp:150] Setting up conv7/dw/relu
I0524 12:49:57.790729  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.790732  9498 net.cpp:165] Memory required for data: 536281120
I0524 12:49:57.790735  9498 layer_factory.hpp:77] Creating layer conv7
I0524 12:49:57.790745  9498 net.cpp:100] Creating Layer conv7
I0524 12:49:57.790747  9498 net.cpp:434] conv7 <- conv7/dw
I0524 12:49:57.790753  9498 net.cpp:408] conv7 -> conv7
I0524 12:49:57.795738  9498 net.cpp:150] Setting up conv7
I0524 12:49:57.795753  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.795755  9498 net.cpp:165] Memory required for data: 539492384
I0524 12:49:57.795760  9498 layer_factory.hpp:77] Creating layer conv7/bn
I0524 12:49:57.795766  9498 net.cpp:100] Creating Layer conv7/bn
I0524 12:49:57.795770  9498 net.cpp:434] conv7/bn <- conv7
I0524 12:49:57.795775  9498 net.cpp:395] conv7/bn -> conv7 (in-place)
I0524 12:49:57.796340  9498 net.cpp:150] Setting up conv7/bn
I0524 12:49:57.796347  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.796350  9498 net.cpp:165] Memory required for data: 542703648
I0524 12:49:57.796355  9498 layer_factory.hpp:77] Creating layer conv7/scale
I0524 12:49:57.796361  9498 net.cpp:100] Creating Layer conv7/scale
I0524 12:49:57.796365  9498 net.cpp:434] conv7/scale <- conv7
I0524 12:49:57.796368  9498 net.cpp:395] conv7/scale -> conv7 (in-place)
I0524 12:49:57.796460  9498 layer_factory.hpp:77] Creating layer conv7/scale
I0524 12:49:57.796763  9498 net.cpp:150] Setting up conv7/scale
I0524 12:49:57.796770  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.796773  9498 net.cpp:165] Memory required for data: 545914912
I0524 12:49:57.796777  9498 layer_factory.hpp:77] Creating layer conv7/relu
I0524 12:49:57.796783  9498 net.cpp:100] Creating Layer conv7/relu
I0524 12:49:57.796787  9498 net.cpp:434] conv7/relu <- conv7
I0524 12:49:57.796790  9498 net.cpp:395] conv7/relu -> conv7 (in-place)
I0524 12:49:57.800695  9498 net.cpp:150] Setting up conv7/relu
I0524 12:49:57.800711  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.800714  9498 net.cpp:165] Memory required for data: 549126176
I0524 12:49:57.800719  9498 layer_factory.hpp:77] Creating layer conv8/dw
I0524 12:49:57.800729  9498 net.cpp:100] Creating Layer conv8/dw
I0524 12:49:57.800734  9498 net.cpp:434] conv8/dw <- conv7
I0524 12:49:57.800741  9498 net.cpp:408] conv8/dw -> conv8/dw
I0524 12:49:57.801407  9498 net.cpp:150] Setting up conv8/dw
I0524 12:49:57.801417  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.801420  9498 net.cpp:165] Memory required for data: 552337440
I0524 12:49:57.801424  9498 layer_factory.hpp:77] Creating layer conv8/dw/bn
I0524 12:49:57.801434  9498 net.cpp:100] Creating Layer conv8/dw/bn
I0524 12:49:57.801437  9498 net.cpp:434] conv8/dw/bn <- conv8/dw
I0524 12:49:57.801445  9498 net.cpp:395] conv8/dw/bn -> conv8/dw (in-place)
I0524 12:49:57.802070  9498 net.cpp:150] Setting up conv8/dw/bn
I0524 12:49:57.802083  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.802085  9498 net.cpp:165] Memory required for data: 555548704
I0524 12:49:57.802093  9498 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0524 12:49:57.802111  9498 net.cpp:100] Creating Layer conv8/dw/scale
I0524 12:49:57.802119  9498 net.cpp:434] conv8/dw/scale <- conv8/dw
I0524 12:49:57.802143  9498 net.cpp:395] conv8/dw/scale -> conv8/dw (in-place)
I0524 12:49:57.802332  9498 layer_factory.hpp:77] Creating layer conv8/dw/scale
I0524 12:49:57.802824  9498 net.cpp:150] Setting up conv8/dw/scale
I0524 12:49:57.802834  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.802836  9498 net.cpp:165] Memory required for data: 558759968
I0524 12:49:57.802841  9498 layer_factory.hpp:77] Creating layer conv8/dw/relu
I0524 12:49:57.802848  9498 net.cpp:100] Creating Layer conv8/dw/relu
I0524 12:49:57.802853  9498 net.cpp:434] conv8/dw/relu <- conv8/dw
I0524 12:49:57.802860  9498 net.cpp:395] conv8/dw/relu -> conv8/dw (in-place)
I0524 12:49:57.803428  9498 net.cpp:150] Setting up conv8/dw/relu
I0524 12:49:57.803442  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.803444  9498 net.cpp:165] Memory required for data: 561971232
I0524 12:49:57.803447  9498 layer_factory.hpp:77] Creating layer conv8
I0524 12:49:57.803457  9498 net.cpp:100] Creating Layer conv8
I0524 12:49:57.803463  9498 net.cpp:434] conv8 <- conv8/dw
I0524 12:49:57.803470  9498 net.cpp:408] conv8 -> conv8
I0524 12:49:57.808073  9498 net.cpp:150] Setting up conv8
I0524 12:49:57.808087  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.808090  9498 net.cpp:165] Memory required for data: 565182496
I0524 12:49:57.808096  9498 layer_factory.hpp:77] Creating layer conv8/bn
I0524 12:49:57.808105  9498 net.cpp:100] Creating Layer conv8/bn
I0524 12:49:57.808112  9498 net.cpp:434] conv8/bn <- conv8
I0524 12:49:57.808118  9498 net.cpp:395] conv8/bn -> conv8 (in-place)
I0524 12:49:57.808753  9498 net.cpp:150] Setting up conv8/bn
I0524 12:49:57.808763  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.808766  9498 net.cpp:165] Memory required for data: 568393760
I0524 12:49:57.808773  9498 layer_factory.hpp:77] Creating layer conv8/scale
I0524 12:49:57.808784  9498 net.cpp:100] Creating Layer conv8/scale
I0524 12:49:57.808790  9498 net.cpp:434] conv8/scale <- conv8
I0524 12:49:57.808796  9498 net.cpp:395] conv8/scale -> conv8 (in-place)
I0524 12:49:57.808917  9498 layer_factory.hpp:77] Creating layer conv8/scale
I0524 12:49:57.809253  9498 net.cpp:150] Setting up conv8/scale
I0524 12:49:57.809262  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.809264  9498 net.cpp:165] Memory required for data: 571605024
I0524 12:49:57.809269  9498 layer_factory.hpp:77] Creating layer conv8/relu
I0524 12:49:57.809280  9498 net.cpp:100] Creating Layer conv8/relu
I0524 12:49:57.809286  9498 net.cpp:434] conv8/relu <- conv8
I0524 12:49:57.809293  9498 net.cpp:395] conv8/relu -> conv8 (in-place)
I0524 12:49:57.810103  9498 net.cpp:150] Setting up conv8/relu
I0524 12:49:57.810117  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.810118  9498 net.cpp:165] Memory required for data: 574816288
I0524 12:49:57.810122  9498 layer_factory.hpp:77] Creating layer conv9/dw
I0524 12:49:57.810133  9498 net.cpp:100] Creating Layer conv9/dw
I0524 12:49:57.810139  9498 net.cpp:434] conv9/dw <- conv8
I0524 12:49:57.810148  9498 net.cpp:408] conv9/dw -> conv9/dw
I0524 12:49:57.810781  9498 net.cpp:150] Setting up conv9/dw
I0524 12:49:57.810791  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.810793  9498 net.cpp:165] Memory required for data: 578027552
I0524 12:49:57.810798  9498 layer_factory.hpp:77] Creating layer conv9/dw/bn
I0524 12:49:57.810806  9498 net.cpp:100] Creating Layer conv9/dw/bn
I0524 12:49:57.810811  9498 net.cpp:434] conv9/dw/bn <- conv9/dw
I0524 12:49:57.810817  9498 net.cpp:395] conv9/dw/bn -> conv9/dw (in-place)
I0524 12:49:57.811386  9498 net.cpp:150] Setting up conv9/dw/bn
I0524 12:49:57.811395  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.811398  9498 net.cpp:165] Memory required for data: 581238816
I0524 12:49:57.811404  9498 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0524 12:49:57.811415  9498 net.cpp:100] Creating Layer conv9/dw/scale
I0524 12:49:57.811420  9498 net.cpp:434] conv9/dw/scale <- conv9/dw
I0524 12:49:57.811444  9498 net.cpp:395] conv9/dw/scale -> conv9/dw (in-place)
I0524 12:49:57.811570  9498 layer_factory.hpp:77] Creating layer conv9/dw/scale
I0524 12:49:57.811883  9498 net.cpp:150] Setting up conv9/dw/scale
I0524 12:49:57.811892  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.811894  9498 net.cpp:165] Memory required for data: 584450080
I0524 12:49:57.811900  9498 layer_factory.hpp:77] Creating layer conv9/dw/relu
I0524 12:49:57.811909  9498 net.cpp:100] Creating Layer conv9/dw/relu
I0524 12:49:57.811915  9498 net.cpp:434] conv9/dw/relu <- conv9/dw
I0524 12:49:57.811921  9498 net.cpp:395] conv9/dw/relu -> conv9/dw (in-place)
I0524 12:49:57.812431  9498 net.cpp:150] Setting up conv9/dw/relu
I0524 12:49:57.812443  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.812444  9498 net.cpp:165] Memory required for data: 587661344
I0524 12:49:57.812448  9498 layer_factory.hpp:77] Creating layer conv9
I0524 12:49:57.812458  9498 net.cpp:100] Creating Layer conv9
I0524 12:49:57.812464  9498 net.cpp:434] conv9 <- conv9/dw
I0524 12:49:57.812472  9498 net.cpp:408] conv9 -> conv9
I0524 12:49:57.817615  9498 net.cpp:150] Setting up conv9
I0524 12:49:57.817631  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.817633  9498 net.cpp:165] Memory required for data: 590872608
I0524 12:49:57.817638  9498 layer_factory.hpp:77] Creating layer conv9/bn
I0524 12:49:57.817646  9498 net.cpp:100] Creating Layer conv9/bn
I0524 12:49:57.817651  9498 net.cpp:434] conv9/bn <- conv9
I0524 12:49:57.817657  9498 net.cpp:395] conv9/bn -> conv9 (in-place)
I0524 12:49:57.818265  9498 net.cpp:150] Setting up conv9/bn
I0524 12:49:57.818274  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.818277  9498 net.cpp:165] Memory required for data: 594083872
I0524 12:49:57.818284  9498 layer_factory.hpp:77] Creating layer conv9/scale
I0524 12:49:57.818291  9498 net.cpp:100] Creating Layer conv9/scale
I0524 12:49:57.818295  9498 net.cpp:434] conv9/scale <- conv9
I0524 12:49:57.818305  9498 net.cpp:395] conv9/scale -> conv9 (in-place)
I0524 12:49:57.818418  9498 layer_factory.hpp:77] Creating layer conv9/scale
I0524 12:49:57.818729  9498 net.cpp:150] Setting up conv9/scale
I0524 12:49:57.818737  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.818740  9498 net.cpp:165] Memory required for data: 597295136
I0524 12:49:57.818747  9498 layer_factory.hpp:77] Creating layer conv9/relu
I0524 12:49:57.818753  9498 net.cpp:100] Creating Layer conv9/relu
I0524 12:49:57.818756  9498 net.cpp:434] conv9/relu <- conv9
I0524 12:49:57.818765  9498 net.cpp:395] conv9/relu -> conv9 (in-place)
I0524 12:49:57.822331  9498 net.cpp:150] Setting up conv9/relu
I0524 12:49:57.822346  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.822350  9498 net.cpp:165] Memory required for data: 600506400
I0524 12:49:57.822369  9498 layer_factory.hpp:77] Creating layer conv10/dw
I0524 12:49:57.822378  9498 net.cpp:100] Creating Layer conv10/dw
I0524 12:49:57.822382  9498 net.cpp:434] conv10/dw <- conv9
I0524 12:49:57.822391  9498 net.cpp:408] conv10/dw -> conv10/dw
I0524 12:49:57.823057  9498 net.cpp:150] Setting up conv10/dw
I0524 12:49:57.823068  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.823071  9498 net.cpp:165] Memory required for data: 603717664
I0524 12:49:57.823076  9498 layer_factory.hpp:77] Creating layer conv10/dw/bn
I0524 12:49:57.823082  9498 net.cpp:100] Creating Layer conv10/dw/bn
I0524 12:49:57.823087  9498 net.cpp:434] conv10/dw/bn <- conv10/dw
I0524 12:49:57.823093  9498 net.cpp:395] conv10/dw/bn -> conv10/dw (in-place)
I0524 12:49:57.823699  9498 net.cpp:150] Setting up conv10/dw/bn
I0524 12:49:57.823709  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.823712  9498 net.cpp:165] Memory required for data: 606928928
I0524 12:49:57.823720  9498 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0524 12:49:57.823727  9498 net.cpp:100] Creating Layer conv10/dw/scale
I0524 12:49:57.823734  9498 net.cpp:434] conv10/dw/scale <- conv10/dw
I0524 12:49:57.823756  9498 net.cpp:395] conv10/dw/scale -> conv10/dw (in-place)
I0524 12:49:57.823891  9498 layer_factory.hpp:77] Creating layer conv10/dw/scale
I0524 12:49:57.824218  9498 net.cpp:150] Setting up conv10/dw/scale
I0524 12:49:57.824226  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.824229  9498 net.cpp:165] Memory required for data: 610140192
I0524 12:49:57.824234  9498 layer_factory.hpp:77] Creating layer conv10/dw/relu
I0524 12:49:57.824241  9498 net.cpp:100] Creating Layer conv10/dw/relu
I0524 12:49:57.824249  9498 net.cpp:434] conv10/dw/relu <- conv10/dw
I0524 12:49:57.824255  9498 net.cpp:395] conv10/dw/relu -> conv10/dw (in-place)
I0524 12:49:57.824780  9498 net.cpp:150] Setting up conv10/dw/relu
I0524 12:49:57.824793  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.824796  9498 net.cpp:165] Memory required for data: 613351456
I0524 12:49:57.824800  9498 layer_factory.hpp:77] Creating layer conv10
I0524 12:49:57.824811  9498 net.cpp:100] Creating Layer conv10
I0524 12:49:57.824818  9498 net.cpp:434] conv10 <- conv10/dw
I0524 12:49:57.824826  9498 net.cpp:408] conv10 -> conv10
I0524 12:49:57.829524  9498 net.cpp:150] Setting up conv10
I0524 12:49:57.829537  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.829540  9498 net.cpp:165] Memory required for data: 616562720
I0524 12:49:57.829545  9498 layer_factory.hpp:77] Creating layer conv10/bn
I0524 12:49:57.829551  9498 net.cpp:100] Creating Layer conv10/bn
I0524 12:49:57.829557  9498 net.cpp:434] conv10/bn <- conv10
I0524 12:49:57.829563  9498 net.cpp:395] conv10/bn -> conv10 (in-place)
I0524 12:49:57.830169  9498 net.cpp:150] Setting up conv10/bn
I0524 12:49:57.830178  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.830181  9498 net.cpp:165] Memory required for data: 619773984
I0524 12:49:57.830188  9498 layer_factory.hpp:77] Creating layer conv10/scale
I0524 12:49:57.830197  9498 net.cpp:100] Creating Layer conv10/scale
I0524 12:49:57.830202  9498 net.cpp:434] conv10/scale <- conv10
I0524 12:49:57.830210  9498 net.cpp:395] conv10/scale -> conv10 (in-place)
I0524 12:49:57.830327  9498 layer_factory.hpp:77] Creating layer conv10/scale
I0524 12:49:57.830655  9498 net.cpp:150] Setting up conv10/scale
I0524 12:49:57.830663  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.830667  9498 net.cpp:165] Memory required for data: 622985248
I0524 12:49:57.830672  9498 layer_factory.hpp:77] Creating layer conv10/relu
I0524 12:49:57.830678  9498 net.cpp:100] Creating Layer conv10/relu
I0524 12:49:57.830684  9498 net.cpp:434] conv10/relu <- conv10
I0524 12:49:57.830691  9498 net.cpp:395] conv10/relu -> conv10 (in-place)
I0524 12:49:57.831481  9498 net.cpp:150] Setting up conv10/relu
I0524 12:49:57.831496  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.831499  9498 net.cpp:165] Memory required for data: 626196512
I0524 12:49:57.831503  9498 layer_factory.hpp:77] Creating layer conv11/dw
I0524 12:49:57.831513  9498 net.cpp:100] Creating Layer conv11/dw
I0524 12:49:57.831519  9498 net.cpp:434] conv11/dw <- conv10
I0524 12:49:57.831528  9498 net.cpp:408] conv11/dw -> conv11/dw
I0524 12:49:57.832195  9498 net.cpp:150] Setting up conv11/dw
I0524 12:49:57.832204  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.832209  9498 net.cpp:165] Memory required for data: 629407776
I0524 12:49:57.832214  9498 layer_factory.hpp:77] Creating layer conv11/dw/bn
I0524 12:49:57.832221  9498 net.cpp:100] Creating Layer conv11/dw/bn
I0524 12:49:57.832224  9498 net.cpp:434] conv11/dw/bn <- conv11/dw
I0524 12:49:57.832232  9498 net.cpp:395] conv11/dw/bn -> conv11/dw (in-place)
I0524 12:49:57.832808  9498 net.cpp:150] Setting up conv11/dw/bn
I0524 12:49:57.832816  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.832820  9498 net.cpp:165] Memory required for data: 632619040
I0524 12:49:57.832849  9498 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0524 12:49:57.832855  9498 net.cpp:100] Creating Layer conv11/dw/scale
I0524 12:49:57.832860  9498 net.cpp:434] conv11/dw/scale <- conv11/dw
I0524 12:49:57.832883  9498 net.cpp:395] conv11/dw/scale -> conv11/dw (in-place)
I0524 12:49:57.833017  9498 layer_factory.hpp:77] Creating layer conv11/dw/scale
I0524 12:49:57.833340  9498 net.cpp:150] Setting up conv11/dw/scale
I0524 12:49:57.833348  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.833351  9498 net.cpp:165] Memory required for data: 635830304
I0524 12:49:57.833357  9498 layer_factory.hpp:77] Creating layer conv11/dw/relu
I0524 12:49:57.833364  9498 net.cpp:100] Creating Layer conv11/dw/relu
I0524 12:49:57.833369  9498 net.cpp:434] conv11/dw/relu <- conv11/dw
I0524 12:49:57.833376  9498 net.cpp:395] conv11/dw/relu -> conv11/dw (in-place)
I0524 12:49:57.833879  9498 net.cpp:150] Setting up conv11/dw/relu
I0524 12:49:57.833891  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.833895  9498 net.cpp:165] Memory required for data: 639041568
I0524 12:49:57.833899  9498 layer_factory.hpp:77] Creating layer conv11
I0524 12:49:57.833911  9498 net.cpp:100] Creating Layer conv11
I0524 12:49:57.833916  9498 net.cpp:434] conv11 <- conv11/dw
I0524 12:49:57.833927  9498 net.cpp:408] conv11 -> conv11
I0524 12:49:57.838970  9498 net.cpp:150] Setting up conv11
I0524 12:49:57.838984  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.838986  9498 net.cpp:165] Memory required for data: 642252832
I0524 12:49:57.838991  9498 layer_factory.hpp:77] Creating layer conv11/bn
I0524 12:49:57.839013  9498 net.cpp:100] Creating Layer conv11/bn
I0524 12:49:57.839017  9498 net.cpp:434] conv11/bn <- conv11
I0524 12:49:57.839021  9498 net.cpp:395] conv11/bn -> conv11 (in-place)
I0524 12:49:57.839653  9498 net.cpp:150] Setting up conv11/bn
I0524 12:49:57.839663  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.839668  9498 net.cpp:165] Memory required for data: 645464096
I0524 12:49:57.839674  9498 layer_factory.hpp:77] Creating layer conv11/scale
I0524 12:49:57.839684  9498 net.cpp:100] Creating Layer conv11/scale
I0524 12:49:57.839690  9498 net.cpp:434] conv11/scale <- conv11
I0524 12:49:57.839697  9498 net.cpp:395] conv11/scale -> conv11 (in-place)
I0524 12:49:57.839818  9498 layer_factory.hpp:77] Creating layer conv11/scale
I0524 12:49:57.840153  9498 net.cpp:150] Setting up conv11/scale
I0524 12:49:57.840162  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.840164  9498 net.cpp:165] Memory required for data: 648675360
I0524 12:49:57.840171  9498 layer_factory.hpp:77] Creating layer conv11/relu
I0524 12:49:57.840181  9498 net.cpp:100] Creating Layer conv11/relu
I0524 12:49:57.840188  9498 net.cpp:434] conv11/relu <- conv11
I0524 12:49:57.840194  9498 net.cpp:395] conv11/relu -> conv11 (in-place)
I0524 12:49:57.841147  9498 net.cpp:150] Setting up conv11/relu
I0524 12:49:57.841161  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.841166  9498 net.cpp:165] Memory required for data: 651886624
I0524 12:49:57.841169  9498 layer_factory.hpp:77] Creating layer conv12/dw
I0524 12:49:57.841181  9498 net.cpp:100] Creating Layer conv12/dw
I0524 12:49:57.841187  9498 net.cpp:434] conv12/dw <- conv11
I0524 12:49:57.841194  9498 net.cpp:408] conv12/dw -> conv12/dw
I0524 12:49:57.841859  9498 net.cpp:150] Setting up conv12/dw
I0524 12:49:57.841868  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.841871  9498 net.cpp:165] Memory required for data: 655097888
I0524 12:49:57.841876  9498 layer_factory.hpp:77] Creating layer conv12/dw/bn
I0524 12:49:57.841884  9498 net.cpp:100] Creating Layer conv12/dw/bn
I0524 12:49:57.841890  9498 net.cpp:434] conv12/dw/bn <- conv12/dw
I0524 12:49:57.841897  9498 net.cpp:395] conv12/dw/bn -> conv12/dw (in-place)
I0524 12:49:57.842496  9498 net.cpp:150] Setting up conv12/dw/bn
I0524 12:49:57.842505  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.842507  9498 net.cpp:165] Memory required for data: 658309152
I0524 12:49:57.842514  9498 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0524 12:49:57.842522  9498 net.cpp:100] Creating Layer conv12/dw/scale
I0524 12:49:57.842550  9498 net.cpp:434] conv12/dw/scale <- conv12/dw
I0524 12:49:57.842559  9498 net.cpp:395] conv12/dw/scale -> conv12/dw (in-place)
I0524 12:49:57.842690  9498 layer_factory.hpp:77] Creating layer conv12/dw/scale
I0524 12:49:57.843021  9498 net.cpp:150] Setting up conv12/dw/scale
I0524 12:49:57.843030  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.843034  9498 net.cpp:165] Memory required for data: 661520416
I0524 12:49:57.843039  9498 layer_factory.hpp:77] Creating layer conv12/dw/relu
I0524 12:49:57.843045  9498 net.cpp:100] Creating Layer conv12/dw/relu
I0524 12:49:57.843051  9498 net.cpp:434] conv12/dw/relu <- conv12/dw
I0524 12:49:57.843061  9498 net.cpp:395] conv12/dw/relu -> conv12/dw (in-place)
I0524 12:49:57.846335  9498 net.cpp:150] Setting up conv12/dw/relu
I0524 12:49:57.846349  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.846352  9498 net.cpp:165] Memory required for data: 664731680
I0524 12:49:57.846355  9498 layer_factory.hpp:77] Creating layer conv12/dw_conv12/dw/relu_0_split
I0524 12:49:57.846360  9498 net.cpp:100] Creating Layer conv12/dw_conv12/dw/relu_0_split
I0524 12:49:57.846380  9498 net.cpp:434] conv12/dw_conv12/dw/relu_0_split <- conv12/dw
I0524 12:49:57.846397  9498 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_0
I0524 12:49:57.846405  9498 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_1
I0524 12:49:57.846417  9498 net.cpp:408] conv12/dw_conv12/dw/relu_0_split -> conv12/dw_conv12/dw/relu_0_split_2
I0524 12:49:57.846628  9498 net.cpp:150] Setting up conv12/dw_conv12/dw/relu_0_split
I0524 12:49:57.846637  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.846640  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.846643  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:57.846647  9498 net.cpp:165] Memory required for data: 674365472
I0524 12:49:57.846650  9498 layer_factory.hpp:77] Creating layer sample_pooling
I0524 12:49:57.846662  9498 net.cpp:100] Creating Layer sample_pooling
I0524 12:49:57.846668  9498 net.cpp:434] sample_pooling <- conv12/dw_conv12/dw/relu_0_split_0
I0524 12:49:57.846676  9498 net.cpp:408] sample_pooling -> sample_pooling
I0524 12:49:59.284809  9498 net.cpp:150] Setting up sample_pooling
I0524 12:49:59.284832  9498 net.cpp:157] Top shape: 2 512 14 14 (200704)
I0524 12:49:59.284835  9498 net.cpp:165] Memory required for data: 675168288
I0524 12:49:59.284844  9498 layer_factory.hpp:77] Creating layer conv12
I0524 12:49:59.284859  9498 net.cpp:100] Creating Layer conv12
I0524 12:49:59.284865  9498 net.cpp:434] conv12 <- sample_pooling
I0524 12:49:59.284875  9498 net.cpp:408] conv12 -> conv12
I0524 12:49:59.291507  9498 net.cpp:150] Setting up conv12
I0524 12:49:59.291527  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.291529  9498 net.cpp:165] Memory required for data: 676773920
I0524 12:49:59.291538  9498 layer_factory.hpp:77] Creating layer conv12/bn
I0524 12:49:59.291544  9498 net.cpp:100] Creating Layer conv12/bn
I0524 12:49:59.291551  9498 net.cpp:434] conv12/bn <- conv12
I0524 12:49:59.291559  9498 net.cpp:395] conv12/bn -> conv12 (in-place)
I0524 12:49:59.292177  9498 net.cpp:150] Setting up conv12/bn
I0524 12:49:59.292188  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.292192  9498 net.cpp:165] Memory required for data: 678379552
I0524 12:49:59.292198  9498 layer_factory.hpp:77] Creating layer conv12/scale
I0524 12:49:59.292205  9498 net.cpp:100] Creating Layer conv12/scale
I0524 12:49:59.292209  9498 net.cpp:434] conv12/scale <- conv12
I0524 12:49:59.292215  9498 net.cpp:395] conv12/scale -> conv12 (in-place)
I0524 12:49:59.292361  9498 layer_factory.hpp:77] Creating layer conv12/scale
I0524 12:49:59.292667  9498 net.cpp:150] Setting up conv12/scale
I0524 12:49:59.292675  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.292678  9498 net.cpp:165] Memory required for data: 679985184
I0524 12:49:59.292683  9498 layer_factory.hpp:77] Creating layer conv12/relu
I0524 12:49:59.292707  9498 net.cpp:100] Creating Layer conv12/relu
I0524 12:49:59.292711  9498 net.cpp:434] conv12/relu <- conv12
I0524 12:49:59.292714  9498 net.cpp:395] conv12/relu -> conv12 (in-place)
I0524 12:49:59.293190  9498 net.cpp:150] Setting up conv12/relu
I0524 12:49:59.293202  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.293205  9498 net.cpp:165] Memory required for data: 681590816
I0524 12:49:59.293210  9498 layer_factory.hpp:77] Creating layer conv13/dw
I0524 12:49:59.293220  9498 net.cpp:100] Creating Layer conv13/dw
I0524 12:49:59.293222  9498 net.cpp:434] conv13/dw <- conv12
I0524 12:49:59.293227  9498 net.cpp:408] conv13/dw -> conv13/dw
I0524 12:49:59.293798  9498 net.cpp:150] Setting up conv13/dw
I0524 12:49:59.293807  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.293810  9498 net.cpp:165] Memory required for data: 683196448
I0524 12:49:59.293814  9498 layer_factory.hpp:77] Creating layer conv13/dw/bn
I0524 12:49:59.293819  9498 net.cpp:100] Creating Layer conv13/dw/bn
I0524 12:49:59.293823  9498 net.cpp:434] conv13/dw/bn <- conv13/dw
I0524 12:49:59.293828  9498 net.cpp:395] conv13/dw/bn -> conv13/dw (in-place)
I0524 12:49:59.294363  9498 net.cpp:150] Setting up conv13/dw/bn
I0524 12:49:59.294373  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.294375  9498 net.cpp:165] Memory required for data: 684802080
I0524 12:49:59.294381  9498 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0524 12:49:59.294386  9498 net.cpp:100] Creating Layer conv13/dw/scale
I0524 12:49:59.294390  9498 net.cpp:434] conv13/dw/scale <- conv13/dw
I0524 12:49:59.294396  9498 net.cpp:395] conv13/dw/scale -> conv13/dw (in-place)
I0524 12:49:59.294541  9498 layer_factory.hpp:77] Creating layer conv13/dw/scale
I0524 12:49:59.294838  9498 net.cpp:150] Setting up conv13/dw/scale
I0524 12:49:59.294847  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.294849  9498 net.cpp:165] Memory required for data: 686407712
I0524 12:49:59.294855  9498 layer_factory.hpp:77] Creating layer conv13/dw/relu
I0524 12:49:59.294862  9498 net.cpp:100] Creating Layer conv13/dw/relu
I0524 12:49:59.294867  9498 net.cpp:434] conv13/dw/relu <- conv13/dw
I0524 12:49:59.294874  9498 net.cpp:395] conv13/dw/relu -> conv13/dw (in-place)
I0524 12:49:59.295717  9498 net.cpp:150] Setting up conv13/dw/relu
I0524 12:49:59.295729  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.295732  9498 net.cpp:165] Memory required for data: 688013344
I0524 12:49:59.295735  9498 layer_factory.hpp:77] Creating layer conv13
I0524 12:49:59.295745  9498 net.cpp:100] Creating Layer conv13
I0524 12:49:59.295750  9498 net.cpp:434] conv13 <- conv13/dw
I0524 12:49:59.295758  9498 net.cpp:408] conv13 -> conv13
I0524 12:49:59.305994  9498 net.cpp:150] Setting up conv13
I0524 12:49:59.306010  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.306012  9498 net.cpp:165] Memory required for data: 689618976
I0524 12:49:59.306020  9498 layer_factory.hpp:77] Creating layer conv13/bn
I0524 12:49:59.306025  9498 net.cpp:100] Creating Layer conv13/bn
I0524 12:49:59.306030  9498 net.cpp:434] conv13/bn <- conv13
I0524 12:49:59.306033  9498 net.cpp:395] conv13/bn -> conv13 (in-place)
I0524 12:49:59.306627  9498 net.cpp:150] Setting up conv13/bn
I0524 12:49:59.306636  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.306640  9498 net.cpp:165] Memory required for data: 691224608
I0524 12:49:59.306648  9498 layer_factory.hpp:77] Creating layer conv13/scale
I0524 12:49:59.306656  9498 net.cpp:100] Creating Layer conv13/scale
I0524 12:49:59.306660  9498 net.cpp:434] conv13/scale <- conv13
I0524 12:49:59.306665  9498 net.cpp:395] conv13/scale -> conv13 (in-place)
I0524 12:49:59.306809  9498 layer_factory.hpp:77] Creating layer conv13/scale
I0524 12:49:59.307126  9498 net.cpp:150] Setting up conv13/scale
I0524 12:49:59.307137  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.307139  9498 net.cpp:165] Memory required for data: 692830240
I0524 12:49:59.307165  9498 layer_factory.hpp:77] Creating layer conv13/relu
I0524 12:49:59.307171  9498 net.cpp:100] Creating Layer conv13/relu
I0524 12:49:59.307175  9498 net.cpp:434] conv13/relu <- conv13
I0524 12:49:59.307179  9498 net.cpp:395] conv13/relu -> conv13 (in-place)
I0524 12:49:59.307699  9498 net.cpp:150] Setting up conv13/relu
I0524 12:49:59.307711  9498 net.cpp:157] Top shape: 2 1024 14 14 (401408)
I0524 12:49:59.307713  9498 net.cpp:165] Memory required for data: 694435872
I0524 12:49:59.307718  9498 layer_factory.hpp:77] Creating layer ip6
I0524 12:49:59.307726  9498 net.cpp:100] Creating Layer ip6
I0524 12:49:59.307730  9498 net.cpp:434] ip6 <- conv13
I0524 12:49:59.307736  9498 net.cpp:408] ip6 -> ip6
I0524 12:49:59.318797  9498 net.cpp:150] Setting up ip6
I0524 12:49:59.318820  9498 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0524 12:49:59.318825  9498 net.cpp:165] Memory required for data: 694837280
I0524 12:49:59.318832  9498 layer_factory.hpp:77] Creating layer relu6
I0524 12:49:59.318840  9498 net.cpp:100] Creating Layer relu6
I0524 12:49:59.318843  9498 net.cpp:434] relu6 <- ip6
I0524 12:49:59.318850  9498 net.cpp:395] relu6 -> ip6 (in-place)
I0524 12:49:59.324936  9498 net.cpp:150] Setting up relu6
I0524 12:49:59.324955  9498 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0524 12:49:59.324959  9498 net.cpp:165] Memory required for data: 695238688
I0524 12:49:59.324964  9498 layer_factory.hpp:77] Creating layer ip7
I0524 12:49:59.324976  9498 net.cpp:100] Creating Layer ip7
I0524 12:49:59.324980  9498 net.cpp:434] ip7 <- ip6
I0524 12:49:59.324988  9498 net.cpp:408] ip7 -> ip7
I0524 12:49:59.326300  9498 net.cpp:150] Setting up ip7
I0524 12:49:59.326311  9498 net.cpp:157] Top shape: 2 512 14 14 (200704)
I0524 12:49:59.326314  9498 net.cpp:165] Memory required for data: 696041504
I0524 12:49:59.326320  9498 layer_factory.hpp:77] Creating layer relu7
I0524 12:49:59.326341  9498 net.cpp:100] Creating Layer relu7
I0524 12:49:59.326345  9498 net.cpp:434] relu7 <- ip7
I0524 12:49:59.326349  9498 net.cpp:395] relu7 -> ip7 (in-place)
I0524 12:49:59.326860  9498 net.cpp:150] Setting up relu7
I0524 12:49:59.326871  9498 net.cpp:157] Top shape: 2 512 14 14 (200704)
I0524 12:49:59.326874  9498 net.cpp:165] Memory required for data: 696844320
I0524 12:49:59.326876  9498 layer_factory.hpp:77] Creating layer ip7_relu7_0_split
I0524 12:49:59.326881  9498 net.cpp:100] Creating Layer ip7_relu7_0_split
I0524 12:49:59.326885  9498 net.cpp:434] ip7_relu7_0_split <- ip7
I0524 12:49:59.326891  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_0
I0524 12:49:59.326897  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_1
I0524 12:49:59.326903  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_2
I0524 12:49:59.326908  9498 net.cpp:408] ip7_relu7_0_split -> ip7_relu7_0_split_3
I0524 12:49:59.327050  9498 net.cpp:150] Setting up ip7_relu7_0_split
I0524 12:49:59.327056  9498 net.cpp:157] Top shape: 2 512 14 14 (200704)
I0524 12:49:59.327059  9498 net.cpp:157] Top shape: 2 512 14 14 (200704)
I0524 12:49:59.327064  9498 net.cpp:157] Top shape: 2 512 14 14 (200704)
I0524 12:49:59.327066  9498 net.cpp:157] Top shape: 2 512 14 14 (200704)
I0524 12:49:59.327069  9498 net.cpp:165] Memory required for data: 700055584
I0524 12:49:59.327071  9498 layer_factory.hpp:77] Creating layer conv6_1
I0524 12:49:59.327080  9498 net.cpp:100] Creating Layer conv6_1
I0524 12:49:59.327082  9498 net.cpp:434] conv6_1 <- ip7_relu7_0_split_0
I0524 12:49:59.327088  9498 net.cpp:408] conv6_1 -> conv6_1
I0524 12:49:59.330667  9498 net.cpp:150] Setting up conv6_1
I0524 12:49:59.330682  9498 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0524 12:49:59.330684  9498 net.cpp:165] Memory required for data: 700456992
I0524 12:49:59.330690  9498 layer_factory.hpp:77] Creating layer conv6_1_relu
I0524 12:49:59.330695  9498 net.cpp:100] Creating Layer conv6_1_relu
I0524 12:49:59.330700  9498 net.cpp:434] conv6_1_relu <- conv6_1
I0524 12:49:59.330704  9498 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0524 12:49:59.331598  9498 net.cpp:150] Setting up conv6_1_relu
I0524 12:49:59.331627  9498 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0524 12:49:59.331631  9498 net.cpp:165] Memory required for data: 700858400
I0524 12:49:59.331634  9498 layer_factory.hpp:77] Creating layer conv6_2
I0524 12:49:59.331643  9498 net.cpp:100] Creating Layer conv6_2
I0524 12:49:59.331646  9498 net.cpp:434] conv6_2 <- conv6_1
I0524 12:49:59.331655  9498 net.cpp:408] conv6_2 -> conv6_2
I0524 12:49:59.337116  9498 net.cpp:150] Setting up conv6_2
I0524 12:49:59.337131  9498 net.cpp:157] Top shape: 2 256 7 7 (25088)
I0524 12:49:59.337133  9498 net.cpp:165] Memory required for data: 700958752
I0524 12:49:59.337139  9498 layer_factory.hpp:77] Creating layer conv6_2_relu
I0524 12:49:59.337144  9498 net.cpp:100] Creating Layer conv6_2_relu
I0524 12:49:59.337148  9498 net.cpp:434] conv6_2_relu <- conv6_2
I0524 12:49:59.337153  9498 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0524 12:49:59.337641  9498 net.cpp:150] Setting up conv6_2_relu
I0524 12:49:59.337651  9498 net.cpp:157] Top shape: 2 256 7 7 (25088)
I0524 12:49:59.337654  9498 net.cpp:165] Memory required for data: 701059104
I0524 12:49:59.337657  9498 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0524 12:49:59.337664  9498 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0524 12:49:59.337667  9498 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0524 12:49:59.337672  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0524 12:49:59.337678  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0524 12:49:59.337685  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0524 12:49:59.337690  9498 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0524 12:49:59.337832  9498 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0524 12:49:59.337837  9498 net.cpp:157] Top shape: 2 256 7 7 (25088)
I0524 12:49:59.337841  9498 net.cpp:157] Top shape: 2 256 7 7 (25088)
I0524 12:49:59.337844  9498 net.cpp:157] Top shape: 2 256 7 7 (25088)
I0524 12:49:59.337847  9498 net.cpp:157] Top shape: 2 256 7 7 (25088)
I0524 12:49:59.337849  9498 net.cpp:165] Memory required for data: 701460512
I0524 12:49:59.337852  9498 layer_factory.hpp:77] Creating layer conv7_1
I0524 12:49:59.337862  9498 net.cpp:100] Creating Layer conv7_1
I0524 12:49:59.337867  9498 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0524 12:49:59.337874  9498 net.cpp:408] conv7_1 -> conv7_1
I0524 12:49:59.345412  9498 net.cpp:150] Setting up conv7_1
I0524 12:49:59.345425  9498 net.cpp:157] Top shape: 2 128 7 7 (12544)
I0524 12:49:59.345428  9498 net.cpp:165] Memory required for data: 701510688
I0524 12:49:59.345434  9498 layer_factory.hpp:77] Creating layer conv7_1_relu
I0524 12:49:59.345440  9498 net.cpp:100] Creating Layer conv7_1_relu
I0524 12:49:59.345444  9498 net.cpp:434] conv7_1_relu <- conv7_1
I0524 12:49:59.345450  9498 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0524 12:49:59.345963  9498 net.cpp:150] Setting up conv7_1_relu
I0524 12:49:59.345974  9498 net.cpp:157] Top shape: 2 128 7 7 (12544)
I0524 12:49:59.345978  9498 net.cpp:165] Memory required for data: 701560864
I0524 12:49:59.345981  9498 layer_factory.hpp:77] Creating layer conv7_2
I0524 12:49:59.345990  9498 net.cpp:100] Creating Layer conv7_2
I0524 12:49:59.345995  9498 net.cpp:434] conv7_2 <- conv7_1
I0524 12:49:59.346000  9498 net.cpp:408] conv7_2 -> conv7_2
I0524 12:49:59.350406  9498 net.cpp:150] Setting up conv7_2
I0524 12:49:59.350419  9498 net.cpp:157] Top shape: 2 256 4 4 (8192)
I0524 12:49:59.350422  9498 net.cpp:165] Memory required for data: 701593632
I0524 12:49:59.350427  9498 layer_factory.hpp:77] Creating layer conv7_2_relu
I0524 12:49:59.350448  9498 net.cpp:100] Creating Layer conv7_2_relu
I0524 12:49:59.350451  9498 net.cpp:434] conv7_2_relu <- conv7_2
I0524 12:49:59.350456  9498 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0524 12:49:59.351269  9498 net.cpp:150] Setting up conv7_2_relu
I0524 12:49:59.351282  9498 net.cpp:157] Top shape: 2 256 4 4 (8192)
I0524 12:49:59.351298  9498 net.cpp:165] Memory required for data: 701626400
I0524 12:49:59.351301  9498 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0524 12:49:59.351307  9498 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0524 12:49:59.351310  9498 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0524 12:49:59.351316  9498 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0524 12:49:59.351323  9498 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0524 12:49:59.351327  9498 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0524 12:49:59.351476  9498 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0524 12:49:59.351482  9498 net.cpp:157] Top shape: 2 256 4 4 (8192)
I0524 12:49:59.351486  9498 net.cpp:157] Top shape: 2 256 4 4 (8192)
I0524 12:49:59.351490  9498 net.cpp:157] Top shape: 2 256 4 4 (8192)
I0524 12:49:59.351492  9498 net.cpp:165] Memory required for data: 701724704
I0524 12:49:59.351495  9498 layer_factory.hpp:77] Creating layer conv12_norm
I0524 12:49:59.351501  9498 net.cpp:100] Creating Layer conv12_norm
I0524 12:49:59.351505  9498 net.cpp:434] conv12_norm <- conv12/dw_conv12/dw/relu_0_split_1
I0524 12:49:59.351511  9498 net.cpp:408] conv12_norm -> conv12_norm
I0524 12:49:59.352061  9498 net.cpp:150] Setting up conv12_norm
I0524 12:49:59.352072  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:59.352074  9498 net.cpp:165] Memory required for data: 704935968
I0524 12:49:59.352079  9498 layer_factory.hpp:77] Creating layer conv12_norm_conv12_norm_0_split
I0524 12:49:59.352094  9498 net.cpp:100] Creating Layer conv12_norm_conv12_norm_0_split
I0524 12:49:59.352098  9498 net.cpp:434] conv12_norm_conv12_norm_0_split <- conv12_norm
I0524 12:49:59.352103  9498 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_0
I0524 12:49:59.352108  9498 net.cpp:408] conv12_norm_conv12_norm_0_split -> conv12_norm_conv12_norm_0_split_1
I0524 12:49:59.352170  9498 net.cpp:150] Setting up conv12_norm_conv12_norm_0_split
I0524 12:49:59.352177  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:59.352180  9498 net.cpp:157] Top shape: 2 512 28 28 (802816)
I0524 12:49:59.352182  9498 net.cpp:165] Memory required for data: 711358496
I0524 12:49:59.352186  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc
I0524 12:49:59.352196  9498 net.cpp:100] Creating Layer conv12_norm_mbox_loc
I0524 12:49:59.352200  9498 net.cpp:434] conv12_norm_mbox_loc <- conv12_norm_conv12_norm_0_split_0
I0524 12:49:59.352205  9498 net.cpp:408] conv12_norm_mbox_loc -> conv12_norm_mbox_loc
I0524 12:49:59.360116  9498 net.cpp:150] Setting up conv12_norm_mbox_loc
I0524 12:49:59.360131  9498 net.cpp:157] Top shape: 2 24 28 28 (37632)
I0524 12:49:59.360133  9498 net.cpp:165] Memory required for data: 711509024
I0524 12:49:59.360141  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_perm
I0524 12:49:59.360148  9498 net.cpp:100] Creating Layer conv12_norm_mbox_loc_perm
I0524 12:49:59.360152  9498 net.cpp:434] conv12_norm_mbox_loc_perm <- conv12_norm_mbox_loc
I0524 12:49:59.360157  9498 net.cpp:408] conv12_norm_mbox_loc_perm -> conv12_norm_mbox_loc_perm
I0524 12:49:59.360411  9498 net.cpp:150] Setting up conv12_norm_mbox_loc_perm
I0524 12:49:59.360417  9498 net.cpp:157] Top shape: 2 28 28 24 (37632)
I0524 12:49:59.360421  9498 net.cpp:165] Memory required for data: 711659552
I0524 12:49:59.360424  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_loc_flat
I0524 12:49:59.360430  9498 net.cpp:100] Creating Layer conv12_norm_mbox_loc_flat
I0524 12:49:59.360433  9498 net.cpp:434] conv12_norm_mbox_loc_flat <- conv12_norm_mbox_loc_perm
I0524 12:49:59.360438  9498 net.cpp:408] conv12_norm_mbox_loc_flat -> conv12_norm_mbox_loc_flat
I0524 12:49:59.360473  9498 net.cpp:150] Setting up conv12_norm_mbox_loc_flat
I0524 12:49:59.360477  9498 net.cpp:157] Top shape: 2 18816 (37632)
I0524 12:49:59.360479  9498 net.cpp:165] Memory required for data: 711810080
I0524 12:49:59.360496  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf
I0524 12:49:59.360508  9498 net.cpp:100] Creating Layer conv12_norm_mbox_conf
I0524 12:49:59.360512  9498 net.cpp:434] conv12_norm_mbox_conf <- conv12_norm_conv12_norm_0_split_1
I0524 12:49:59.360517  9498 net.cpp:408] conv12_norm_mbox_conf -> conv12_norm_mbox_conf
I0524 12:49:59.364854  9498 net.cpp:150] Setting up conv12_norm_mbox_conf
I0524 12:49:59.364867  9498 net.cpp:157] Top shape: 2 36 28 28 (56448)
I0524 12:49:59.364871  9498 net.cpp:165] Memory required for data: 712035872
I0524 12:49:59.364892  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_perm
I0524 12:49:59.364899  9498 net.cpp:100] Creating Layer conv12_norm_mbox_conf_perm
I0524 12:49:59.364903  9498 net.cpp:434] conv12_norm_mbox_conf_perm <- conv12_norm_mbox_conf
I0524 12:49:59.364908  9498 net.cpp:408] conv12_norm_mbox_conf_perm -> conv12_norm_mbox_conf_perm
I0524 12:49:59.365156  9498 net.cpp:150] Setting up conv12_norm_mbox_conf_perm
I0524 12:49:59.365164  9498 net.cpp:157] Top shape: 2 28 28 36 (56448)
I0524 12:49:59.365165  9498 net.cpp:165] Memory required for data: 712261664
I0524 12:49:59.365168  9498 layer_factory.hpp:77] Creating layer conv12_norm_mbox_conf_flat
I0524 12:49:59.365175  9498 net.cpp:100] Creating Layer conv12_norm_mbox_conf_flat
I0524 12:49:59.365177  9498 net.cpp:434] conv12_norm_mbox_conf_flat <- conv12_norm_mbox_conf_perm
I0524 12:49:59.365181  9498 net.cpp:408] conv12_norm_mbox_conf_flat -> conv12_norm_mbox_conf_flat
I0524 12:49:59.365231  9498 net.cpp:150] Setting up conv12_norm_mbox_conf_flat
I0524 12:49:59.365237  9498 net.cpp:157] Top shape: 2 28224 (56448)
I0524 12:49:59.365240  9498 net.cpp:165] Memory required for data: 712487456
I0524 12:49:59.365242  9498 layer_factory.hpp:77] Creating layer ip7_mbox_loc
I0524 12:49:59.365250  9498 net.cpp:100] Creating Layer ip7_mbox_loc
I0524 12:49:59.365253  9498 net.cpp:434] ip7_mbox_loc <- ip7_relu7_0_split_1
I0524 12:49:59.365260  9498 net.cpp:408] ip7_mbox_loc -> ip7_mbox_loc
I0524 12:49:59.368566  9498 net.cpp:150] Setting up ip7_mbox_loc
I0524 12:49:59.368579  9498 net.cpp:157] Top shape: 2 24 14 14 (9408)
I0524 12:49:59.368582  9498 net.cpp:165] Memory required for data: 712525088
I0524 12:49:59.368589  9498 layer_factory.hpp:77] Creating layer ip7_mbox_loc_perm
I0524 12:49:59.368597  9498 net.cpp:100] Creating Layer ip7_mbox_loc_perm
I0524 12:49:59.368600  9498 net.cpp:434] ip7_mbox_loc_perm <- ip7_mbox_loc
I0524 12:49:59.368604  9498 net.cpp:408] ip7_mbox_loc_perm -> ip7_mbox_loc_perm
I0524 12:49:59.368851  9498 net.cpp:150] Setting up ip7_mbox_loc_perm
I0524 12:49:59.368857  9498 net.cpp:157] Top shape: 2 14 14 24 (9408)
I0524 12:49:59.368860  9498 net.cpp:165] Memory required for data: 712562720
I0524 12:49:59.368863  9498 layer_factory.hpp:77] Creating layer ip7_mbox_loc_flat
I0524 12:49:59.368870  9498 net.cpp:100] Creating Layer ip7_mbox_loc_flat
I0524 12:49:59.368872  9498 net.cpp:434] ip7_mbox_loc_flat <- ip7_mbox_loc_perm
I0524 12:49:59.368876  9498 net.cpp:408] ip7_mbox_loc_flat -> ip7_mbox_loc_flat
I0524 12:49:59.368911  9498 net.cpp:150] Setting up ip7_mbox_loc_flat
I0524 12:49:59.368918  9498 net.cpp:157] Top shape: 2 4704 (9408)
I0524 12:49:59.368921  9498 net.cpp:165] Memory required for data: 712600352
I0524 12:49:59.368924  9498 layer_factory.hpp:77] Creating layer ip7_mbox_conf
I0524 12:49:59.368933  9498 net.cpp:100] Creating Layer ip7_mbox_conf
I0524 12:49:59.368937  9498 net.cpp:434] ip7_mbox_conf <- ip7_relu7_0_split_2
I0524 12:49:59.368943  9498 net.cpp:408] ip7_mbox_conf -> ip7_mbox_conf
I0524 12:49:59.372448  9498 net.cpp:150] Setting up ip7_mbox_conf
I0524 12:49:59.372462  9498 net.cpp:157] Top shape: 2 36 14 14 (14112)
I0524 12:49:59.372464  9498 net.cpp:165] Memory required for data: 712656800
I0524 12:49:59.372471  9498 layer_factory.hpp:77] Creating layer ip7_mbox_conf_perm
I0524 12:49:59.372478  9498 net.cpp:100] Creating Layer ip7_mbox_conf_perm
I0524 12:49:59.372481  9498 net.cpp:434] ip7_mbox_conf_perm <- ip7_mbox_conf
I0524 12:49:59.372486  9498 net.cpp:408] ip7_mbox_conf_perm -> ip7_mbox_conf_perm
I0524 12:49:59.372732  9498 net.cpp:150] Setting up ip7_mbox_conf_perm
I0524 12:49:59.372740  9498 net.cpp:157] Top shape: 2 14 14 36 (14112)
I0524 12:49:59.372741  9498 net.cpp:165] Memory required for data: 712713248
I0524 12:49:59.372745  9498 layer_factory.hpp:77] Creating layer ip7_mbox_conf_flat
I0524 12:49:59.372750  9498 net.cpp:100] Creating Layer ip7_mbox_conf_flat
I0524 12:49:59.372751  9498 net.cpp:434] ip7_mbox_conf_flat <- ip7_mbox_conf_perm
I0524 12:49:59.372757  9498 net.cpp:408] ip7_mbox_conf_flat -> ip7_mbox_conf_flat
I0524 12:49:59.372807  9498 net.cpp:150] Setting up ip7_mbox_conf_flat
I0524 12:49:59.372812  9498 net.cpp:157] Top shape: 2 7056 (14112)
I0524 12:49:59.372814  9498 net.cpp:165] Memory required for data: 712769696
I0524 12:49:59.372819  9498 layer_factory.hpp:77] Creating layer conv12/dw_mbox_priorbox
I0524 12:49:59.372826  9498 net.cpp:100] Creating Layer conv12/dw_mbox_priorbox
I0524 12:49:59.372829  9498 net.cpp:434] conv12/dw_mbox_priorbox <- conv12/dw_conv12/dw/relu_0_split_2
I0524 12:49:59.372834  9498 net.cpp:434] conv12/dw_mbox_priorbox <- data_data_0_split_1
I0524 12:49:59.372840  9498 net.cpp:408] conv12/dw_mbox_priorbox -> conv12/dw_mbox_priorbox
I0524 12:49:59.372881  9498 net.cpp:150] Setting up conv12/dw_mbox_priorbox
I0524 12:49:59.372886  9498 net.cpp:157] Top shape: 1 2 18816 (37632)
I0524 12:49:59.372889  9498 net.cpp:165] Memory required for data: 712920224
I0524 12:49:59.372891  9498 layer_factory.hpp:77] Creating layer ip7_mbox_priorbox
I0524 12:49:59.372896  9498 net.cpp:100] Creating Layer ip7_mbox_priorbox
I0524 12:49:59.372900  9498 net.cpp:434] ip7_mbox_priorbox <- ip7_relu7_0_split_3
I0524 12:49:59.372903  9498 net.cpp:434] ip7_mbox_priorbox <- data_data_0_split_2
I0524 12:49:59.372908  9498 net.cpp:408] ip7_mbox_priorbox -> ip7_mbox_priorbox
I0524 12:49:59.372946  9498 net.cpp:150] Setting up ip7_mbox_priorbox
I0524 12:49:59.372949  9498 net.cpp:157] Top shape: 1 2 4704 (9408)
I0524 12:49:59.372952  9498 net.cpp:165] Memory required for data: 712957856
I0524 12:49:59.372954  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0524 12:49:59.372963  9498 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0524 12:49:59.372967  9498 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0524 12:49:59.372972  9498 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0524 12:49:59.381004  9498 net.cpp:150] Setting up conv6_2_mbox_loc
I0524 12:49:59.381019  9498 net.cpp:157] Top shape: 2 24 7 7 (2352)
I0524 12:49:59.381021  9498 net.cpp:165] Memory required for data: 712967264
I0524 12:49:59.381028  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0524 12:49:59.381036  9498 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0524 12:49:59.381042  9498 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0524 12:49:59.381047  9498 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0524 12:49:59.381295  9498 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0524 12:49:59.381301  9498 net.cpp:157] Top shape: 2 7 7 24 (2352)
I0524 12:49:59.381305  9498 net.cpp:165] Memory required for data: 712976672
I0524 12:49:59.381309  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0524 12:49:59.381314  9498 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0524 12:49:59.381316  9498 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0524 12:49:59.381322  9498 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0524 12:49:59.381357  9498 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0524 12:49:59.381361  9498 net.cpp:157] Top shape: 2 1176 (2352)
I0524 12:49:59.381363  9498 net.cpp:165] Memory required for data: 712986080
I0524 12:49:59.381366  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0524 12:49:59.381374  9498 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0524 12:49:59.381377  9498 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0524 12:49:59.381383  9498 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0524 12:49:59.384599  9498 net.cpp:150] Setting up conv6_2_mbox_conf
I0524 12:49:59.384613  9498 net.cpp:157] Top shape: 2 36 7 7 (3528)
I0524 12:49:59.384614  9498 net.cpp:165] Memory required for data: 713000192
I0524 12:49:59.384620  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0524 12:49:59.384644  9498 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0524 12:49:59.384647  9498 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0524 12:49:59.384654  9498 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0524 12:49:59.384892  9498 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0524 12:49:59.384901  9498 net.cpp:157] Top shape: 2 7 7 36 (3528)
I0524 12:49:59.384903  9498 net.cpp:165] Memory required for data: 713014304
I0524 12:49:59.384907  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0524 12:49:59.384910  9498 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0524 12:49:59.384914  9498 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0524 12:49:59.384919  9498 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0524 12:49:59.384950  9498 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0524 12:49:59.384954  9498 net.cpp:157] Top shape: 2 1764 (3528)
I0524 12:49:59.384958  9498 net.cpp:165] Memory required for data: 713028416
I0524 12:49:59.384959  9498 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0524 12:49:59.384965  9498 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0524 12:49:59.384968  9498 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0524 12:49:59.384972  9498 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0524 12:49:59.384977  9498 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0524 12:49:59.385013  9498 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0524 12:49:59.385018  9498 net.cpp:157] Top shape: 1 2 1176 (2352)
I0524 12:49:59.385021  9498 net.cpp:165] Memory required for data: 713037824
I0524 12:49:59.385023  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0524 12:49:59.385031  9498 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0524 12:49:59.385036  9498 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_0
I0524 12:49:59.385058  9498 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0524 12:49:59.388094  9498 net.cpp:150] Setting up conv7_2_mbox_loc
I0524 12:49:59.388108  9498 net.cpp:157] Top shape: 2 16 4 4 (512)
I0524 12:49:59.388109  9498 net.cpp:165] Memory required for data: 713039872
I0524 12:49:59.388116  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0524 12:49:59.388124  9498 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0524 12:49:59.388129  9498 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0524 12:49:59.388137  9498 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0524 12:49:59.388402  9498 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0524 12:49:59.388411  9498 net.cpp:157] Top shape: 2 4 4 16 (512)
I0524 12:49:59.388412  9498 net.cpp:165] Memory required for data: 713041920
I0524 12:49:59.388415  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0524 12:49:59.388422  9498 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0524 12:49:59.388427  9498 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0524 12:49:59.388432  9498 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0524 12:49:59.388484  9498 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0524 12:49:59.388489  9498 net.cpp:157] Top shape: 2 256 (512)
I0524 12:49:59.388492  9498 net.cpp:165] Memory required for data: 713043968
I0524 12:49:59.388495  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0524 12:49:59.388505  9498 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0524 12:49:59.388510  9498 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_1
I0524 12:49:59.388520  9498 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0524 12:49:59.396263  9498 net.cpp:150] Setting up conv7_2_mbox_conf
I0524 12:49:59.396278  9498 net.cpp:157] Top shape: 2 24 4 4 (768)
I0524 12:49:59.396296  9498 net.cpp:165] Memory required for data: 713047040
I0524 12:49:59.396302  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0524 12:49:59.396309  9498 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0524 12:49:59.396314  9498 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0524 12:49:59.396324  9498 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0524 12:49:59.396587  9498 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0524 12:49:59.396595  9498 net.cpp:157] Top shape: 2 4 4 24 (768)
I0524 12:49:59.396598  9498 net.cpp:165] Memory required for data: 713050112
I0524 12:49:59.396602  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0524 12:49:59.396608  9498 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0524 12:49:59.396611  9498 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0524 12:49:59.396618  9498 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0524 12:49:59.396670  9498 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0524 12:49:59.396677  9498 net.cpp:157] Top shape: 2 384 (768)
I0524 12:49:59.396678  9498 net.cpp:165] Memory required for data: 713053184
I0524 12:49:59.396682  9498 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0524 12:49:59.396692  9498 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0524 12:49:59.396695  9498 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_2
I0524 12:49:59.396701  9498 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0524 12:49:59.396710  9498 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0524 12:49:59.396765  9498 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0524 12:49:59.396771  9498 net.cpp:157] Top shape: 1 2 256 (512)
I0524 12:49:59.396775  9498 net.cpp:165] Memory required for data: 713055232
I0524 12:49:59.396777  9498 layer_factory.hpp:77] Creating layer mbox_loc
I0524 12:49:59.396785  9498 net.cpp:100] Creating Layer mbox_loc
I0524 12:49:59.396790  9498 net.cpp:434] mbox_loc <- conv12_norm_mbox_loc_flat
I0524 12:49:59.396797  9498 net.cpp:434] mbox_loc <- ip7_mbox_loc_flat
I0524 12:49:59.396803  9498 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0524 12:49:59.396809  9498 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0524 12:49:59.396819  9498 net.cpp:408] mbox_loc -> mbox_loc
I0524 12:49:59.396869  9498 net.cpp:150] Setting up mbox_loc
I0524 12:49:59.396875  9498 net.cpp:157] Top shape: 2 24952 (49904)
I0524 12:49:59.396878  9498 net.cpp:165] Memory required for data: 713254848
I0524 12:49:59.396881  9498 layer_factory.hpp:77] Creating layer mbox_conf
I0524 12:49:59.396889  9498 net.cpp:100] Creating Layer mbox_conf
I0524 12:49:59.396893  9498 net.cpp:434] mbox_conf <- conv12_norm_mbox_conf_flat
I0524 12:49:59.396899  9498 net.cpp:434] mbox_conf <- ip7_mbox_conf_flat
I0524 12:49:59.396905  9498 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0524 12:49:59.396910  9498 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0524 12:49:59.396917  9498 net.cpp:408] mbox_conf -> mbox_conf
I0524 12:49:59.396970  9498 net.cpp:150] Setting up mbox_conf
I0524 12:49:59.396976  9498 net.cpp:157] Top shape: 2 37428 (74856)
I0524 12:49:59.396978  9498 net.cpp:165] Memory required for data: 713554272
I0524 12:49:59.396981  9498 layer_factory.hpp:77] Creating layer mbox_priorbox
I0524 12:49:59.396986  9498 net.cpp:100] Creating Layer mbox_priorbox
I0524 12:49:59.396991  9498 net.cpp:434] mbox_priorbox <- conv12/dw_mbox_priorbox
I0524 12:49:59.396996  9498 net.cpp:434] mbox_priorbox <- ip7_mbox_priorbox
I0524 12:49:59.397002  9498 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0524 12:49:59.397008  9498 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0524 12:49:59.397017  9498 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0524 12:49:59.397063  9498 net.cpp:150] Setting up mbox_priorbox
I0524 12:49:59.397069  9498 net.cpp:157] Top shape: 1 2 24952 (49904)
I0524 12:49:59.397073  9498 net.cpp:165] Memory required for data: 713753888
I0524 12:49:59.397076  9498 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0524 12:49:59.397091  9498 net.cpp:100] Creating Layer mbox_conf_reshape
I0524 12:49:59.397096  9498 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0524 12:49:59.397106  9498 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0524 12:49:59.397173  9498 net.cpp:150] Setting up mbox_conf_reshape
I0524 12:49:59.397181  9498 net.cpp:157] Top shape: 2 6238 6 (74856)
I0524 12:49:59.397182  9498 net.cpp:165] Memory required for data: 714053312
I0524 12:49:59.397186  9498 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0524 12:49:59.397192  9498 net.cpp:100] Creating Layer mbox_conf_softmax
I0524 12:49:59.397194  9498 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0524 12:49:59.397200  9498 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0524 12:49:59.398546  9498 net.cpp:150] Setting up mbox_conf_softmax
I0524 12:49:59.398560  9498 net.cpp:157] Top shape: 2 6238 6 (74856)
I0524 12:49:59.398562  9498 net.cpp:165] Memory required for data: 714352736
I0524 12:49:59.398566  9498 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0524 12:49:59.398571  9498 net.cpp:100] Creating Layer mbox_conf_flatten
I0524 12:49:59.398574  9498 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0524 12:49:59.398582  9498 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0524 12:49:59.398641  9498 net.cpp:150] Setting up mbox_conf_flatten
I0524 12:49:59.398648  9498 net.cpp:157] Top shape: 2 37428 (74856)
I0524 12:49:59.398651  9498 net.cpp:165] Memory required for data: 714652160
I0524 12:49:59.398654  9498 layer_factory.hpp:77] Creating layer detection_out
I0524 12:49:59.398665  9498 net.cpp:100] Creating Layer detection_out
I0524 12:49:59.398670  9498 net.cpp:434] detection_out <- mbox_loc
I0524 12:49:59.398675  9498 net.cpp:434] detection_out <- mbox_conf_flatten
I0524 12:49:59.398681  9498 net.cpp:434] detection_out <- mbox_priorbox
I0524 12:49:59.398689  9498 net.cpp:408] detection_out -> detection_out
11111
I0524 12:49:59.398828  9498 net.cpp:150] Setting up detection_out
I0524 12:49:59.398834  9498 net.cpp:157] Top shape: 1 1 1 7 (7)
I0524 12:49:59.398836  9498 net.cpp:165] Memory required for data: 714652188
I0524 12:49:59.398839  9498 layer_factory.hpp:77] Creating layer detection_eval
I0524 12:49:59.398845  9498 net.cpp:100] Creating Layer detection_eval
I0524 12:49:59.398849  9498 net.cpp:434] detection_eval <- detection_out
I0524 12:49:59.398855  9498 net.cpp:434] detection_eval <- label
I0524 12:49:59.398864  9498 net.cpp:408] detection_eval -> detection_eval
I0524 12:49:59.399124  9498 net.cpp:150] Setting up detection_eval
I0524 12:49:59.399132  9498 net.cpp:157] Top shape: 1 1 6 5 (30)
I0524 12:49:59.399137  9498 net.cpp:165] Memory required for data: 714652308
I0524 12:49:59.399140  9498 net.cpp:228] detection_eval does not need backward computation.
I0524 12:49:59.399147  9498 net.cpp:228] detection_out does not need backward computation.
I0524 12:49:59.399152  9498 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0524 12:49:59.399155  9498 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0524 12:49:59.399159  9498 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0524 12:49:59.399164  9498 net.cpp:228] mbox_priorbox does not need backward computation.
I0524 12:49:59.399170  9498 net.cpp:228] mbox_conf does not need backward computation.
I0524 12:49:59.399176  9498 net.cpp:228] mbox_loc does not need backward computation.
I0524 12:49:59.399183  9498 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0524 12:49:59.399188  9498 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0524 12:49:59.399194  9498 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0524 12:49:59.399199  9498 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0524 12:49:59.399204  9498 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0524 12:49:59.399209  9498 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0524 12:49:59.399214  9498 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0524 12:49:59.399230  9498 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0524 12:49:59.399235  9498 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0524 12:49:59.399241  9498 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0524 12:49:59.399245  9498 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0524 12:49:59.399250  9498 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0524 12:49:59.399255  9498 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0524 12:49:59.399260  9498 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0524 12:49:59.399266  9498 net.cpp:228] ip7_mbox_priorbox does not need backward computation.
I0524 12:49:59.399271  9498 net.cpp:228] conv12/dw_mbox_priorbox does not need backward computation.
I0524 12:49:59.399276  9498 net.cpp:228] ip7_mbox_conf_flat does not need backward computation.
I0524 12:49:59.399282  9498 net.cpp:228] ip7_mbox_conf_perm does not need backward computation.
I0524 12:49:59.399287  9498 net.cpp:228] ip7_mbox_conf does not need backward computation.
I0524 12:49:59.399292  9498 net.cpp:228] ip7_mbox_loc_flat does not need backward computation.
I0524 12:49:59.399297  9498 net.cpp:228] ip7_mbox_loc_perm does not need backward computation.
I0524 12:49:59.399303  9498 net.cpp:228] ip7_mbox_loc does not need backward computation.
I0524 12:49:59.399308  9498 net.cpp:228] conv12_norm_mbox_conf_flat does not need backward computation.
I0524 12:49:59.399313  9498 net.cpp:228] conv12_norm_mbox_conf_perm does not need backward computation.
I0524 12:49:59.399318  9498 net.cpp:228] conv12_norm_mbox_conf does not need backward computation.
I0524 12:49:59.399323  9498 net.cpp:228] conv12_norm_mbox_loc_flat does not need backward computation.
I0524 12:49:59.399328  9498 net.cpp:228] conv12_norm_mbox_loc_perm does not need backward computation.
I0524 12:49:59.399334  9498 net.cpp:228] conv12_norm_mbox_loc does not need backward computation.
I0524 12:49:59.399339  9498 net.cpp:228] conv12_norm_conv12_norm_0_split does not need backward computation.
I0524 12:49:59.399345  9498 net.cpp:228] conv12_norm does not need backward computation.
I0524 12:49:59.399350  9498 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0524 12:49:59.399356  9498 net.cpp:228] conv7_2_relu does not need backward computation.
I0524 12:49:59.399360  9498 net.cpp:228] conv7_2 does not need backward computation.
I0524 12:49:59.399366  9498 net.cpp:228] conv7_1_relu does not need backward computation.
I0524 12:49:59.399370  9498 net.cpp:228] conv7_1 does not need backward computation.
I0524 12:49:59.399376  9498 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0524 12:49:59.399381  9498 net.cpp:228] conv6_2_relu does not need backward computation.
I0524 12:49:59.399386  9498 net.cpp:228] conv6_2 does not need backward computation.
I0524 12:49:59.399392  9498 net.cpp:228] conv6_1_relu does not need backward computation.
I0524 12:49:59.399396  9498 net.cpp:228] conv6_1 does not need backward computation.
I0524 12:49:59.399402  9498 net.cpp:228] ip7_relu7_0_split does not need backward computation.
I0524 12:49:59.399407  9498 net.cpp:228] relu7 does not need backward computation.
I0524 12:49:59.399411  9498 net.cpp:228] ip7 does not need backward computation.
I0524 12:49:59.399416  9498 net.cpp:228] relu6 does not need backward computation.
I0524 12:49:59.399420  9498 net.cpp:228] ip6 does not need backward computation.
I0524 12:49:59.399426  9498 net.cpp:228] conv13/relu does not need backward computation.
I0524 12:49:59.399430  9498 net.cpp:228] conv13/scale does not need backward computation.
I0524 12:49:59.399435  9498 net.cpp:228] conv13/bn does not need backward computation.
I0524 12:49:59.399438  9498 net.cpp:228] conv13 does not need backward computation.
I0524 12:49:59.399444  9498 net.cpp:228] conv13/dw/relu does not need backward computation.
I0524 12:49:59.399454  9498 net.cpp:228] conv13/dw/scale does not need backward computation.
I0524 12:49:59.399459  9498 net.cpp:228] conv13/dw/bn does not need backward computation.
I0524 12:49:59.399463  9498 net.cpp:228] conv13/dw does not need backward computation.
I0524 12:49:59.399469  9498 net.cpp:228] conv12/relu does not need backward computation.
I0524 12:49:59.399474  9498 net.cpp:228] conv12/scale does not need backward computation.
I0524 12:49:59.399478  9498 net.cpp:228] conv12/bn does not need backward computation.
I0524 12:49:59.399482  9498 net.cpp:228] conv12 does not need backward computation.
I0524 12:49:59.399488  9498 net.cpp:228] sample_pooling does not need backward computation.
I0524 12:49:59.399493  9498 net.cpp:228] conv12/dw_conv12/dw/relu_0_split does not need backward computation.
I0524 12:49:59.399498  9498 net.cpp:228] conv12/dw/relu does not need backward computation.
I0524 12:49:59.399503  9498 net.cpp:228] conv12/dw/scale does not need backward computation.
I0524 12:49:59.399509  9498 net.cpp:228] conv12/dw/bn does not need backward computation.
I0524 12:49:59.399513  9498 net.cpp:228] conv12/dw does not need backward computation.
I0524 12:49:59.399518  9498 net.cpp:228] conv11/relu does not need backward computation.
I0524 12:49:59.399523  9498 net.cpp:228] conv11/scale does not need backward computation.
I0524 12:49:59.399528  9498 net.cpp:228] conv11/bn does not need backward computation.
I0524 12:49:59.399533  9498 net.cpp:228] conv11 does not need backward computation.
I0524 12:49:59.399538  9498 net.cpp:228] conv11/dw/relu does not need backward computation.
I0524 12:49:59.399541  9498 net.cpp:228] conv11/dw/scale does not need backward computation.
I0524 12:49:59.399546  9498 net.cpp:228] conv11/dw/bn does not need backward computation.
I0524 12:49:59.399551  9498 net.cpp:228] conv11/dw does not need backward computation.
I0524 12:49:59.399556  9498 net.cpp:228] conv10/relu does not need backward computation.
I0524 12:49:59.399560  9498 net.cpp:228] conv10/scale does not need backward computation.
I0524 12:49:59.399565  9498 net.cpp:228] conv10/bn does not need backward computation.
I0524 12:49:59.399569  9498 net.cpp:228] conv10 does not need backward computation.
I0524 12:49:59.399574  9498 net.cpp:228] conv10/dw/relu does not need backward computation.
I0524 12:49:59.399580  9498 net.cpp:228] conv10/dw/scale does not need backward computation.
I0524 12:49:59.399585  9498 net.cpp:228] conv10/dw/bn does not need backward computation.
I0524 12:49:59.399588  9498 net.cpp:228] conv10/dw does not need backward computation.
I0524 12:49:59.399592  9498 net.cpp:228] conv9/relu does not need backward computation.
I0524 12:49:59.399597  9498 net.cpp:228] conv9/scale does not need backward computation.
I0524 12:49:59.399601  9498 net.cpp:228] conv9/bn does not need backward computation.
I0524 12:49:59.399605  9498 net.cpp:228] conv9 does not need backward computation.
I0524 12:49:59.399610  9498 net.cpp:228] conv9/dw/relu does not need backward computation.
I0524 12:49:59.399616  9498 net.cpp:228] conv9/dw/scale does not need backward computation.
I0524 12:49:59.399621  9498 net.cpp:228] conv9/dw/bn does not need backward computation.
I0524 12:49:59.399624  9498 net.cpp:228] conv9/dw does not need backward computation.
I0524 12:49:59.399628  9498 net.cpp:228] conv8/relu does not need backward computation.
I0524 12:49:59.399632  9498 net.cpp:228] conv8/scale does not need backward computation.
I0524 12:49:59.399637  9498 net.cpp:228] conv8/bn does not need backward computation.
I0524 12:49:59.399641  9498 net.cpp:228] conv8 does not need backward computation.
I0524 12:49:59.399646  9498 net.cpp:228] conv8/dw/relu does not need backward computation.
I0524 12:49:59.399652  9498 net.cpp:228] conv8/dw/scale does not need backward computation.
I0524 12:49:59.399657  9498 net.cpp:228] conv8/dw/bn does not need backward computation.
I0524 12:49:59.399660  9498 net.cpp:228] conv8/dw does not need backward computation.
I0524 12:49:59.399665  9498 net.cpp:228] conv7/relu does not need backward computation.
I0524 12:49:59.399677  9498 net.cpp:228] conv7/scale does not need backward computation.
I0524 12:49:59.399682  9498 net.cpp:228] conv7/bn does not need backward computation.
I0524 12:49:59.399688  9498 net.cpp:228] conv7 does not need backward computation.
I0524 12:49:59.399691  9498 net.cpp:228] conv7/dw/relu does not need backward computation.
I0524 12:49:59.399695  9498 net.cpp:228] conv7/dw/scale does not need backward computation.
I0524 12:49:59.399700  9498 net.cpp:228] conv7/dw/bn does not need backward computation.
I0524 12:49:59.399705  9498 net.cpp:228] conv7/dw does not need backward computation.
I0524 12:49:59.399709  9498 net.cpp:228] conv6/relu does not need backward computation.
I0524 12:49:59.399714  9498 net.cpp:228] conv6/scale does not need backward computation.
I0524 12:49:59.399719  9498 net.cpp:228] conv6/bn does not need backward computation.
I0524 12:49:59.399724  9498 net.cpp:228] conv6 does not need backward computation.
I0524 12:49:59.399729  9498 net.cpp:228] conv6/dw/relu does not need backward computation.
I0524 12:49:59.399732  9498 net.cpp:228] conv6/dw/scale does not need backward computation.
I0524 12:49:59.399739  9498 net.cpp:228] conv6/dw/bn does not need backward computation.
I0524 12:49:59.399742  9498 net.cpp:228] conv6/dw does not need backward computation.
I0524 12:49:59.399747  9498 net.cpp:228] conv5/relu does not need backward computation.
I0524 12:49:59.399751  9498 net.cpp:228] conv5/scale does not need backward computation.
I0524 12:49:59.399756  9498 net.cpp:228] conv5/bn does not need backward computation.
I0524 12:49:59.399760  9498 net.cpp:228] conv5 does not need backward computation.
I0524 12:49:59.399765  9498 net.cpp:228] conv5/dw/relu does not need backward computation.
I0524 12:49:59.399770  9498 net.cpp:228] conv5/dw/scale does not need backward computation.
I0524 12:49:59.399775  9498 net.cpp:228] conv5/dw/bn does not need backward computation.
I0524 12:49:59.399778  9498 net.cpp:228] conv5/dw does not need backward computation.
I0524 12:49:59.399783  9498 net.cpp:228] conv4/relu does not need backward computation.
I0524 12:49:59.399787  9498 net.cpp:228] conv4/scale does not need backward computation.
I0524 12:49:59.399792  9498 net.cpp:228] conv4/bn does not need backward computation.
I0524 12:49:59.399796  9498 net.cpp:228] conv4 does not need backward computation.
I0524 12:49:59.399801  9498 net.cpp:228] conv4/dw/relu does not need backward computation.
I0524 12:49:59.399806  9498 net.cpp:228] conv4/dw/scale does not need backward computation.
I0524 12:49:59.399811  9498 net.cpp:228] conv4/dw/bn does not need backward computation.
I0524 12:49:59.399816  9498 net.cpp:228] conv4/dw does not need backward computation.
I0524 12:49:59.399821  9498 net.cpp:228] conv3/relu does not need backward computation.
I0524 12:49:59.399824  9498 net.cpp:228] conv3/scale does not need backward computation.
I0524 12:49:59.399839  9498 net.cpp:228] conv3/bn does not need backward computation.
I0524 12:49:59.399844  9498 net.cpp:228] conv3 does not need backward computation.
I0524 12:49:59.399848  9498 net.cpp:228] conv3/dw/relu does not need backward computation.
I0524 12:49:59.399853  9498 net.cpp:228] conv3/dw/scale does not need backward computation.
I0524 12:49:59.399858  9498 net.cpp:228] conv3/dw/bn does not need backward computation.
I0524 12:49:59.399863  9498 net.cpp:228] conv3/dw does not need backward computation.
I0524 12:49:59.399868  9498 net.cpp:228] conv2/relu does not need backward computation.
I0524 12:49:59.399870  9498 net.cpp:228] conv2/scale does not need backward computation.
I0524 12:49:59.399891  9498 net.cpp:228] conv2/bn does not need backward computation.
I0524 12:49:59.399895  9498 net.cpp:228] conv2 does not need backward computation.
I0524 12:49:59.399900  9498 net.cpp:228] conv2/dw/relu does not need backward computation.
I0524 12:49:59.399904  9498 net.cpp:228] conv2/dw/scale does not need backward computation.
I0524 12:49:59.399909  9498 net.cpp:228] conv2/dw/bn does not need backward computation.
I0524 12:49:59.399914  9498 net.cpp:228] conv2/dw does not need backward computation.
I0524 12:49:59.399924  9498 net.cpp:228] conv1/relu does not need backward computation.
I0524 12:49:59.399929  9498 net.cpp:228] conv1/scale does not need backward computation.
I0524 12:49:59.399932  9498 net.cpp:228] conv1/bn does not need backward computation.
I0524 12:49:59.399936  9498 net.cpp:228] conv1 does not need backward computation.
I0524 12:49:59.399941  9498 net.cpp:228] conv1/dw/relu does not need backward computation.
I0524 12:49:59.399945  9498 net.cpp:228] conv1/dw/scale does not need backward computation.
I0524 12:49:59.399950  9498 net.cpp:228] conv1/dw/bn does not need backward computation.
I0524 12:49:59.399955  9498 net.cpp:228] conv1/dw does not need backward computation.
I0524 12:49:59.399958  9498 net.cpp:228] conv0/relu does not need backward computation.
I0524 12:49:59.399963  9498 net.cpp:228] conv0/scale does not need backward computation.
I0524 12:49:59.399968  9498 net.cpp:228] conv0/bn does not need backward computation.
I0524 12:49:59.399973  9498 net.cpp:228] conv0 does not need backward computation.
I0524 12:49:59.399978  9498 net.cpp:228] data_data_0_split does not need backward computation.
I0524 12:49:59.399983  9498 net.cpp:228] data does not need backward computation.
I0524 12:49:59.399987  9498 net.cpp:270] This network produces output detection_eval
I0524 12:49:59.400074  9498 net.cpp:283] Network initialization done.
I0524 12:49:59.400480  9498 solver.cpp:75] Solver scaffolding done.
I0524 12:49:59.414973  9498 caffe.cpp:155] Finetuning from mobilessd_step1/step1_iter_5000.caffemodel
I0524 12:49:59.432667  9498 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/step1_iter_5000.caffemodel
I0524 12:49:59.432718  9498 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0524 12:49:59.447791  9498 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilessd_step1/step1_iter_5000.caffemodel
I0524 12:49:59.447840  9498 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0524 12:49:59.452679  9498 net.cpp:761] Ignoring source layer mbox_loss
I0524 12:49:59.452917  9498 caffe.cpp:251] Starting Optimization
I0524 12:49:59.452927  9498 solver.cpp:294] Solving MobileNet-SSD
I0524 12:49:59.452929  9498 solver.cpp:295] Learning Rate Policy: multistep
I0524 12:50:00.953624  9498 solver.cpp:243] Iteration 0, loss = 5.76789
I0524 12:50:00.953657  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.76789 (* 1 = 5.76789 loss)
I0524 12:50:00.953673  9498 sgd_solver.cpp:138] Iteration 0, lr = 0.0001
I0524 12:52:11.827225  9498 solver.cpp:243] Iteration 100, loss = 5.65988
I0524 12:52:11.827323  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.97863 (* 1 = 5.97863 loss)
I0524 12:52:11.827347  9498 sgd_solver.cpp:138] Iteration 100, lr = 0.0001
I0524 12:54:23.029332  9498 solver.cpp:243] Iteration 200, loss = 5.28468
I0524 12:54:23.029464  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.48896 (* 1 = 4.48896 loss)
I0524 12:54:23.029474  9498 sgd_solver.cpp:138] Iteration 200, lr = 0.0001
I0524 12:56:34.236840  9498 solver.cpp:243] Iteration 300, loss = 5.43728
I0524 12:56:34.236985  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.51236 (* 1 = 5.51236 loss)
I0524 12:56:34.236992  9498 sgd_solver.cpp:138] Iteration 300, lr = 0.0001
I0524 12:58:45.420024  9498 solver.cpp:243] Iteration 400, loss = 5.50386
I0524 12:58:45.420162  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.62391 (* 1 = 5.62391 loss)
I0524 12:58:45.420171  9498 sgd_solver.cpp:138] Iteration 400, lr = 0.0001
I0524 13:00:55.382596  9498 solver.cpp:433] Iteration 500, Testing net (#0)
I0524 13:00:55.390121  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 13:01:58.563699  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.117689
I0524 13:01:59.788599  9498 solver.cpp:243] Iteration 500, loss = 5.94162
I0524 13:01:59.788636  9498 solver.cpp:259]     Train net output #0: mbox_loss = 7.00162 (* 1 = 7.00162 loss)
I0524 13:01:59.788643  9498 sgd_solver.cpp:138] Iteration 500, lr = 0.0001
I0524 13:04:12.058953  9498 solver.cpp:243] Iteration 600, loss = 5.51855
I0524 13:04:12.059108  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.91321 (* 1 = 5.91321 loss)
I0524 13:04:12.059121  9498 sgd_solver.cpp:138] Iteration 600, lr = 0.0001
I0524 13:06:24.336158  9498 solver.cpp:243] Iteration 700, loss = 5.36468
I0524 13:06:24.336294  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.09658 (* 1 = 6.09658 loss)
I0524 13:06:24.336302  9498 sgd_solver.cpp:138] Iteration 700, lr = 0.0001
I0524 13:08:36.568742  9498 solver.cpp:243] Iteration 800, loss = 5.43056
I0524 13:08:36.568884  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.01011 (* 1 = 5.01011 loss)
I0524 13:08:36.568893  9498 sgd_solver.cpp:138] Iteration 800, lr = 0.0001
I0524 13:10:48.982379  9498 solver.cpp:243] Iteration 900, loss = 5.45535
I0524 13:10:48.982550  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.65402 (* 1 = 4.65402 loss)
I0524 13:10:48.982561  9498 sgd_solver.cpp:138] Iteration 900, lr = 0.0001
I0524 13:13:00.062804  9498 solver.cpp:433] Iteration 1000, Testing net (#0)
I0524 13:13:00.063024  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 13:14:03.994527  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.136496
I0524 13:14:05.235651  9498 solver.cpp:243] Iteration 1000, loss = 5.5847
I0524 13:14:05.235684  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.89988 (* 1 = 5.89988 loss)
I0524 13:14:05.235690  9498 sgd_solver.cpp:138] Iteration 1000, lr = 0.0001
I0524 13:16:17.764763  9498 solver.cpp:243] Iteration 1100, loss = 5.6387
I0524 13:16:17.764909  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.36778 (* 1 = 5.36778 loss)
I0524 13:16:17.764917  9498 sgd_solver.cpp:138] Iteration 1100, lr = 0.0001
I0524 13:18:30.237880  9498 solver.cpp:243] Iteration 1200, loss = 5.46604
I0524 13:18:30.238014  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.08932 (* 1 = 6.08932 loss)
I0524 13:18:30.238023  9498 sgd_solver.cpp:138] Iteration 1200, lr = 0.0001
I0524 13:20:42.716173  9498 solver.cpp:243] Iteration 1300, loss = 5.72217
I0524 13:20:42.716307  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.55764 (* 1 = 5.55764 loss)
I0524 13:20:42.716316  9498 sgd_solver.cpp:138] Iteration 1300, lr = 0.0001
I0524 13:22:55.258661  9498 solver.cpp:243] Iteration 1400, loss = 5.21709
I0524 13:22:55.258795  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.86622 (* 1 = 4.86622 loss)
I0524 13:22:55.258802  9498 sgd_solver.cpp:138] Iteration 1400, lr = 0.0001
I0524 13:25:06.562237  9498 solver.cpp:433] Iteration 1500, Testing net (#0)
I0524 13:25:06.562453  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 13:26:10.568037  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.13878
I0524 13:26:11.805733  9498 solver.cpp:243] Iteration 1500, loss = 5.46931
I0524 13:26:11.805768  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.46468 (* 1 = 5.46468 loss)
I0524 13:26:11.805774  9498 sgd_solver.cpp:138] Iteration 1500, lr = 0.0001
I0524 13:28:24.384932  9498 solver.cpp:243] Iteration 1600, loss = 5.78187
I0524 13:28:24.385068  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.26023 (* 1 = 6.26023 loss)
I0524 13:28:24.385076  9498 sgd_solver.cpp:138] Iteration 1600, lr = 0.0001
I0524 13:30:37.011327  9498 solver.cpp:243] Iteration 1700, loss = 5.34571
I0524 13:30:37.011452  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.08753 (* 1 = 4.08753 loss)
I0524 13:30:37.011461  9498 sgd_solver.cpp:138] Iteration 1700, lr = 0.0001
I0524 13:32:49.636286  9498 solver.cpp:243] Iteration 1800, loss = 5.30125
I0524 13:32:49.636377  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.2217 (* 1 = 4.2217 loss)
I0524 13:32:49.636386  9498 sgd_solver.cpp:138] Iteration 1800, lr = 0.0001
I0524 13:35:02.181088  9498 solver.cpp:243] Iteration 1900, loss = 5.56613
I0524 13:35:02.181234  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.80098 (* 1 = 5.80098 loss)
I0524 13:35:02.181242  9498 sgd_solver.cpp:138] Iteration 1900, lr = 0.0001
I0524 13:37:13.602502  9498 solver.cpp:433] Iteration 2000, Testing net (#0)
I0524 13:37:13.602716  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 13:38:17.520221  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.132196
I0524 13:38:18.756706  9498 solver.cpp:243] Iteration 2000, loss = 5.55776
I0524 13:38:18.756739  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.17977 (* 1 = 5.17977 loss)
I0524 13:38:18.756747  9498 sgd_solver.cpp:138] Iteration 2000, lr = 0.0001
I0524 13:40:31.470104  9498 solver.cpp:243] Iteration 2100, loss = 5.3647
I0524 13:40:31.470243  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.91555 (* 1 = 5.91555 loss)
I0524 13:40:31.470252  9498 sgd_solver.cpp:138] Iteration 2100, lr = 0.0001
I0524 13:42:43.982018  9498 solver.cpp:243] Iteration 2200, loss = 5.2882
I0524 13:42:43.982173  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.89112 (* 1 = 5.89112 loss)
I0524 13:42:43.982183  9498 sgd_solver.cpp:138] Iteration 2200, lr = 0.0001
I0524 13:44:56.567566  9498 solver.cpp:243] Iteration 2300, loss = 5.67615
I0524 13:44:56.567728  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.96104 (* 1 = 4.96104 loss)
I0524 13:44:56.567736  9498 sgd_solver.cpp:138] Iteration 2300, lr = 0.0001
I0524 13:47:09.154906  9498 solver.cpp:243] Iteration 2400, loss = 5.50113
I0524 13:47:09.155061  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.16601 (* 1 = 4.16601 loss)
I0524 13:47:09.155069  9498 sgd_solver.cpp:138] Iteration 2400, lr = 0.0001
I0524 13:49:20.503667  9498 solver.cpp:433] Iteration 2500, Testing net (#0)
I0524 13:49:20.504048  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 13:50:24.448276  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.127635
I0524 13:50:25.682530  9498 solver.cpp:243] Iteration 2500, loss = 5.4989
I0524 13:50:25.682566  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.35006 (* 1 = 5.35006 loss)
I0524 13:50:25.682574  9498 sgd_solver.cpp:138] Iteration 2500, lr = 0.0001
I0524 13:52:38.431861  9498 solver.cpp:243] Iteration 2600, loss = 5.24832
I0524 13:52:38.431998  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.50006 (* 1 = 5.50006 loss)
I0524 13:52:38.432006  9498 sgd_solver.cpp:138] Iteration 2600, lr = 0.0001
I0524 13:54:50.940951  9498 solver.cpp:243] Iteration 2700, loss = 5.42836
I0524 13:54:50.941038  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.31949 (* 1 = 5.31949 loss)
I0524 13:54:50.941046  9498 sgd_solver.cpp:138] Iteration 2700, lr = 0.0001
I0524 13:57:03.559082  9498 solver.cpp:243] Iteration 2800, loss = 5.59732
I0524 13:57:03.559243  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.94637 (* 1 = 5.94637 loss)
I0524 13:57:03.559252  9498 sgd_solver.cpp:138] Iteration 2800, lr = 0.0001
I0524 13:59:16.114693  9498 solver.cpp:243] Iteration 2900, loss = 5.45744
I0524 13:59:16.114846  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.34862 (* 1 = 5.34862 loss)
I0524 13:59:16.114856  9498 sgd_solver.cpp:138] Iteration 2900, lr = 0.0001
I0524 14:01:27.588723  9498 solver.cpp:433] Iteration 3000, Testing net (#0)
I0524 14:01:27.588940  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 14:02:31.576360  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.150625
I0524 14:02:32.809016  9498 solver.cpp:243] Iteration 3000, loss = 5.16162
I0524 14:02:32.809048  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.28069 (* 1 = 5.28069 loss)
I0524 14:02:32.809056  9498 sgd_solver.cpp:138] Iteration 3000, lr = 0.0001
I0524 14:04:45.349898  9498 solver.cpp:243] Iteration 3100, loss = 5.40577
I0524 14:04:45.350033  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.10197 (* 1 = 5.10197 loss)
I0524 14:04:45.350056  9498 sgd_solver.cpp:138] Iteration 3100, lr = 0.0001
I0524 14:06:57.889714  9498 solver.cpp:243] Iteration 3200, loss = 5.40228
I0524 14:06:57.889889  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.62546 (* 1 = 5.62546 loss)
I0524 14:06:57.889899  9498 sgd_solver.cpp:138] Iteration 3200, lr = 0.0001
I0524 14:09:10.547308  9498 solver.cpp:243] Iteration 3300, loss = 5.2191
I0524 14:09:10.547462  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.00877 (* 1 = 5.00877 loss)
I0524 14:09:10.547471  9498 sgd_solver.cpp:138] Iteration 3300, lr = 0.0001
I0524 14:11:23.139575  9498 solver.cpp:243] Iteration 3400, loss = 5.27033
I0524 14:11:23.139683  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.18066 (* 1 = 5.18066 loss)
I0524 14:11:23.139690  9498 sgd_solver.cpp:138] Iteration 3400, lr = 0.0001
I0524 14:13:34.569880  9498 solver.cpp:433] Iteration 3500, Testing net (#0)
I0524 14:13:34.570092  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 14:14:38.556430  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.139785
I0524 14:14:39.793776  9498 solver.cpp:243] Iteration 3500, loss = 5.61092
I0524 14:14:39.793823  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.11616 (* 1 = 5.11616 loss)
I0524 14:14:39.793831  9498 sgd_solver.cpp:138] Iteration 3500, lr = 0.0001
I0524 14:16:52.537735  9498 solver.cpp:243] Iteration 3600, loss = 5.31173
I0524 14:16:52.537886  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.56837 (* 1 = 5.56837 loss)
I0524 14:16:52.537895  9498 sgd_solver.cpp:138] Iteration 3600, lr = 0.0001
I0524 14:19:05.218523  9498 solver.cpp:243] Iteration 3700, loss = 5.12494
I0524 14:19:05.218647  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.65407 (* 1 = 5.65407 loss)
I0524 14:19:05.218655  9498 sgd_solver.cpp:138] Iteration 3700, lr = 0.0001
I0524 14:21:17.935943  9498 solver.cpp:243] Iteration 3800, loss = 5.31705
I0524 14:21:17.936097  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.04295 (* 1 = 5.04295 loss)
I0524 14:21:17.936105  9498 sgd_solver.cpp:138] Iteration 3800, lr = 0.0001
I0524 14:23:30.730521  9498 solver.cpp:243] Iteration 3900, loss = 5.40216
I0524 14:23:30.730646  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.48558 (* 1 = 5.48558 loss)
I0524 14:23:30.730655  9498 sgd_solver.cpp:138] Iteration 3900, lr = 0.0001
I0524 14:25:42.088717  9498 solver.cpp:433] Iteration 4000, Testing net (#0)
I0524 14:25:42.088933  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 14:26:46.062589  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.151416
I0524 14:26:47.302610  9498 solver.cpp:243] Iteration 4000, loss = 5.16306
I0524 14:26:47.302644  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.89332 (* 1 = 5.89332 loss)
I0524 14:26:47.302651  9498 sgd_solver.cpp:138] Iteration 4000, lr = 0.0001
I0524 14:28:59.982178  9498 solver.cpp:243] Iteration 4100, loss = 5.46842
I0524 14:28:59.982340  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.36674 (* 1 = 4.36674 loss)
I0524 14:28:59.982348  9498 sgd_solver.cpp:138] Iteration 4100, lr = 0.0001
I0524 14:31:12.601794  9498 solver.cpp:243] Iteration 4200, loss = 4.86588
I0524 14:31:12.601931  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.00381 (* 1 = 5.00381 loss)
I0524 14:31:12.601940  9498 sgd_solver.cpp:138] Iteration 4200, lr = 0.0001
I0524 14:33:25.158717  9498 solver.cpp:243] Iteration 4300, loss = 5.06155
I0524 14:33:25.158882  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.60988 (* 1 = 4.60988 loss)
I0524 14:33:25.158890  9498 sgd_solver.cpp:138] Iteration 4300, lr = 0.0001
I0524 14:35:37.886471  9498 solver.cpp:243] Iteration 4400, loss = 5.46587
I0524 14:35:37.886574  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.11762 (* 1 = 5.11762 loss)
I0524 14:35:37.886582  9498 sgd_solver.cpp:138] Iteration 4400, lr = 0.0001
I0524 14:37:49.231830  9498 solver.cpp:433] Iteration 4500, Testing net (#0)
I0524 14:37:49.232004  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 14:38:53.249141  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.153077
I0524 14:38:54.487706  9498 solver.cpp:243] Iteration 4500, loss = 5.56431
I0524 14:38:54.487747  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.75326 (* 1 = 5.75326 loss)
I0524 14:38:54.487756  9498 sgd_solver.cpp:138] Iteration 4500, lr = 0.0001
I0524 14:41:07.356882  9498 solver.cpp:243] Iteration 4600, loss = 5.37361
I0524 14:41:07.357074  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.50769 (* 1 = 5.50769 loss)
I0524 14:41:07.357105  9498 sgd_solver.cpp:138] Iteration 4600, lr = 0.0001
I0524 14:43:20.130599  9498 solver.cpp:243] Iteration 4700, loss = 4.86303
I0524 14:43:20.130751  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.54314 (* 1 = 4.54314 loss)
I0524 14:43:20.130761  9498 sgd_solver.cpp:138] Iteration 4700, lr = 0.0001
I0524 14:45:32.820122  9498 solver.cpp:243] Iteration 4800, loss = 5.15066
I0524 14:45:32.820281  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.43406 (* 1 = 4.43406 loss)
I0524 14:45:32.820288  9498 sgd_solver.cpp:138] Iteration 4800, lr = 0.0001
I0524 14:47:45.652515  9498 solver.cpp:243] Iteration 4900, loss = 5.24096
I0524 14:47:45.652678  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.49396 (* 1 = 4.49396 loss)
I0524 14:47:45.652688  9498 sgd_solver.cpp:138] Iteration 4900, lr = 0.0001
I0524 14:49:57.154289  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_5000.caffemodel
I0524 14:49:57.253772  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_5000.solverstate
I0524 14:49:57.290920  9498 solver.cpp:433] Iteration 5000, Testing net (#0)
I0524 14:49:57.291028  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 14:51:01.309525  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.152578
I0524 14:51:02.551463  9498 solver.cpp:243] Iteration 5000, loss = 5.56774
I0524 14:51:02.551496  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.2774 (* 1 = 5.2774 loss)
I0524 14:51:02.551504  9498 sgd_solver.cpp:138] Iteration 5000, lr = 0.0001
I0524 14:53:15.156996  9498 solver.cpp:243] Iteration 5100, loss = 5.54535
I0524 14:53:15.157140  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.44638 (* 1 = 5.44638 loss)
I0524 14:53:15.157147  9498 sgd_solver.cpp:138] Iteration 5100, lr = 0.0001
I0524 14:55:27.887885  9498 solver.cpp:243] Iteration 5200, loss = 5.22216
I0524 14:55:27.888029  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.00496 (* 1 = 4.00496 loss)
I0524 14:55:27.888038  9498 sgd_solver.cpp:138] Iteration 5200, lr = 0.0001
I0524 14:57:40.661307  9498 solver.cpp:243] Iteration 5300, loss = 5.58451
I0524 14:57:40.661442  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.28355 (* 1 = 5.28355 loss)
I0524 14:57:40.661449  9498 sgd_solver.cpp:138] Iteration 5300, lr = 0.0001
I0524 14:59:53.518568  9498 solver.cpp:243] Iteration 5400, loss = 5.3748
I0524 14:59:53.518726  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.90597 (* 1 = 4.90597 loss)
I0524 14:59:53.518735  9498 sgd_solver.cpp:138] Iteration 5400, lr = 0.0001
I0524 15:02:04.972843  9498 solver.cpp:433] Iteration 5500, Testing net (#0)
I0524 15:02:04.973075  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 15:03:08.895105  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.163247
I0524 15:03:10.134977  9498 solver.cpp:243] Iteration 5500, loss = 5.07082
I0524 15:03:10.135011  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.46148 (* 1 = 4.46148 loss)
I0524 15:03:10.135020  9498 sgd_solver.cpp:138] Iteration 5500, lr = 0.0001
I0524 15:05:22.807202  9498 solver.cpp:243] Iteration 5600, loss = 5.15914
I0524 15:05:22.807325  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.29299 (* 1 = 5.29299 loss)
I0524 15:05:22.807334  9498 sgd_solver.cpp:138] Iteration 5600, lr = 0.0001
I0524 15:07:35.532845  9498 solver.cpp:243] Iteration 5700, loss = 5.55092
I0524 15:07:35.533032  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.297 (* 1 = 5.297 loss)
I0524 15:07:35.533043  9498 sgd_solver.cpp:138] Iteration 5700, lr = 0.0001
I0524 15:09:48.449118  9498 solver.cpp:243] Iteration 5800, loss = 5.35991
I0524 15:09:48.449270  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.00282 (* 1 = 5.00282 loss)
I0524 15:09:48.449295  9498 sgd_solver.cpp:138] Iteration 5800, lr = 0.0001
I0524 15:12:01.266541  9498 solver.cpp:243] Iteration 5900, loss = 5.45227
I0524 15:12:01.266696  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.29 (* 1 = 5.29 loss)
I0524 15:12:01.266705  9498 sgd_solver.cpp:138] Iteration 5900, lr = 0.0001
I0524 15:14:12.857497  9498 solver.cpp:433] Iteration 6000, Testing net (#0)
I0524 15:14:12.857718  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 15:15:16.878192  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.145653
I0524 15:15:18.114890  9498 solver.cpp:243] Iteration 6000, loss = 5.29371
I0524 15:15:18.114924  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.7603 (* 1 = 5.7603 loss)
I0524 15:15:18.114948  9498 sgd_solver.cpp:138] Iteration 6000, lr = 0.0001
I0524 15:17:30.823746  9498 solver.cpp:243] Iteration 6100, loss = 4.83637
I0524 15:17:30.823860  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.11459 (* 1 = 4.11459 loss)
I0524 15:17:30.823868  9498 sgd_solver.cpp:138] Iteration 6100, lr = 0.0001
I0524 15:19:43.501905  9498 solver.cpp:243] Iteration 6200, loss = 4.99105
I0524 15:19:43.502032  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.16662 (* 1 = 5.16662 loss)
I0524 15:19:43.502040  9498 sgd_solver.cpp:138] Iteration 6200, lr = 0.0001
I0524 15:21:56.341274  9498 solver.cpp:243] Iteration 6300, loss = 4.98967
I0524 15:21:56.341414  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.30274 (* 1 = 4.30274 loss)
I0524 15:21:56.341423  9498 sgd_solver.cpp:138] Iteration 6300, lr = 0.0001
I0524 15:24:09.184132  9498 solver.cpp:243] Iteration 6400, loss = 5.05181
I0524 15:24:09.184273  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.30096 (* 1 = 5.30096 loss)
I0524 15:24:09.184283  9498 sgd_solver.cpp:138] Iteration 6400, lr = 0.0001
I0524 15:26:20.612932  9498 solver.cpp:433] Iteration 6500, Testing net (#0)
I0524 15:26:20.613169  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 15:27:24.583062  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.186578
I0524 15:27:25.817746  9498 solver.cpp:243] Iteration 6500, loss = 5.24056
I0524 15:27:25.817781  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.87861 (* 1 = 5.87861 loss)
I0524 15:27:25.817788  9498 sgd_solver.cpp:138] Iteration 6500, lr = 0.0001
I0524 15:29:38.569509  9498 solver.cpp:243] Iteration 6600, loss = 5.02224
I0524 15:29:38.569650  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.53545 (* 1 = 5.53545 loss)
I0524 15:29:38.569658  9498 sgd_solver.cpp:138] Iteration 6600, lr = 0.0001
I0524 15:31:51.420310  9498 solver.cpp:243] Iteration 6700, loss = 5.18619
I0524 15:31:51.420428  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.61835 (* 1 = 5.61835 loss)
I0524 15:31:51.420437  9498 sgd_solver.cpp:138] Iteration 6700, lr = 0.0001
I0524 15:34:04.233919  9498 solver.cpp:243] Iteration 6800, loss = 4.83824
I0524 15:34:04.234051  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.23196 (* 1 = 5.23196 loss)
I0524 15:34:04.234059  9498 sgd_solver.cpp:138] Iteration 6800, lr = 0.0001
I0524 15:36:17.234767  9498 solver.cpp:243] Iteration 6900, loss = 5.31003
I0524 15:36:17.234936  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.83077 (* 1 = 4.83077 loss)
I0524 15:36:17.234946  9498 sgd_solver.cpp:138] Iteration 6900, lr = 0.0001
I0524 15:38:28.695713  9498 solver.cpp:433] Iteration 7000, Testing net (#0)
I0524 15:38:28.695941  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 15:39:32.706950  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.171618
I0524 15:39:33.947880  9498 solver.cpp:243] Iteration 7000, loss = 5.17859
I0524 15:39:33.947912  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.98482 (* 1 = 4.98482 loss)
I0524 15:39:33.947921  9498 sgd_solver.cpp:138] Iteration 7000, lr = 0.0001
I0524 15:41:46.764168  9498 solver.cpp:243] Iteration 7100, loss = 4.91449
I0524 15:41:46.764328  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.32397 (* 1 = 4.32397 loss)
I0524 15:41:46.764336  9498 sgd_solver.cpp:138] Iteration 7100, lr = 0.0001
I0524 15:43:59.559576  9498 solver.cpp:243] Iteration 7200, loss = 5.59603
I0524 15:43:59.559707  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.35609 (* 1 = 5.35609 loss)
I0524 15:43:59.559716  9498 sgd_solver.cpp:138] Iteration 7200, lr = 0.0001
I0524 15:46:12.236892  9498 solver.cpp:243] Iteration 7300, loss = 5.06539
I0524 15:46:12.237030  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.09042 (* 1 = 6.09042 loss)
I0524 15:46:12.237038  9498 sgd_solver.cpp:138] Iteration 7300, lr = 0.0001
I0524 15:48:25.011945  9498 solver.cpp:243] Iteration 7400, loss = 5.44782
I0524 15:48:25.012135  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.48838 (* 1 = 5.48838 loss)
I0524 15:48:25.012143  9498 sgd_solver.cpp:138] Iteration 7400, lr = 0.0001
I0524 15:50:36.603174  9498 solver.cpp:433] Iteration 7500, Testing net (#0)
I0524 15:50:36.603390  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 15:51:40.795166  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.162775
I0524 15:51:42.025287  9498 solver.cpp:243] Iteration 7500, loss = 5.22296
I0524 15:51:42.025324  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.1175 (* 1 = 5.1175 loss)
I0524 15:51:42.025331  9498 sgd_solver.cpp:138] Iteration 7500, lr = 0.0001
I0524 15:53:54.923344  9498 solver.cpp:243] Iteration 7600, loss = 5.03281
I0524 15:53:54.923456  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.17181 (* 1 = 6.17181 loss)
I0524 15:53:54.923466  9498 sgd_solver.cpp:138] Iteration 7600, lr = 0.0001
I0524 15:56:07.897812  9498 solver.cpp:243] Iteration 7700, loss = 5.32359
I0524 15:56:07.897955  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.23403 (* 1 = 5.23403 loss)
I0524 15:56:07.897965  9498 sgd_solver.cpp:138] Iteration 7700, lr = 0.0001
I0524 15:58:20.646801  9498 solver.cpp:243] Iteration 7800, loss = 5.59996
I0524 15:58:20.646956  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.19344 (* 1 = 5.19344 loss)
I0524 15:58:20.646965  9498 sgd_solver.cpp:138] Iteration 7800, lr = 0.0001
I0524 16:00:33.273015  9498 solver.cpp:243] Iteration 7900, loss = 4.9746
I0524 16:00:33.273160  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.07427 (* 1 = 5.07427 loss)
I0524 16:00:33.273169  9498 sgd_solver.cpp:138] Iteration 7900, lr = 0.0001
I0524 16:02:44.853885  9498 solver.cpp:433] Iteration 8000, Testing net (#0)
I0524 16:02:44.854106  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 16:03:48.908579  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.179714
I0524 16:03:50.137854  9498 solver.cpp:243] Iteration 8000, loss = 5.22133
I0524 16:03:50.137890  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.95548 (* 1 = 6.95548 loss)
I0524 16:03:50.137897  9498 sgd_solver.cpp:138] Iteration 8000, lr = 0.0001
I0524 16:06:02.783231  9498 solver.cpp:243] Iteration 8100, loss = 5.00149
I0524 16:06:02.783354  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.6505 (* 1 = 5.6505 loss)
I0524 16:06:02.783363  9498 sgd_solver.cpp:138] Iteration 8100, lr = 0.0001
I0524 16:08:15.685312  9498 solver.cpp:243] Iteration 8200, loss = 4.92261
I0524 16:08:15.685406  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.40166 (* 1 = 4.40166 loss)
I0524 16:08:15.685415  9498 sgd_solver.cpp:138] Iteration 8200, lr = 0.0001
I0524 16:10:28.434192  9498 solver.cpp:243] Iteration 8300, loss = 5.46041
I0524 16:10:28.434363  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.96655 (* 1 = 5.96655 loss)
I0524 16:10:28.434372  9498 sgd_solver.cpp:138] Iteration 8300, lr = 0.0001
I0524 16:12:41.107033  9498 solver.cpp:243] Iteration 8400, loss = 5.11688
I0524 16:12:41.107209  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.51556 (* 1 = 4.51556 loss)
I0524 16:12:41.107219  9498 sgd_solver.cpp:138] Iteration 8400, lr = 0.0001
I0524 16:14:52.623857  9498 solver.cpp:433] Iteration 8500, Testing net (#0)
I0524 16:14:52.624079  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 16:15:56.573922  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.170966
I0524 16:15:57.812148  9498 solver.cpp:243] Iteration 8500, loss = 4.75417
I0524 16:15:57.812182  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.25841 (* 1 = 5.25841 loss)
I0524 16:15:57.812189  9498 sgd_solver.cpp:138] Iteration 8500, lr = 0.0001
I0524 16:18:10.412457  9498 solver.cpp:243] Iteration 8600, loss = 5.26296
I0524 16:18:10.412562  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.69811 (* 1 = 5.69811 loss)
I0524 16:18:10.412570  9498 sgd_solver.cpp:138] Iteration 8600, lr = 0.0001
I0524 16:20:23.184821  9498 solver.cpp:243] Iteration 8700, loss = 5.01299
I0524 16:20:23.184969  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.38285 (* 1 = 3.38285 loss)
I0524 16:20:23.184978  9498 sgd_solver.cpp:138] Iteration 8700, lr = 0.0001
I0524 16:22:36.059476  9498 solver.cpp:243] Iteration 8800, loss = 5.29845
I0524 16:22:36.059626  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.63969 (* 1 = 5.63969 loss)
I0524 16:22:36.059634  9498 sgd_solver.cpp:138] Iteration 8800, lr = 0.0001
I0524 16:24:48.843885  9498 solver.cpp:243] Iteration 8900, loss = 5.30572
I0524 16:24:48.844048  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.63544 (* 1 = 5.63544 loss)
I0524 16:24:48.844055  9498 sgd_solver.cpp:138] Iteration 8900, lr = 0.0001
I0524 16:27:00.304319  9498 solver.cpp:433] Iteration 9000, Testing net (#0)
I0524 16:27:00.304543  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 16:28:04.348881  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.171888
I0524 16:28:05.581050  9498 solver.cpp:243] Iteration 9000, loss = 5.14328
I0524 16:28:05.581086  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.80026 (* 1 = 4.80026 loss)
I0524 16:28:05.581094  9498 sgd_solver.cpp:138] Iteration 9000, lr = 0.0001
I0524 16:30:18.437398  9498 solver.cpp:243] Iteration 9100, loss = 5.41079
I0524 16:30:18.437537  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.39639 (* 1 = 5.39639 loss)
I0524 16:30:18.437561  9498 sgd_solver.cpp:138] Iteration 9100, lr = 0.0001
I0524 16:32:31.003785  9498 solver.cpp:243] Iteration 9200, loss = 4.82742
I0524 16:32:31.003921  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.63239 (* 1 = 4.63239 loss)
I0524 16:32:31.003928  9498 sgd_solver.cpp:138] Iteration 9200, lr = 0.0001
I0524 16:34:43.877161  9498 solver.cpp:243] Iteration 9300, loss = 4.88911
I0524 16:34:43.877256  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.17464 (* 1 = 5.17464 loss)
I0524 16:34:43.877264  9498 sgd_solver.cpp:138] Iteration 9300, lr = 0.0001
I0524 16:36:56.497957  9498 solver.cpp:243] Iteration 9400, loss = 5.18335
I0524 16:36:56.498095  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.58177 (* 1 = 5.58177 loss)
I0524 16:36:56.498104  9498 sgd_solver.cpp:138] Iteration 9400, lr = 0.0001
I0524 16:39:08.060583  9498 solver.cpp:433] Iteration 9500, Testing net (#0)
I0524 16:39:08.060806  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 16:40:12.071058  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.204943
I0524 16:40:13.311269  9498 solver.cpp:243] Iteration 9500, loss = 5.12902
I0524 16:40:13.311302  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.67653 (* 1 = 4.67653 loss)
I0524 16:40:13.311309  9498 sgd_solver.cpp:138] Iteration 9500, lr = 0.0001
I0524 16:42:26.224017  9498 solver.cpp:243] Iteration 9600, loss = 5.20658
I0524 16:42:26.224148  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.84449 (* 1 = 4.84449 loss)
I0524 16:42:26.224156  9498 sgd_solver.cpp:138] Iteration 9600, lr = 0.0001
I0524 16:44:38.885362  9498 solver.cpp:243] Iteration 9700, loss = 5.35933
I0524 16:44:38.885535  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.62066 (* 1 = 5.62066 loss)
I0524 16:44:38.885545  9498 sgd_solver.cpp:138] Iteration 9700, lr = 0.0001
I0524 16:46:51.673393  9498 solver.cpp:243] Iteration 9800, loss = 5.19479
I0524 16:46:51.673493  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.58108 (* 1 = 5.58108 loss)
I0524 16:46:51.673501  9498 sgd_solver.cpp:138] Iteration 9800, lr = 0.0001
I0524 16:49:04.483533  9498 solver.cpp:243] Iteration 9900, loss = 4.89651
I0524 16:49:04.483690  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.35718 (* 1 = 4.35718 loss)
I0524 16:49:04.483698  9498 sgd_solver.cpp:138] Iteration 9900, lr = 0.0001
I0524 16:51:16.052755  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_10000.caffemodel
I0524 16:51:16.114028  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_10000.solverstate
I0524 16:51:16.146225  9498 solver.cpp:433] Iteration 10000, Testing net (#0)
I0524 16:51:16.146330  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 16:52:20.155115  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.179886
I0524 16:52:21.402022  9498 solver.cpp:243] Iteration 10000, loss = 5.18443
I0524 16:52:21.402057  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.44629 (* 1 = 5.44629 loss)
I0524 16:52:21.402063  9498 sgd_solver.cpp:138] Iteration 10000, lr = 0.0001
I0524 16:54:34.283579  9498 solver.cpp:243] Iteration 10100, loss = 5.11611
I0524 16:54:34.283677  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.39617 (* 1 = 5.39617 loss)
I0524 16:54:34.283685  9498 sgd_solver.cpp:138] Iteration 10100, lr = 0.0001
I0524 16:56:46.926311  9498 solver.cpp:243] Iteration 10200, loss = 5.05944
I0524 16:56:46.926455  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.05528 (* 1 = 4.05528 loss)
I0524 16:56:46.926465  9498 sgd_solver.cpp:138] Iteration 10200, lr = 0.0001
I0524 16:58:59.794128  9498 solver.cpp:243] Iteration 10300, loss = 4.90053
I0524 16:58:59.794281  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.56309 (* 1 = 5.56309 loss)
I0524 16:58:59.794288  9498 sgd_solver.cpp:138] Iteration 10300, lr = 0.0001
I0524 17:01:12.522872  9498 solver.cpp:243] Iteration 10400, loss = 4.46385
I0524 17:01:12.523011  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.62303 (* 1 = 4.62303 loss)
I0524 17:01:12.523020  9498 sgd_solver.cpp:138] Iteration 10400, lr = 0.0001
I0524 17:03:24.106846  9498 solver.cpp:433] Iteration 10500, Testing net (#0)
I0524 17:03:24.107059  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 17:04:28.073180  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.200858
I0524 17:04:29.335484  9498 solver.cpp:243] Iteration 10500, loss = 5.24886
I0524 17:04:29.335517  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.55044 (* 1 = 5.55044 loss)
I0524 17:04:29.335525  9498 sgd_solver.cpp:138] Iteration 10500, lr = 0.0001
I0524 17:06:42.040459  9498 solver.cpp:243] Iteration 10600, loss = 4.97409
I0524 17:06:42.040602  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.78917 (* 1 = 5.78917 loss)
I0524 17:06:42.040611  9498 sgd_solver.cpp:138] Iteration 10600, lr = 0.0001
I0524 17:08:54.762284  9498 solver.cpp:243] Iteration 10700, loss = 5.07293
I0524 17:08:54.762410  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.26959 (* 1 = 5.26959 loss)
I0524 17:08:54.762419  9498 sgd_solver.cpp:138] Iteration 10700, lr = 0.0001
I0524 17:11:07.610776  9498 solver.cpp:243] Iteration 10800, loss = 4.89888
I0524 17:11:07.610924  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.25619 (* 1 = 5.25619 loss)
I0524 17:11:07.610932  9498 sgd_solver.cpp:138] Iteration 10800, lr = 0.0001
I0524 17:13:20.301826  9498 solver.cpp:243] Iteration 10900, loss = 5.24728
I0524 17:13:20.301926  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.65268 (* 1 = 5.65268 loss)
I0524 17:13:20.301934  9498 sgd_solver.cpp:138] Iteration 10900, lr = 0.0001
I0524 17:15:31.636510  9498 solver.cpp:433] Iteration 11000, Testing net (#0)
I0524 17:15:31.636723  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 17:16:35.612553  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.213417
I0524 17:16:36.850018  9498 solver.cpp:243] Iteration 11000, loss = 5.36465
I0524 17:16:36.850054  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.27405 (* 1 = 4.27405 loss)
I0524 17:16:36.850059  9498 sgd_solver.cpp:138] Iteration 11000, lr = 0.0001
I0524 17:18:49.833088  9498 solver.cpp:243] Iteration 11100, loss = 5.05514
I0524 17:18:49.833631  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.42844 (* 1 = 5.42844 loss)
I0524 17:18:49.833638  9498 sgd_solver.cpp:138] Iteration 11100, lr = 0.0001
I0524 17:21:02.713743  9498 solver.cpp:243] Iteration 11200, loss = 5.15728
I0524 17:21:02.713894  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.30557 (* 1 = 5.30557 loss)
I0524 17:21:02.713903  9498 sgd_solver.cpp:138] Iteration 11200, lr = 0.0001
I0524 17:23:15.378234  9498 solver.cpp:243] Iteration 11300, loss = 4.85616
I0524 17:23:15.378367  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.917 (* 1 = 4.917 loss)
I0524 17:23:15.378376  9498 sgd_solver.cpp:138] Iteration 11300, lr = 0.0001
I0524 17:25:28.284554  9498 solver.cpp:243] Iteration 11400, loss = 5.24462
I0524 17:25:28.284682  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.00417 (* 1 = 5.00417 loss)
I0524 17:25:28.284689  9498 sgd_solver.cpp:138] Iteration 11400, lr = 0.0001
I0524 17:27:39.998980  9498 solver.cpp:433] Iteration 11500, Testing net (#0)
I0524 17:27:39.999214  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 17:28:43.933055  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.21177
I0524 17:28:45.165032  9498 solver.cpp:243] Iteration 11500, loss = 5.06473
I0524 17:28:45.165066  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.81377 (* 1 = 5.81377 loss)
I0524 17:28:45.165088  9498 sgd_solver.cpp:138] Iteration 11500, lr = 0.0001
I0524 17:30:57.903082  9498 solver.cpp:243] Iteration 11600, loss = 5.17463
I0524 17:30:57.903249  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.82562 (* 1 = 5.82562 loss)
I0524 17:30:57.903259  9498 sgd_solver.cpp:138] Iteration 11600, lr = 0.0001
I0524 17:33:10.826401  9498 solver.cpp:243] Iteration 11700, loss = 5.152
I0524 17:33:10.826548  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.26338 (* 1 = 5.26338 loss)
I0524 17:33:10.826556  9498 sgd_solver.cpp:138] Iteration 11700, lr = 0.0001
I0524 17:35:23.599143  9498 solver.cpp:243] Iteration 11800, loss = 5.16915
I0524 17:35:23.599268  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.72569 (* 1 = 5.72569 loss)
I0524 17:35:23.599277  9498 sgd_solver.cpp:138] Iteration 11800, lr = 0.0001
I0524 17:37:36.261559  9498 solver.cpp:243] Iteration 11900, loss = 4.97409
I0524 17:37:36.261703  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.27476 (* 1 = 5.27476 loss)
I0524 17:37:36.261711  9498 sgd_solver.cpp:138] Iteration 11900, lr = 0.0001
I0524 17:39:47.654060  9498 solver.cpp:433] Iteration 12000, Testing net (#0)
I0524 17:39:47.654292  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 17:40:51.522467  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.205503
I0524 17:40:52.763144  9498 solver.cpp:243] Iteration 12000, loss = 4.67721
I0524 17:40:52.763181  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.6911 (* 1 = 4.6911 loss)
I0524 17:40:52.763190  9498 sgd_solver.cpp:138] Iteration 12000, lr = 0.0001
I0524 17:43:05.435545  9498 solver.cpp:243] Iteration 12100, loss = 5.08585
I0524 17:43:05.435660  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.35387 (* 1 = 5.35387 loss)
I0524 17:43:05.435685  9498 sgd_solver.cpp:138] Iteration 12100, lr = 0.0001
I0524 17:45:17.968879  9498 solver.cpp:243] Iteration 12200, loss = 5.23822
I0524 17:45:17.969013  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.42774 (* 1 = 4.42774 loss)
I0524 17:45:17.969022  9498 sgd_solver.cpp:138] Iteration 12200, lr = 0.0001
I0524 17:47:30.713207  9498 solver.cpp:243] Iteration 12300, loss = 4.92493
I0524 17:47:30.713340  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.42053 (* 1 = 5.42053 loss)
I0524 17:47:30.713348  9498 sgd_solver.cpp:138] Iteration 12300, lr = 0.0001
I0524 17:49:43.552759  9498 solver.cpp:243] Iteration 12400, loss = 4.75728
I0524 17:49:43.552883  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.41548 (* 1 = 4.41548 loss)
I0524 17:49:43.552891  9498 sgd_solver.cpp:138] Iteration 12400, lr = 0.0001
I0524 17:51:55.146319  9498 solver.cpp:433] Iteration 12500, Testing net (#0)
I0524 17:51:55.146531  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 17:52:59.100292  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.202193
I0524 17:53:00.341806  9498 solver.cpp:243] Iteration 12500, loss = 4.77942
I0524 17:53:00.341838  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.37859 (* 1 = 4.37859 loss)
I0524 17:53:00.341861  9498 sgd_solver.cpp:138] Iteration 12500, lr = 0.0001
I0524 17:55:12.881000  9498 solver.cpp:243] Iteration 12600, loss = 4.90455
I0524 17:55:12.881109  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.66443 (* 1 = 5.66443 loss)
I0524 17:55:12.881119  9498 sgd_solver.cpp:138] Iteration 12600, lr = 0.0001
I0524 17:57:25.701009  9498 solver.cpp:243] Iteration 12700, loss = 4.88562
I0524 17:57:25.701166  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.09265 (* 1 = 5.09265 loss)
I0524 17:57:25.701174  9498 sgd_solver.cpp:138] Iteration 12700, lr = 0.0001
I0524 17:59:38.444862  9498 solver.cpp:243] Iteration 12800, loss = 5.42572
I0524 17:59:38.445001  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.43311 (* 1 = 5.43311 loss)
I0524 17:59:38.445009  9498 sgd_solver.cpp:138] Iteration 12800, lr = 0.0001
I0524 18:01:51.185035  9498 solver.cpp:243] Iteration 12900, loss = 5.05264
I0524 18:01:51.185197  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.09386 (* 1 = 4.09386 loss)
I0524 18:01:51.185207  9498 sgd_solver.cpp:138] Iteration 12900, lr = 0.0001
I0524 18:04:02.625993  9498 solver.cpp:433] Iteration 13000, Testing net (#0)
I0524 18:04:02.626225  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 18:05:06.562664  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.214347
I0524 18:05:07.802069  9498 solver.cpp:243] Iteration 13000, loss = 4.98562
I0524 18:05:07.802105  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.46257 (* 1 = 5.46257 loss)
I0524 18:05:07.802112  9498 sgd_solver.cpp:138] Iteration 13000, lr = 0.0001
I0524 18:07:20.457398  9498 solver.cpp:243] Iteration 13100, loss = 5.08104
I0524 18:07:20.457530  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.70633 (* 1 = 4.70633 loss)
I0524 18:07:20.457538  9498 sgd_solver.cpp:138] Iteration 13100, lr = 0.0001
I0524 18:09:33.104733  9498 solver.cpp:243] Iteration 13200, loss = 4.86021
I0524 18:09:33.104832  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.44985 (* 1 = 5.44985 loss)
I0524 18:09:33.104841  9498 sgd_solver.cpp:138] Iteration 13200, lr = 0.0001
I0524 18:11:45.770537  9498 solver.cpp:243] Iteration 13300, loss = 4.8759
I0524 18:11:45.770634  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.48851 (* 1 = 5.48851 loss)
I0524 18:11:45.770643  9498 sgd_solver.cpp:138] Iteration 13300, lr = 0.0001
I0524 18:13:58.736654  9498 solver.cpp:243] Iteration 13400, loss = 4.82572
I0524 18:13:58.736791  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.22754 (* 1 = 4.22754 loss)
I0524 18:13:58.736799  9498 sgd_solver.cpp:138] Iteration 13400, lr = 0.0001
I0524 18:16:10.284236  9498 solver.cpp:433] Iteration 13500, Testing net (#0)
I0524 18:16:10.284446  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 18:17:14.179087  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.214978
I0524 18:17:15.417224  9498 solver.cpp:243] Iteration 13500, loss = 5.05339
I0524 18:17:15.417261  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.82724 (* 1 = 5.82724 loss)
I0524 18:17:15.417269  9498 sgd_solver.cpp:138] Iteration 13500, lr = 0.0001
I0524 18:19:28.167614  9498 solver.cpp:243] Iteration 13600, loss = 4.82876
I0524 18:19:28.167794  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.63293 (* 1 = 4.63293 loss)
I0524 18:19:28.167804  9498 sgd_solver.cpp:138] Iteration 13600, lr = 0.0001
I0524 18:21:40.884157  9498 solver.cpp:243] Iteration 13700, loss = 5.09554
I0524 18:21:40.884294  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.20261 (* 1 = 5.20261 loss)
I0524 18:21:40.884305  9498 sgd_solver.cpp:138] Iteration 13700, lr = 0.0001
I0524 18:23:53.717305  9498 solver.cpp:243] Iteration 13800, loss = 4.96268
I0524 18:23:53.717541  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.72312 (* 1 = 5.72312 loss)
I0524 18:23:53.717550  9498 sgd_solver.cpp:138] Iteration 13800, lr = 0.0001
I0524 18:26:06.516199  9498 solver.cpp:243] Iteration 13900, loss = 4.65115
I0524 18:26:06.516342  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.25967 (* 1 = 5.25967 loss)
I0524 18:26:06.516350  9498 sgd_solver.cpp:138] Iteration 13900, lr = 0.0001
I0524 18:28:18.027385  9498 solver.cpp:433] Iteration 14000, Testing net (#0)
I0524 18:28:18.027585  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 18:29:21.929409  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.227048
I0524 18:29:23.168042  9498 solver.cpp:243] Iteration 14000, loss = 4.80626
I0524 18:29:23.168079  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.21912 (* 1 = 5.21912 loss)
I0524 18:29:23.168087  9498 sgd_solver.cpp:138] Iteration 14000, lr = 0.0001
I0524 18:31:35.928788  9498 solver.cpp:243] Iteration 14100, loss = 5.03589
I0524 18:31:35.928934  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.05751 (* 1 = 5.05751 loss)
I0524 18:31:35.928942  9498 sgd_solver.cpp:138] Iteration 14100, lr = 0.0001
I0524 18:33:48.685437  9498 solver.cpp:243] Iteration 14200, loss = 4.92333
I0524 18:33:48.685581  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.57819 (* 1 = 3.57819 loss)
I0524 18:33:48.685591  9498 sgd_solver.cpp:138] Iteration 14200, lr = 0.0001
I0524 18:36:01.382889  9498 solver.cpp:243] Iteration 14300, loss = 4.8957
I0524 18:36:01.383008  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.24937 (* 1 = 4.24937 loss)
I0524 18:36:01.383016  9498 sgd_solver.cpp:138] Iteration 14300, lr = 0.0001
I0524 18:38:14.377140  9498 solver.cpp:243] Iteration 14400, loss = 4.92165
I0524 18:38:14.377240  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.97654 (* 1 = 4.97654 loss)
I0524 18:38:14.377249  9498 sgd_solver.cpp:138] Iteration 14400, lr = 0.0001
I0524 18:40:25.860114  9498 solver.cpp:433] Iteration 14500, Testing net (#0)
I0524 18:40:25.860329  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 18:41:29.811646  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.232184
I0524 18:41:31.051283  9498 solver.cpp:243] Iteration 14500, loss = 4.7291
I0524 18:41:31.051318  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.70467 (* 1 = 4.70467 loss)
I0524 18:41:31.051326  9498 sgd_solver.cpp:138] Iteration 14500, lr = 0.0001
I0524 18:43:43.800552  9498 solver.cpp:243] Iteration 14600, loss = 5.26125
I0524 18:43:43.800701  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.0189 (* 1 = 5.0189 loss)
I0524 18:43:43.800709  9498 sgd_solver.cpp:138] Iteration 14600, lr = 0.0001
I0524 18:45:56.530750  9498 solver.cpp:243] Iteration 14700, loss = 5.13488
I0524 18:45:56.530910  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.09176 (* 1 = 5.09176 loss)
I0524 18:45:56.530918  9498 sgd_solver.cpp:138] Iteration 14700, lr = 0.0001
I0524 18:48:09.184659  9498 solver.cpp:243] Iteration 14800, loss = 5.04028
I0524 18:48:09.184792  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.29969 (* 1 = 4.29969 loss)
I0524 18:48:09.184800  9498 sgd_solver.cpp:138] Iteration 14800, lr = 0.0001
I0524 18:50:21.907374  9498 solver.cpp:243] Iteration 14900, loss = 4.5936
I0524 18:50:21.907541  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.62909 (* 1 = 4.62909 loss)
I0524 18:50:21.907552  9498 sgd_solver.cpp:138] Iteration 14900, lr = 0.0001
I0524 18:52:33.344102  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_15000.caffemodel
I0524 18:52:33.404116  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_15000.solverstate
I0524 18:52:33.435920  9498 solver.cpp:433] Iteration 15000, Testing net (#0)
I0524 18:52:33.436026  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 18:53:37.371141  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.242172
I0524 18:53:38.599107  9498 solver.cpp:243] Iteration 15000, loss = 5.15738
I0524 18:53:38.599146  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.02089 (* 1 = 5.02089 loss)
I0524 18:53:38.599153  9498 sgd_solver.cpp:138] Iteration 15000, lr = 0.0001
I0524 18:55:51.406082  9498 solver.cpp:243] Iteration 15100, loss = 4.80423
I0524 18:55:51.406217  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.09113 (* 1 = 4.09113 loss)
I0524 18:55:51.406224  9498 sgd_solver.cpp:138] Iteration 15100, lr = 0.0001
I0524 18:58:03.975291  9498 solver.cpp:243] Iteration 15200, loss = 4.85705
I0524 18:58:03.975446  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.84806 (* 1 = 4.84806 loss)
I0524 18:58:03.975456  9498 sgd_solver.cpp:138] Iteration 15200, lr = 0.0001
I0524 19:00:16.674232  9498 solver.cpp:243] Iteration 15300, loss = 5.34676
I0524 19:00:16.674332  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.61711 (* 1 = 4.61711 loss)
I0524 19:00:16.674340  9498 sgd_solver.cpp:138] Iteration 15300, lr = 0.0001
I0524 19:02:29.276415  9498 solver.cpp:243] Iteration 15400, loss = 4.83287
I0524 19:02:29.276549  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.99678 (* 1 = 4.99678 loss)
I0524 19:02:29.276558  9498 sgd_solver.cpp:138] Iteration 15400, lr = 0.0001
I0524 19:04:40.691675  9498 solver.cpp:433] Iteration 15500, Testing net (#0)
I0524 19:04:40.691839  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 19:05:44.659482  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.236737
I0524 19:05:45.896739  9498 solver.cpp:243] Iteration 15500, loss = 4.89461
I0524 19:05:45.896771  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.036 (* 1 = 5.036 loss)
I0524 19:05:45.896793  9498 sgd_solver.cpp:138] Iteration 15500, lr = 0.0001
I0524 19:07:58.618929  9498 solver.cpp:243] Iteration 15600, loss = 5.12621
I0524 19:07:58.619082  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.19593 (* 1 = 4.19593 loss)
I0524 19:07:58.619091  9498 sgd_solver.cpp:138] Iteration 15600, lr = 0.0001
I0524 19:10:11.290717  9498 solver.cpp:243] Iteration 15700, loss = 4.97167
I0524 19:10:11.290853  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.83648 (* 1 = 4.83648 loss)
I0524 19:10:11.290861  9498 sgd_solver.cpp:138] Iteration 15700, lr = 0.0001
I0524 19:12:24.116595  9498 solver.cpp:243] Iteration 15800, loss = 4.71003
I0524 19:12:24.116748  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.21191 (* 1 = 5.21191 loss)
I0524 19:12:24.116756  9498 sgd_solver.cpp:138] Iteration 15800, lr = 0.0001
I0524 19:14:36.750859  9498 solver.cpp:243] Iteration 15900, loss = 4.83642
I0524 19:14:36.751006  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.9349 (* 1 = 4.9349 loss)
I0524 19:14:36.751014  9498 sgd_solver.cpp:138] Iteration 15900, lr = 0.0001
I0524 19:16:48.360605  9498 solver.cpp:433] Iteration 16000, Testing net (#0)
I0524 19:16:48.360827  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 19:17:52.275374  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.220568
I0524 19:17:53.512626  9498 solver.cpp:243] Iteration 16000, loss = 4.47351
I0524 19:17:53.512660  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.25017 (* 1 = 4.25017 loss)
I0524 19:17:53.512666  9498 sgd_solver.cpp:138] Iteration 16000, lr = 0.0001
I0524 19:20:06.335539  9498 solver.cpp:243] Iteration 16100, loss = 4.70482
I0524 19:20:06.335702  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.06836 (* 1 = 4.06836 loss)
I0524 19:20:06.335711  9498 sgd_solver.cpp:138] Iteration 16100, lr = 0.0001
I0524 19:22:19.125566  9498 solver.cpp:243] Iteration 16200, loss = 4.95608
I0524 19:22:19.125692  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.29129 (* 1 = 5.29129 loss)
I0524 19:22:19.125701  9498 sgd_solver.cpp:138] Iteration 16200, lr = 0.0001
I0524 19:24:31.837458  9498 solver.cpp:243] Iteration 16300, loss = 4.74056
I0524 19:24:31.837610  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.59886 (* 1 = 4.59886 loss)
I0524 19:24:31.837620  9498 sgd_solver.cpp:138] Iteration 16300, lr = 0.0001
I0524 19:26:44.631297  9498 solver.cpp:243] Iteration 16400, loss = 5.00935
I0524 19:26:44.631445  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.307 (* 1 = 4.307 loss)
I0524 19:26:44.631455  9498 sgd_solver.cpp:138] Iteration 16400, lr = 0.0001
I0524 19:28:56.334571  9498 solver.cpp:433] Iteration 16500, Testing net (#0)
I0524 19:28:56.334771  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 19:30:00.307150  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.24636
I0524 19:30:01.546867  9498 solver.cpp:243] Iteration 16500, loss = 4.54886
I0524 19:30:01.546901  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.69382 (* 1 = 3.69382 loss)
I0524 19:30:01.546908  9498 sgd_solver.cpp:138] Iteration 16500, lr = 0.0001
I0524 19:32:14.491748  9498 solver.cpp:243] Iteration 16600, loss = 5.20073
I0524 19:32:14.491899  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.48848 (* 1 = 5.48848 loss)
I0524 19:32:14.491907  9498 sgd_solver.cpp:138] Iteration 16600, lr = 0.0001
I0524 19:34:27.293731  9498 solver.cpp:243] Iteration 16700, loss = 4.71797
I0524 19:34:27.293867  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.9785 (* 1 = 4.9785 loss)
I0524 19:34:27.293877  9498 sgd_solver.cpp:138] Iteration 16700, lr = 0.0001
I0524 19:36:40.031687  9498 solver.cpp:243] Iteration 16800, loss = 4.824
I0524 19:36:40.031810  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.47628 (* 1 = 4.47628 loss)
I0524 19:36:40.031817  9498 sgd_solver.cpp:138] Iteration 16800, lr = 0.0001
I0524 19:38:52.789841  9498 solver.cpp:243] Iteration 16900, loss = 5.01387
I0524 19:38:52.789986  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.20821 (* 1 = 5.20821 loss)
I0524 19:38:52.789995  9498 sgd_solver.cpp:138] Iteration 16900, lr = 0.0001
I0524 19:41:04.278025  9498 solver.cpp:433] Iteration 17000, Testing net (#0)
I0524 19:41:04.278264  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 19:42:08.206701  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.222341
I0524 19:42:09.444572  9498 solver.cpp:243] Iteration 17000, loss = 4.83104
I0524 19:42:09.444605  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.53058 (* 1 = 4.53058 loss)
I0524 19:42:09.444629  9498 sgd_solver.cpp:138] Iteration 17000, lr = 0.0001
I0524 19:44:22.260538  9498 solver.cpp:243] Iteration 17100, loss = 4.94783
I0524 19:44:22.260689  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.20005 (* 1 = 5.20005 loss)
I0524 19:44:22.260712  9498 sgd_solver.cpp:138] Iteration 17100, lr = 0.0001
I0524 19:46:35.017940  9498 solver.cpp:243] Iteration 17200, loss = 5.18963
I0524 19:46:35.018040  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.99534 (* 1 = 4.99534 loss)
I0524 19:46:35.018049  9498 sgd_solver.cpp:138] Iteration 17200, lr = 0.0001
I0524 19:48:47.723352  9498 solver.cpp:243] Iteration 17300, loss = 4.73668
I0524 19:48:47.723495  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.41577 (* 1 = 3.41577 loss)
I0524 19:48:47.723503  9498 sgd_solver.cpp:138] Iteration 17300, lr = 0.0001
I0524 19:51:00.509974  9498 solver.cpp:243] Iteration 17400, loss = 4.65576
I0524 19:51:00.510099  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.672 (* 1 = 5.672 loss)
I0524 19:51:00.510108  9498 sgd_solver.cpp:138] Iteration 17400, lr = 0.0001
I0524 19:53:12.079739  9498 solver.cpp:433] Iteration 17500, Testing net (#0)
I0524 19:53:12.079993  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 19:54:15.990835  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.254173
I0524 19:54:17.224195  9498 solver.cpp:243] Iteration 17500, loss = 5.0159
I0524 19:54:17.224228  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.19941 (* 1 = 5.19941 loss)
I0524 19:54:17.224234  9498 sgd_solver.cpp:138] Iteration 17500, lr = 0.0001
I0524 19:56:30.022061  9498 solver.cpp:243] Iteration 17600, loss = 5.07939
I0524 19:56:30.022195  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.73542 (* 1 = 5.73542 loss)
I0524 19:56:30.022202  9498 sgd_solver.cpp:138] Iteration 17600, lr = 0.0001
I0524 19:58:42.760452  9498 solver.cpp:243] Iteration 17700, loss = 4.88067
I0524 19:58:42.760601  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.4763 (* 1 = 6.4763 loss)
I0524 19:58:42.760613  9498 sgd_solver.cpp:138] Iteration 17700, lr = 0.0001
I0524 20:00:55.484753  9498 solver.cpp:243] Iteration 17800, loss = 4.66402
I0524 20:00:55.484866  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.58505 (* 1 = 4.58505 loss)
I0524 20:00:55.484875  9498 sgd_solver.cpp:138] Iteration 17800, lr = 0.0001
I0524 20:03:08.355655  9498 solver.cpp:243] Iteration 17900, loss = 4.55461
I0524 20:03:08.355813  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.00903 (* 1 = 4.00903 loss)
I0524 20:03:08.355820  9498 sgd_solver.cpp:138] Iteration 17900, lr = 0.0001
I0524 20:05:19.848495  9498 solver.cpp:433] Iteration 18000, Testing net (#0)
I0524 20:05:19.848695  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 20:06:23.711174  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.232376
I0524 20:06:24.947556  9498 solver.cpp:243] Iteration 18000, loss = 4.8479
I0524 20:06:24.947592  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.21375 (* 1 = 4.21375 loss)
I0524 20:06:24.947600  9498 sgd_solver.cpp:138] Iteration 18000, lr = 0.0001
I0524 20:08:37.581135  9498 solver.cpp:243] Iteration 18100, loss = 5.05079
I0524 20:08:37.581292  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.17559 (* 1 = 4.17559 loss)
I0524 20:08:37.581301  9498 sgd_solver.cpp:138] Iteration 18100, lr = 0.0001
I0524 20:10:50.247262  9498 solver.cpp:243] Iteration 18200, loss = 4.62168
I0524 20:10:50.247417  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.1548 (* 1 = 4.1548 loss)
I0524 20:10:50.247426  9498 sgd_solver.cpp:138] Iteration 18200, lr = 0.0001
I0524 20:13:03.081867  9498 solver.cpp:243] Iteration 18300, loss = 4.82647
I0524 20:13:03.082002  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.34443 (* 1 = 5.34443 loss)
I0524 20:13:03.082010  9498 sgd_solver.cpp:138] Iteration 18300, lr = 0.0001
I0524 20:15:15.786978  9498 solver.cpp:243] Iteration 18400, loss = 4.84254
I0524 20:15:15.787127  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.03904 (* 1 = 4.03904 loss)
I0524 20:15:15.787137  9498 sgd_solver.cpp:138] Iteration 18400, lr = 0.0001
I0524 20:17:27.217550  9498 solver.cpp:433] Iteration 18500, Testing net (#0)
I0524 20:17:27.217756  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 20:18:31.064956  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.265139
I0524 20:18:32.301168  9498 solver.cpp:243] Iteration 18500, loss = 5.02675
I0524 20:18:32.301203  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.55143 (* 1 = 5.55143 loss)
I0524 20:18:32.301210  9498 sgd_solver.cpp:138] Iteration 18500, lr = 0.0001
I0524 20:20:45.035665  9498 solver.cpp:243] Iteration 18600, loss = 5.02064
I0524 20:20:45.035817  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.40164 (* 1 = 4.40164 loss)
I0524 20:20:45.035826  9498 sgd_solver.cpp:138] Iteration 18600, lr = 0.0001
I0524 20:22:57.789557  9498 solver.cpp:243] Iteration 18700, loss = 4.7564
I0524 20:22:57.789700  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.70008 (* 1 = 3.70008 loss)
I0524 20:22:57.789710  9498 sgd_solver.cpp:138] Iteration 18700, lr = 0.0001
I0524 20:25:10.453056  9498 solver.cpp:243] Iteration 18800, loss = 5.1269
I0524 20:25:10.453217  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.17989 (* 1 = 4.17989 loss)
I0524 20:25:10.453224  9498 sgd_solver.cpp:138] Iteration 18800, lr = 0.0001
I0524 20:27:23.405202  9498 solver.cpp:243] Iteration 18900, loss = 4.83808
I0524 20:27:23.405347  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.70181 (* 1 = 4.70181 loss)
I0524 20:27:23.405355  9498 sgd_solver.cpp:138] Iteration 18900, lr = 0.0001
I0524 20:29:34.935729  9498 solver.cpp:433] Iteration 19000, Testing net (#0)
I0524 20:29:34.935945  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 20:30:38.748201  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.257106
I0524 20:30:39.984841  9498 solver.cpp:243] Iteration 19000, loss = 5.11148
I0524 20:30:39.984874  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.51688 (* 1 = 4.51688 loss)
I0524 20:30:39.984897  9498 sgd_solver.cpp:138] Iteration 19000, lr = 0.0001
I0524 20:32:52.706537  9498 solver.cpp:243] Iteration 19100, loss = 4.65039
I0524 20:32:52.706677  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.75247 (* 1 = 4.75247 loss)
I0524 20:32:52.706686  9498 sgd_solver.cpp:138] Iteration 19100, lr = 0.0001
I0524 20:35:05.367713  9498 solver.cpp:243] Iteration 19200, loss = 4.63074
I0524 20:35:05.367852  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.69476 (* 1 = 4.69476 loss)
I0524 20:35:05.367861  9498 sgd_solver.cpp:138] Iteration 19200, lr = 0.0001
I0524 20:37:18.348027  9498 solver.cpp:243] Iteration 19300, loss = 5.09501
I0524 20:37:18.348188  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.86192 (* 1 = 4.86192 loss)
I0524 20:37:18.348196  9498 sgd_solver.cpp:138] Iteration 19300, lr = 0.0001
I0524 20:39:31.073313  9498 solver.cpp:243] Iteration 19400, loss = 5.37546
I0524 20:39:31.073477  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.38522 (* 1 = 5.38522 loss)
I0524 20:39:31.073485  9498 sgd_solver.cpp:138] Iteration 19400, lr = 0.0001
I0524 20:41:42.533579  9498 solver.cpp:433] Iteration 19500, Testing net (#0)
I0524 20:41:42.533794  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 20:42:46.256422  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.247971
I0524 20:42:47.494699  9498 solver.cpp:243] Iteration 19500, loss = 4.9324
I0524 20:42:47.494732  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.46595 (* 1 = 5.46595 loss)
I0524 20:42:47.494755  9498 sgd_solver.cpp:138] Iteration 19500, lr = 0.0001
I0524 20:45:00.279075  9498 solver.cpp:243] Iteration 19600, loss = 5.26356
I0524 20:45:00.279227  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.17409 (* 1 = 5.17409 loss)
I0524 20:45:00.279251  9498 sgd_solver.cpp:138] Iteration 19600, lr = 0.0001
I0524 20:47:12.893901  9498 solver.cpp:243] Iteration 19700, loss = 4.94125
I0524 20:47:12.894055  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.79458 (* 1 = 4.79458 loss)
I0524 20:47:12.894065  9498 sgd_solver.cpp:138] Iteration 19700, lr = 0.0001
I0524 20:49:25.462396  9498 solver.cpp:243] Iteration 19800, loss = 4.48877
I0524 20:49:25.462527  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.15341 (* 1 = 5.15341 loss)
I0524 20:49:25.462535  9498 sgd_solver.cpp:138] Iteration 19800, lr = 0.0001
I0524 20:51:38.218257  9498 solver.cpp:243] Iteration 19900, loss = 4.71972
I0524 20:51:38.218416  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.66408 (* 1 = 3.66408 loss)
I0524 20:51:38.218441  9498 sgd_solver.cpp:138] Iteration 19900, lr = 0.0001
I0524 20:53:49.650066  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_20000.caffemodel
I0524 20:53:49.711300  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_20000.solverstate
I0524 20:53:49.743362  9498 solver.cpp:433] Iteration 20000, Testing net (#0)
I0524 20:53:49.743471  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 20:54:53.603806  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.271548
I0524 20:54:54.839679  9498 solver.cpp:243] Iteration 20000, loss = 4.64086
I0524 20:54:54.839716  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.45606 (* 1 = 4.45606 loss)
I0524 20:54:54.839722  9498 sgd_solver.cpp:47] MultiStep Status: Iteration 20000, step = 1
I0524 20:54:54.839726  9498 sgd_solver.cpp:138] Iteration 20000, lr = 5e-05
I0524 20:57:07.680621  9498 solver.cpp:243] Iteration 20100, loss = 4.85083
I0524 20:57:07.680706  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.31582 (* 1 = 5.31582 loss)
I0524 20:57:07.680714  9498 sgd_solver.cpp:138] Iteration 20100, lr = 5e-05
I0524 20:59:20.377408  9498 solver.cpp:243] Iteration 20200, loss = 5.01582
I0524 20:59:20.377516  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.10322 (* 1 = 5.10322 loss)
I0524 20:59:20.377522  9498 sgd_solver.cpp:138] Iteration 20200, lr = 5e-05
I0524 21:01:32.959175  9498 solver.cpp:243] Iteration 20300, loss = 4.62897
I0524 21:01:32.959278  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.36718 (* 1 = 4.36718 loss)
I0524 21:01:32.959286  9498 sgd_solver.cpp:138] Iteration 20300, lr = 5e-05
I0524 21:03:45.642184  9498 solver.cpp:243] Iteration 20400, loss = 4.53499
I0524 21:03:45.642282  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.3664 (* 1 = 3.3664 loss)
I0524 21:03:45.642290  9498 sgd_solver.cpp:138] Iteration 20400, lr = 5e-05
I0524 21:05:57.114085  9498 solver.cpp:433] Iteration 20500, Testing net (#0)
I0524 21:05:57.114290  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 21:07:00.923331  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.269754
I0524 21:07:02.161352  9498 solver.cpp:243] Iteration 20500, loss = 4.8122
I0524 21:07:02.161389  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.7868 (* 1 = 4.7868 loss)
I0524 21:07:02.161396  9498 sgd_solver.cpp:138] Iteration 20500, lr = 5e-05
I0524 21:09:15.009462  9498 solver.cpp:243] Iteration 20600, loss = 4.82061
I0524 21:09:15.009616  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.14282 (* 1 = 4.14282 loss)
I0524 21:09:15.009625  9498 sgd_solver.cpp:138] Iteration 20600, lr = 5e-05
I0524 21:11:27.901166  9498 solver.cpp:243] Iteration 20700, loss = 4.86359
I0524 21:11:27.901286  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.7957 (* 1 = 3.7957 loss)
I0524 21:11:27.901295  9498 sgd_solver.cpp:138] Iteration 20700, lr = 5e-05
I0524 21:13:40.625185  9498 solver.cpp:243] Iteration 20800, loss = 4.55659
I0524 21:13:40.625334  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.02009 (* 1 = 5.02009 loss)
I0524 21:13:40.625344  9498 sgd_solver.cpp:138] Iteration 20800, lr = 5e-05
I0524 21:15:53.478473  9498 solver.cpp:243] Iteration 20900, loss = 4.81488
I0524 21:15:53.478596  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.6914 (* 1 = 3.6914 loss)
I0524 21:15:53.478605  9498 sgd_solver.cpp:138] Iteration 20900, lr = 5e-05
I0524 21:18:04.863955  9498 solver.cpp:433] Iteration 21000, Testing net (#0)
I0524 21:18:04.864163  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 21:19:08.693265  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.283148
I0524 21:19:09.920156  9498 solver.cpp:243] Iteration 21000, loss = 4.63423
I0524 21:19:09.920192  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.3607 (* 1 = 4.3607 loss)
I0524 21:19:09.920198  9498 sgd_solver.cpp:138] Iteration 21000, lr = 5e-05
I0524 21:21:22.797080  9498 solver.cpp:243] Iteration 21100, loss = 4.51358
I0524 21:21:22.797230  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.17729 (* 1 = 4.17729 loss)
I0524 21:21:22.797240  9498 sgd_solver.cpp:138] Iteration 21100, lr = 5e-05
I0524 21:23:35.633559  9498 solver.cpp:243] Iteration 21200, loss = 5.08428
I0524 21:23:35.633668  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.041 (* 1 = 5.041 loss)
I0524 21:23:35.633677  9498 sgd_solver.cpp:138] Iteration 21200, lr = 5e-05
I0524 21:25:48.439805  9498 solver.cpp:243] Iteration 21300, loss = 4.58609
I0524 21:25:48.439954  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.3401 (* 1 = 4.3401 loss)
I0524 21:25:48.439962  9498 sgd_solver.cpp:138] Iteration 21300, lr = 5e-05
I0524 21:28:01.116328  9498 solver.cpp:243] Iteration 21400, loss = 4.46675
I0524 21:28:01.116480  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.88991 (* 1 = 3.88991 loss)
I0524 21:28:01.116488  9498 sgd_solver.cpp:138] Iteration 21400, lr = 5e-05
I0524 21:30:12.657263  9498 solver.cpp:433] Iteration 21500, Testing net (#0)
I0524 21:30:12.657490  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 21:31:16.483990  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.267187
I0524 21:31:17.722360  9498 solver.cpp:243] Iteration 21500, loss = 5.0167
I0524 21:31:17.722393  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.29655 (* 1 = 5.29655 loss)
I0524 21:31:17.722414  9498 sgd_solver.cpp:138] Iteration 21500, lr = 5e-05
I0524 21:33:30.288251  9498 solver.cpp:243] Iteration 21600, loss = 4.95554
I0524 21:33:30.288355  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.78419 (* 1 = 4.78419 loss)
I0524 21:33:30.288363  9498 sgd_solver.cpp:138] Iteration 21600, lr = 5e-05
I0524 21:35:43.047523  9498 solver.cpp:243] Iteration 21700, loss = 4.60155
I0524 21:35:43.047665  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.1974 (* 1 = 5.1974 loss)
I0524 21:35:43.047674  9498 sgd_solver.cpp:138] Iteration 21700, lr = 5e-05
I0524 21:37:55.882779  9498 solver.cpp:243] Iteration 21800, loss = 4.52612
I0524 21:37:55.882900  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.69799 (* 1 = 4.69799 loss)
I0524 21:37:55.882907  9498 sgd_solver.cpp:138] Iteration 21800, lr = 5e-05
I0524 21:40:08.603124  9498 solver.cpp:243] Iteration 21900, loss = 4.60997
I0524 21:40:08.603283  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.51153 (* 1 = 4.51153 loss)
I0524 21:40:08.603292  9498 sgd_solver.cpp:138] Iteration 21900, lr = 5e-05
I0524 21:42:20.207569  9498 solver.cpp:433] Iteration 22000, Testing net (#0)
I0524 21:42:20.207777  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 21:43:23.992463  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.271183
I0524 21:43:25.227408  9498 solver.cpp:243] Iteration 22000, loss = 4.63839
I0524 21:43:25.227442  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.32524 (* 1 = 3.32524 loss)
I0524 21:43:25.227448  9498 sgd_solver.cpp:138] Iteration 22000, lr = 5e-05
I0524 21:45:37.896148  9498 solver.cpp:243] Iteration 22100, loss = 5.02068
I0524 21:45:37.896284  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.7243 (* 1 = 5.7243 loss)
I0524 21:45:37.896291  9498 sgd_solver.cpp:138] Iteration 22100, lr = 5e-05
I0524 21:47:50.808795  9498 solver.cpp:243] Iteration 22200, loss = 4.45104
I0524 21:47:50.808928  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.99605 (* 1 = 3.99605 loss)
I0524 21:47:50.808936  9498 sgd_solver.cpp:138] Iteration 22200, lr = 5e-05
I0524 21:50:03.433610  9498 solver.cpp:243] Iteration 22300, loss = 4.6517
I0524 21:50:03.433763  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.19301 (* 1 = 5.19301 loss)
I0524 21:50:03.433770  9498 sgd_solver.cpp:138] Iteration 22300, lr = 5e-05
I0524 21:52:16.156656  9498 solver.cpp:243] Iteration 22400, loss = 4.69439
I0524 21:52:16.156744  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.43721 (* 1 = 5.43721 loss)
I0524 21:52:16.156752  9498 sgd_solver.cpp:138] Iteration 22400, lr = 5e-05
I0524 21:54:27.651326  9498 solver.cpp:433] Iteration 22500, Testing net (#0)
I0524 21:54:27.651542  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 21:55:31.492198  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.27584
I0524 21:55:32.728960  9498 solver.cpp:243] Iteration 22500, loss = 4.83291
I0524 21:55:32.728993  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.21059 (* 1 = 5.21059 loss)
I0524 21:55:32.729015  9498 sgd_solver.cpp:138] Iteration 22500, lr = 5e-05
I0524 21:57:45.668449  9498 solver.cpp:243] Iteration 22600, loss = 4.86747
I0524 21:57:45.668599  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.86728 (* 1 = 4.86728 loss)
I0524 21:57:45.668609  9498 sgd_solver.cpp:138] Iteration 22600, lr = 5e-05
I0524 21:59:58.527467  9498 solver.cpp:243] Iteration 22700, loss = 4.86154
I0524 21:59:58.527568  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.56055 (* 1 = 4.56055 loss)
I0524 21:59:58.527576  9498 sgd_solver.cpp:138] Iteration 22700, lr = 5e-05
I0524 22:02:11.306726  9498 solver.cpp:243] Iteration 22800, loss = 4.9076
I0524 22:02:11.306849  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.70734 (* 1 = 4.70734 loss)
I0524 22:02:11.306857  9498 sgd_solver.cpp:138] Iteration 22800, lr = 5e-05
I0524 22:04:23.935859  9498 solver.cpp:243] Iteration 22900, loss = 4.65752
I0524 22:04:23.935994  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.80648 (* 1 = 3.80648 loss)
I0524 22:04:23.936002  9498 sgd_solver.cpp:138] Iteration 22900, lr = 5e-05
I0524 22:06:35.474660  9498 solver.cpp:433] Iteration 23000, Testing net (#0)
I0524 22:06:35.475242  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 22:07:39.324451  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.286765
I0524 22:07:40.574738  9498 solver.cpp:243] Iteration 23000, loss = 4.38085
I0524 22:07:40.574772  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.07302 (* 1 = 4.07302 loss)
I0524 22:07:40.574795  9498 sgd_solver.cpp:138] Iteration 23000, lr = 5e-05
I0524 22:09:53.034162  9498 solver.cpp:243] Iteration 23100, loss = 5.08896
I0524 22:09:53.034412  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.62582 (* 1 = 4.62582 loss)
I0524 22:09:53.034446  9498 sgd_solver.cpp:138] Iteration 23100, lr = 5e-05
I0524 22:12:05.912757  9498 solver.cpp:243] Iteration 23200, loss = 4.79953
I0524 22:12:05.912900  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.45541 (* 1 = 4.45541 loss)
I0524 22:12:05.912909  9498 sgd_solver.cpp:138] Iteration 23200, lr = 5e-05
I0524 22:14:19.002434  9498 solver.cpp:243] Iteration 23300, loss = 4.5665
I0524 22:14:19.002583  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.90156 (* 1 = 4.90156 loss)
I0524 22:14:19.002590  9498 sgd_solver.cpp:138] Iteration 23300, lr = 5e-05
I0524 22:16:31.880170  9498 solver.cpp:243] Iteration 23400, loss = 4.88272
I0524 22:16:31.880261  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.53647 (* 1 = 3.53647 loss)
I0524 22:16:31.880270  9498 sgd_solver.cpp:138] Iteration 23400, lr = 5e-05
I0524 22:18:43.299144  9498 solver.cpp:433] Iteration 23500, Testing net (#0)
I0524 22:18:43.299348  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 22:19:47.161434  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.261595
I0524 22:19:48.397140  9498 solver.cpp:243] Iteration 23500, loss = 4.76825
I0524 22:19:48.397172  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.61237 (* 1 = 4.61237 loss)
I0524 22:19:48.397194  9498 sgd_solver.cpp:138] Iteration 23500, lr = 5e-05
I0524 22:22:01.224218  9498 solver.cpp:243] Iteration 23600, loss = 4.86011
I0524 22:22:01.224349  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.2533 (* 1 = 6.2533 loss)
I0524 22:22:01.224372  9498 sgd_solver.cpp:138] Iteration 23600, lr = 5e-05
I0524 22:24:14.220232  9498 solver.cpp:243] Iteration 23700, loss = 4.70595
I0524 22:24:14.220377  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.92963 (* 1 = 3.92963 loss)
I0524 22:24:14.220386  9498 sgd_solver.cpp:138] Iteration 23700, lr = 5e-05
I0524 22:26:26.865424  9498 solver.cpp:243] Iteration 23800, loss = 4.30044
I0524 22:26:26.865576  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.08544 (* 1 = 4.08544 loss)
I0524 22:26:26.865583  9498 sgd_solver.cpp:138] Iteration 23800, lr = 5e-05
I0524 22:28:39.519165  9498 solver.cpp:243] Iteration 23900, loss = 4.74628
I0524 22:28:39.519337  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.31208 (* 1 = 4.31208 loss)
I0524 22:28:39.519346  9498 sgd_solver.cpp:138] Iteration 23900, lr = 5e-05
I0524 22:30:51.335573  9498 solver.cpp:433] Iteration 24000, Testing net (#0)
I0524 22:30:51.335752  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 22:31:55.208420  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.276798
I0524 22:31:56.475080  9498 solver.cpp:243] Iteration 24000, loss = 4.64686
I0524 22:31:56.475118  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.38581 (* 1 = 5.38581 loss)
I0524 22:31:56.475126  9498 sgd_solver.cpp:138] Iteration 24000, lr = 5e-05
I0524 22:34:09.324868  9498 solver.cpp:243] Iteration 24100, loss = 4.72435
I0524 22:34:09.324995  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.15225 (* 1 = 5.15225 loss)
I0524 22:34:09.325004  9498 sgd_solver.cpp:138] Iteration 24100, lr = 5e-05
I0524 22:36:22.529479  9498 solver.cpp:243] Iteration 24200, loss = 4.53801
I0524 22:36:22.529635  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.19312 (* 1 = 5.19312 loss)
I0524 22:36:22.529644  9498 sgd_solver.cpp:138] Iteration 24200, lr = 5e-05
I0524 22:38:35.225410  9498 solver.cpp:243] Iteration 24300, loss = 4.77858
I0524 22:38:35.225512  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.91165 (* 1 = 3.91165 loss)
I0524 22:38:35.225520  9498 sgd_solver.cpp:138] Iteration 24300, lr = 5e-05
I0524 22:40:47.824638  9498 solver.cpp:243] Iteration 24400, loss = 4.83377
I0524 22:40:47.824731  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.00025 (* 1 = 5.00025 loss)
I0524 22:40:47.824739  9498 sgd_solver.cpp:138] Iteration 24400, lr = 5e-05
I0524 22:42:59.102278  9498 solver.cpp:433] Iteration 24500, Testing net (#0)
I0524 22:42:59.102509  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 22:44:02.914927  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.2643
I0524 22:44:04.150197  9498 solver.cpp:243] Iteration 24500, loss = 4.67172
I0524 22:44:04.150247  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.34979 (* 1 = 5.34979 loss)
I0524 22:44:04.150254  9498 sgd_solver.cpp:138] Iteration 24500, lr = 5e-05
I0524 22:46:17.006232  9498 solver.cpp:243] Iteration 24600, loss = 4.94681
I0524 22:46:17.006372  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.41415 (* 1 = 4.41415 loss)
I0524 22:46:17.006381  9498 sgd_solver.cpp:138] Iteration 24600, lr = 5e-05
I0524 22:48:29.887012  9498 solver.cpp:243] Iteration 24700, loss = 4.77491
I0524 22:48:29.887152  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.7563 (* 1 = 4.7563 loss)
I0524 22:48:29.887161  9498 sgd_solver.cpp:138] Iteration 24700, lr = 5e-05
I0524 22:50:42.782619  9498 solver.cpp:243] Iteration 24800, loss = 4.43956
I0524 22:50:42.782768  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.04672 (* 1 = 4.04672 loss)
I0524 22:50:42.782776  9498 sgd_solver.cpp:138] Iteration 24800, lr = 5e-05
I0524 22:52:55.713239  9498 solver.cpp:243] Iteration 24900, loss = 4.97061
I0524 22:52:55.713331  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.9092 (* 1 = 4.9092 loss)
I0524 22:52:55.713340  9498 sgd_solver.cpp:138] Iteration 24900, lr = 5e-05
I0524 22:55:07.329340  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_25000.caffemodel
I0524 22:55:07.389791  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_25000.solverstate
I0524 22:55:07.421548  9498 solver.cpp:433] Iteration 25000, Testing net (#0)
I0524 22:55:07.421665  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 22:56:11.310065  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.281924
I0524 22:56:12.542944  9498 solver.cpp:243] Iteration 25000, loss = 4.6058
I0524 22:56:12.542979  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.37573 (* 1 = 4.37573 loss)
I0524 22:56:12.542985  9498 sgd_solver.cpp:138] Iteration 25000, lr = 5e-05
I0524 22:58:25.410208  9498 solver.cpp:243] Iteration 25100, loss = 4.42586
I0524 22:58:25.410454  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.9514 (* 1 = 4.9514 loss)
I0524 22:58:25.410463  9498 sgd_solver.cpp:138] Iteration 25100, lr = 5e-05
I0524 23:00:38.308131  9498 solver.cpp:243] Iteration 25200, loss = 4.86118
I0524 23:00:38.308225  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.82367 (* 1 = 6.82367 loss)
I0524 23:00:38.308233  9498 sgd_solver.cpp:138] Iteration 25200, lr = 5e-05
I0524 23:02:51.153698  9498 solver.cpp:243] Iteration 25300, loss = 4.86526
I0524 23:02:51.153848  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.32103 (* 1 = 5.32103 loss)
I0524 23:02:51.153856  9498 sgd_solver.cpp:138] Iteration 25300, lr = 5e-05
I0524 23:05:03.997160  9498 solver.cpp:243] Iteration 25400, loss = 5.17465
I0524 23:05:03.997303  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.24564 (* 1 = 5.24564 loss)
I0524 23:05:03.997311  9498 sgd_solver.cpp:138] Iteration 25400, lr = 5e-05
I0524 23:07:15.642992  9498 solver.cpp:433] Iteration 25500, Testing net (#0)
I0524 23:07:15.643216  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 23:08:19.585124  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.291951
I0524 23:08:20.816289  9498 solver.cpp:243] Iteration 25500, loss = 4.84345
I0524 23:08:20.816326  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.53461 (* 1 = 4.53461 loss)
I0524 23:08:20.816334  9498 sgd_solver.cpp:138] Iteration 25500, lr = 5e-05
I0524 23:10:33.634735  9498 solver.cpp:243] Iteration 25600, loss = 4.61698
I0524 23:10:33.634866  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.04078 (* 1 = 5.04078 loss)
I0524 23:10:33.634876  9498 sgd_solver.cpp:138] Iteration 25600, lr = 5e-05
I0524 23:12:46.497328  9498 solver.cpp:243] Iteration 25700, loss = 4.46503
I0524 23:12:46.497470  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.76132 (* 1 = 3.76132 loss)
I0524 23:12:46.497478  9498 sgd_solver.cpp:138] Iteration 25700, lr = 5e-05
I0524 23:14:59.383317  9498 solver.cpp:243] Iteration 25800, loss = 4.61527
I0524 23:14:59.383445  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.50649 (* 1 = 5.50649 loss)
I0524 23:14:59.383453  9498 sgd_solver.cpp:138] Iteration 25800, lr = 5e-05
I0524 23:17:12.221932  9498 solver.cpp:243] Iteration 25900, loss = 4.53953
I0524 23:17:12.222084  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.56662 (* 1 = 3.56662 loss)
I0524 23:17:12.222095  9498 sgd_solver.cpp:138] Iteration 25900, lr = 5e-05
I0524 23:19:23.910749  9498 solver.cpp:433] Iteration 26000, Testing net (#0)
I0524 23:19:23.910944  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 23:20:27.911142  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.280939
I0524 23:20:29.150032  9498 solver.cpp:243] Iteration 26000, loss = 4.70492
I0524 23:20:29.150065  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.79748 (* 1 = 4.79748 loss)
I0524 23:20:29.150072  9498 sgd_solver.cpp:138] Iteration 26000, lr = 5e-05
I0524 23:22:41.953193  9498 solver.cpp:243] Iteration 26100, loss = 4.67318
I0524 23:22:41.953289  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.88987 (* 1 = 3.88987 loss)
I0524 23:22:41.953297  9498 sgd_solver.cpp:138] Iteration 26100, lr = 5e-05
I0524 23:24:54.820806  9498 solver.cpp:243] Iteration 26200, loss = 4.53887
I0524 23:24:54.820950  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.3015 (* 1 = 5.3015 loss)
I0524 23:24:54.820958  9498 sgd_solver.cpp:138] Iteration 26200, lr = 5e-05
I0524 23:27:07.651437  9498 solver.cpp:243] Iteration 26300, loss = 4.69726
I0524 23:27:07.651595  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.40768 (* 1 = 5.40768 loss)
I0524 23:27:07.651603  9498 sgd_solver.cpp:138] Iteration 26300, lr = 5e-05
I0524 23:29:20.477329  9498 solver.cpp:243] Iteration 26400, loss = 4.67694
I0524 23:29:20.477463  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.46196 (* 1 = 4.46196 loss)
I0524 23:29:20.477473  9498 sgd_solver.cpp:138] Iteration 26400, lr = 5e-05
I0524 23:31:32.124430  9498 solver.cpp:433] Iteration 26500, Testing net (#0)
I0524 23:31:32.124673  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 23:32:36.085011  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.288177
I0524 23:32:37.320394  9498 solver.cpp:243] Iteration 26500, loss = 4.6311
I0524 23:32:37.320426  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.6094 (* 1 = 4.6094 loss)
I0524 23:32:37.320448  9498 sgd_solver.cpp:138] Iteration 26500, lr = 5e-05
I0524 23:34:50.154599  9498 solver.cpp:243] Iteration 26600, loss = 4.79844
I0524 23:34:50.154748  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.18171 (* 1 = 4.18171 loss)
I0524 23:34:50.154757  9498 sgd_solver.cpp:138] Iteration 26600, lr = 5e-05
I0524 23:37:03.034529  9498 solver.cpp:243] Iteration 26700, loss = 4.90439
I0524 23:37:03.034636  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.11732 (* 1 = 6.11732 loss)
I0524 23:37:03.034644  9498 sgd_solver.cpp:138] Iteration 26700, lr = 5e-05
I0524 23:39:15.888906  9498 solver.cpp:243] Iteration 26800, loss = 4.88513
I0524 23:39:15.889014  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.6008 (* 1 = 4.6008 loss)
I0524 23:39:15.889021  9498 sgd_solver.cpp:138] Iteration 26800, lr = 5e-05
I0524 23:41:28.770756  9498 solver.cpp:243] Iteration 26900, loss = 4.37851
I0524 23:41:28.770850  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.87648 (* 1 = 4.87648 loss)
I0524 23:41:28.770859  9498 sgd_solver.cpp:138] Iteration 26900, lr = 5e-05
I0524 23:43:40.433522  9498 solver.cpp:433] Iteration 27000, Testing net (#0)
I0524 23:43:40.433734  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 23:44:44.390750  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.289986
I0524 23:44:45.625291  9498 solver.cpp:243] Iteration 27000, loss = 4.35613
I0524 23:44:45.625324  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.25229 (* 1 = 3.25229 loss)
I0524 23:44:45.625329  9498 sgd_solver.cpp:138] Iteration 27000, lr = 5e-05
I0524 23:46:58.568092  9498 solver.cpp:243] Iteration 27100, loss = 4.97381
I0524 23:46:58.568230  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.53182 (* 1 = 4.53182 loss)
I0524 23:46:58.568240  9498 sgd_solver.cpp:138] Iteration 27100, lr = 5e-05
I0524 23:49:11.369403  9498 solver.cpp:243] Iteration 27200, loss = 5.00365
I0524 23:49:11.369527  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.98111 (* 1 = 4.98111 loss)
I0524 23:49:11.369535  9498 sgd_solver.cpp:138] Iteration 27200, lr = 5e-05
I0524 23:51:24.244890  9498 solver.cpp:243] Iteration 27300, loss = 4.75887
I0524 23:51:24.245000  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.43106 (* 1 = 4.43106 loss)
I0524 23:51:24.245008  9498 sgd_solver.cpp:138] Iteration 27300, lr = 5e-05
I0524 23:53:37.144701  9498 solver.cpp:243] Iteration 27400, loss = 5.16307
I0524 23:53:37.144927  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.86113 (* 1 = 4.86113 loss)
I0524 23:53:37.144935  9498 sgd_solver.cpp:138] Iteration 27400, lr = 5e-05
I0524 23:55:48.773474  9498 solver.cpp:433] Iteration 27500, Testing net (#0)
I0524 23:55:48.773685  9498 net.cpp:693] Ignoring source layer mbox_loss
I0524 23:56:52.750203  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.280053
I0524 23:56:53.986542  9498 solver.cpp:243] Iteration 27500, loss = 4.66651
I0524 23:56:53.986582  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.9022 (* 1 = 4.9022 loss)
I0524 23:56:53.986588  9498 sgd_solver.cpp:138] Iteration 27500, lr = 5e-05
I0524 23:59:06.837924  9498 solver.cpp:243] Iteration 27600, loss = 4.21039
I0524 23:59:06.838063  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.80303 (* 1 = 4.80303 loss)
I0524 23:59:06.838069  9498 sgd_solver.cpp:138] Iteration 27600, lr = 5e-05
I0525 00:01:19.713066  9498 solver.cpp:243] Iteration 27700, loss = 4.60789
I0525 00:01:19.713199  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.03105 (* 1 = 5.03105 loss)
I0525 00:01:19.713207  9498 sgd_solver.cpp:138] Iteration 27700, lr = 5e-05
I0525 00:03:32.582635  9498 solver.cpp:243] Iteration 27800, loss = 4.59907
I0525 00:03:32.582796  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.39038 (* 1 = 4.39038 loss)
I0525 00:03:32.582806  9498 sgd_solver.cpp:138] Iteration 27800, lr = 5e-05
I0525 00:05:45.447060  9498 solver.cpp:243] Iteration 27900, loss = 4.78408
I0525 00:05:45.447219  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.75917 (* 1 = 5.75917 loss)
I0525 00:05:45.447227  9498 sgd_solver.cpp:138] Iteration 27900, lr = 5e-05
I0525 00:07:57.081909  9498 solver.cpp:433] Iteration 28000, Testing net (#0)
I0525 00:07:57.082118  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 00:09:01.054909  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.294292
I0525 00:09:02.290536  9498 solver.cpp:243] Iteration 28000, loss = 4.61071
I0525 00:09:02.290571  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.48547 (* 1 = 4.48547 loss)
I0525 00:09:02.290578  9498 sgd_solver.cpp:138] Iteration 28000, lr = 5e-05
I0525 00:11:15.250252  9498 solver.cpp:243] Iteration 28100, loss = 4.55657
I0525 00:11:15.250375  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.34281 (* 1 = 4.34281 loss)
I0525 00:11:15.250383  9498 sgd_solver.cpp:138] Iteration 28100, lr = 5e-05
I0525 00:13:28.152199  9498 solver.cpp:243] Iteration 28200, loss = 4.7222
I0525 00:13:28.152343  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.86007 (* 1 = 4.86007 loss)
I0525 00:13:28.152351  9498 sgd_solver.cpp:138] Iteration 28200, lr = 5e-05
I0525 00:15:41.026015  9498 solver.cpp:243] Iteration 28300, loss = 4.62137
I0525 00:15:41.026160  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.41497 (* 1 = 4.41497 loss)
I0525 00:15:41.026168  9498 sgd_solver.cpp:138] Iteration 28300, lr = 5e-05
I0525 00:17:53.859964  9498 solver.cpp:243] Iteration 28400, loss = 4.78466
I0525 00:17:53.860107  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.20655 (* 1 = 5.20655 loss)
I0525 00:17:53.860116  9498 sgd_solver.cpp:138] Iteration 28400, lr = 5e-05
I0525 00:20:05.548940  9498 solver.cpp:433] Iteration 28500, Testing net (#0)
I0525 00:20:05.549167  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 00:21:09.489830  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.291438
I0525 00:21:10.727413  9498 solver.cpp:243] Iteration 28500, loss = 4.62726
I0525 00:21:10.727449  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.80241 (* 1 = 4.80241 loss)
I0525 00:21:10.727457  9498 sgd_solver.cpp:138] Iteration 28500, lr = 5e-05
I0525 00:23:23.559020  9498 solver.cpp:243] Iteration 28600, loss = 4.89112
I0525 00:23:23.559185  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.38955 (* 1 = 4.38955 loss)
I0525 00:23:23.559201  9498 sgd_solver.cpp:138] Iteration 28600, lr = 5e-05
I0525 00:25:36.414482  9498 solver.cpp:243] Iteration 28700, loss = 4.82282
I0525 00:25:36.414606  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.82598 (* 1 = 4.82598 loss)
I0525 00:25:36.414615  9498 sgd_solver.cpp:138] Iteration 28700, lr = 5e-05
I0525 00:27:49.360321  9498 solver.cpp:243] Iteration 28800, loss = 4.29044
I0525 00:27:49.360471  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.46133 (* 1 = 4.46133 loss)
I0525 00:27:49.360479  9498 sgd_solver.cpp:138] Iteration 28800, lr = 5e-05
I0525 00:30:02.227870  9498 solver.cpp:243] Iteration 28900, loss = 4.42555
I0525 00:30:02.228020  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.66277 (* 1 = 4.66277 loss)
I0525 00:30:02.228029  9498 sgd_solver.cpp:138] Iteration 28900, lr = 5e-05
I0525 00:32:13.942873  9498 solver.cpp:433] Iteration 29000, Testing net (#0)
I0525 00:32:13.943094  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 00:33:17.892144  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.296713
I0525 00:33:19.122855  9498 solver.cpp:243] Iteration 29000, loss = 5.19343
I0525 00:33:19.122890  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.89196 (* 1 = 4.89196 loss)
I0525 00:33:19.122897  9498 sgd_solver.cpp:138] Iteration 29000, lr = 5e-05
I0525 00:35:31.934370  9498 solver.cpp:243] Iteration 29100, loss = 4.57087
I0525 00:35:31.934518  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.86905 (* 1 = 4.86905 loss)
I0525 00:35:31.934528  9498 sgd_solver.cpp:138] Iteration 29100, lr = 5e-05
I0525 00:37:44.782722  9498 solver.cpp:243] Iteration 29200, loss = 4.68322
I0525 00:37:44.782883  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.0725 (* 1 = 5.0725 loss)
I0525 00:37:44.782891  9498 sgd_solver.cpp:138] Iteration 29200, lr = 5e-05
I0525 00:39:57.643035  9498 solver.cpp:243] Iteration 29300, loss = 4.87066
I0525 00:39:57.643187  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.78307 (* 1 = 4.78307 loss)
I0525 00:39:57.643211  9498 sgd_solver.cpp:138] Iteration 29300, lr = 5e-05
I0525 00:42:10.550871  9498 solver.cpp:243] Iteration 29400, loss = 4.52447
I0525 00:42:10.550989  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.0164 (* 1 = 4.0164 loss)
I0525 00:42:10.550997  9498 sgd_solver.cpp:138] Iteration 29400, lr = 5e-05
I0525 00:44:22.158303  9498 solver.cpp:433] Iteration 29500, Testing net (#0)
I0525 00:44:22.158515  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 00:45:26.125095  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.306042
I0525 00:45:27.364549  9498 solver.cpp:243] Iteration 29500, loss = 4.69556
I0525 00:45:27.364583  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.12963 (* 1 = 5.12963 loss)
I0525 00:45:27.364605  9498 sgd_solver.cpp:138] Iteration 29500, lr = 5e-05
I0525 00:47:40.241716  9498 solver.cpp:243] Iteration 29600, loss = 4.72475
I0525 00:47:40.241888  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.09535 (* 1 = 4.09535 loss)
I0525 00:47:40.241896  9498 sgd_solver.cpp:138] Iteration 29600, lr = 5e-05
I0525 00:49:53.085650  9498 solver.cpp:243] Iteration 29700, loss = 4.56553
I0525 00:49:53.085748  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.41888 (* 1 = 5.41888 loss)
I0525 00:49:53.085757  9498 sgd_solver.cpp:138] Iteration 29700, lr = 5e-05
I0525 00:52:05.930757  9498 solver.cpp:243] Iteration 29800, loss = 4.44041
I0525 00:52:05.930881  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.93171 (* 1 = 3.93171 loss)
I0525 00:52:05.930889  9498 sgd_solver.cpp:138] Iteration 29800, lr = 5e-05
I0525 00:54:18.792448  9498 solver.cpp:243] Iteration 29900, loss = 4.90607
I0525 00:54:18.792544  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.41604 (* 1 = 5.41604 loss)
I0525 00:54:18.792553  9498 sgd_solver.cpp:138] Iteration 29900, lr = 5e-05
I0525 00:56:30.424309  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_30000.caffemodel
I0525 00:56:30.486130  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_30000.solverstate
I0525 00:56:30.518378  9498 solver.cpp:433] Iteration 30000, Testing net (#0)
I0525 00:56:30.518508  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 00:57:34.451614  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.277522
I0525 00:57:35.686632  9498 solver.cpp:243] Iteration 30000, loss = 4.52517
I0525 00:57:35.686666  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.65246 (* 1 = 4.65246 loss)
I0525 00:57:35.686671  9498 sgd_solver.cpp:138] Iteration 30000, lr = 5e-05
I0525 00:59:48.561894  9498 solver.cpp:243] Iteration 30100, loss = 4.41614
I0525 00:59:48.562043  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.48922 (* 1 = 5.48922 loss)
I0525 00:59:48.562052  9498 sgd_solver.cpp:138] Iteration 30100, lr = 5e-05
I0525 01:02:01.431311  9498 solver.cpp:243] Iteration 30200, loss = 4.58044
I0525 01:02:01.431442  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.30578 (* 1 = 4.30578 loss)
I0525 01:02:01.431452  9498 sgd_solver.cpp:138] Iteration 30200, lr = 5e-05
I0525 01:04:14.328898  9498 solver.cpp:243] Iteration 30300, loss = 4.69264
I0525 01:04:14.329207  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.43656 (* 1 = 4.43656 loss)
I0525 01:04:14.329217  9498 sgd_solver.cpp:138] Iteration 30300, lr = 5e-05
I0525 01:06:27.126087  9498 solver.cpp:243] Iteration 30400, loss = 4.59836
I0525 01:06:27.126288  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.11767 (* 1 = 4.11767 loss)
I0525 01:06:27.126296  9498 sgd_solver.cpp:138] Iteration 30400, lr = 5e-05
I0525 01:08:38.745198  9498 solver.cpp:433] Iteration 30500, Testing net (#0)
I0525 01:08:38.745424  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 01:09:42.733860  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.308285
I0525 01:09:43.963795  9498 solver.cpp:243] Iteration 30500, loss = 4.73242
I0525 01:09:43.963829  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.43157 (* 1 = 4.43157 loss)
I0525 01:09:43.963850  9498 sgd_solver.cpp:138] Iteration 30500, lr = 5e-05
I0525 01:11:56.807499  9498 solver.cpp:243] Iteration 30600, loss = 4.89308
I0525 01:11:56.807646  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.15028 (* 1 = 3.15028 loss)
I0525 01:11:56.807654  9498 sgd_solver.cpp:138] Iteration 30600, lr = 5e-05
I0525 01:14:09.732884  9498 solver.cpp:243] Iteration 30700, loss = 4.55787
I0525 01:14:09.733049  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.81769 (* 1 = 4.81769 loss)
I0525 01:14:09.733057  9498 sgd_solver.cpp:138] Iteration 30700, lr = 5e-05
I0525 01:16:22.657873  9498 solver.cpp:243] Iteration 30800, loss = 4.93958
I0525 01:16:22.658018  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.94062 (* 1 = 5.94062 loss)
I0525 01:16:22.658027  9498 sgd_solver.cpp:138] Iteration 30800, lr = 5e-05
I0525 01:18:35.579962  9498 solver.cpp:243] Iteration 30900, loss = 4.6896
I0525 01:18:35.580116  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.9159 (* 1 = 4.9159 loss)
I0525 01:18:35.580124  9498 sgd_solver.cpp:138] Iteration 30900, lr = 5e-05
I0525 01:20:47.191459  9498 solver.cpp:433] Iteration 31000, Testing net (#0)
I0525 01:20:47.191676  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 01:21:51.099858  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.294813
I0525 01:21:52.333796  9498 solver.cpp:243] Iteration 31000, loss = 4.83314
I0525 01:21:52.333830  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.15022 (* 1 = 5.15022 loss)
I0525 01:21:52.333853  9498 sgd_solver.cpp:138] Iteration 31000, lr = 5e-05
I0525 01:24:05.195973  9498 solver.cpp:243] Iteration 31100, loss = 4.73874
I0525 01:24:05.196113  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.18625 (* 1 = 5.18625 loss)
I0525 01:24:05.196121  9498 sgd_solver.cpp:138] Iteration 31100, lr = 5e-05
I0525 01:26:18.042789  9498 solver.cpp:243] Iteration 31200, loss = 4.72495
I0525 01:26:18.042919  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.78652 (* 1 = 4.78652 loss)
I0525 01:26:18.042928  9498 sgd_solver.cpp:138] Iteration 31200, lr = 5e-05
I0525 01:28:30.900256  9498 solver.cpp:243] Iteration 31300, loss = 4.53108
I0525 01:28:30.900408  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.09483 (* 1 = 5.09483 loss)
I0525 01:28:30.900415  9498 sgd_solver.cpp:138] Iteration 31300, lr = 5e-05
I0525 01:30:43.754767  9498 solver.cpp:243] Iteration 31400, loss = 4.79712
I0525 01:30:43.754905  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.81848 (* 1 = 3.81848 loss)
I0525 01:30:43.754914  9498 sgd_solver.cpp:138] Iteration 31400, lr = 5e-05
I0525 01:32:55.442883  9498 solver.cpp:433] Iteration 31500, Testing net (#0)
I0525 01:32:55.443097  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 01:33:59.393718  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.299905
I0525 01:34:00.626544  9498 solver.cpp:243] Iteration 31500, loss = 4.65863
I0525 01:34:00.626577  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.37721 (* 1 = 5.37721 loss)
I0525 01:34:00.626583  9498 sgd_solver.cpp:138] Iteration 31500, lr = 5e-05
I0525 01:36:13.496835  9498 solver.cpp:243] Iteration 31600, loss = 4.17687
I0525 01:36:13.496997  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.48956 (* 1 = 4.48956 loss)
I0525 01:36:13.497006  9498 sgd_solver.cpp:138] Iteration 31600, lr = 5e-05
I0525 01:38:26.307476  9498 solver.cpp:243] Iteration 31700, loss = 4.74814
I0525 01:38:26.307585  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.15501 (* 1 = 4.15501 loss)
I0525 01:38:26.307595  9498 sgd_solver.cpp:138] Iteration 31700, lr = 5e-05
I0525 01:40:39.137866  9498 solver.cpp:243] Iteration 31800, loss = 4.17522
I0525 01:40:39.138007  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.82003 (* 1 = 3.82003 loss)
I0525 01:40:39.138016  9498 sgd_solver.cpp:138] Iteration 31800, lr = 5e-05
I0525 01:42:52.044450  9498 solver.cpp:243] Iteration 31900, loss = 4.52628
I0525 01:42:52.045274  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.73835 (* 1 = 4.73835 loss)
I0525 01:42:52.045284  9498 sgd_solver.cpp:138] Iteration 31900, lr = 5e-05
I0525 01:45:03.862035  9498 solver.cpp:433] Iteration 32000, Testing net (#0)
I0525 01:45:03.862269  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 01:46:07.826766  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.314787
I0525 01:46:09.057348  9498 solver.cpp:243] Iteration 32000, loss = 4.55527
I0525 01:46:09.057384  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.1304 (* 1 = 5.1304 loss)
I0525 01:46:09.057391  9498 sgd_solver.cpp:138] Iteration 32000, lr = 5e-05
I0525 01:48:21.933437  9498 solver.cpp:243] Iteration 32100, loss = 4.22539
I0525 01:48:21.933604  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.58982 (* 1 = 4.58982 loss)
I0525 01:48:21.933614  9498 sgd_solver.cpp:138] Iteration 32100, lr = 5e-05
I0525 01:50:34.799221  9498 solver.cpp:243] Iteration 32200, loss = 4.7686
I0525 01:50:34.799314  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.83172 (* 1 = 4.83172 loss)
I0525 01:50:34.799322  9498 sgd_solver.cpp:138] Iteration 32200, lr = 5e-05
I0525 01:52:47.693514  9498 solver.cpp:243] Iteration 32300, loss = 4.74807
I0525 01:52:47.694357  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.57524 (* 1 = 5.57524 loss)
I0525 01:52:47.694366  9498 sgd_solver.cpp:138] Iteration 32300, lr = 5e-05
I0525 01:55:00.544430  9498 solver.cpp:243] Iteration 32400, loss = 4.79684
I0525 01:55:00.545728  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.11746 (* 1 = 5.11746 loss)
I0525 01:55:00.545737  9498 sgd_solver.cpp:138] Iteration 32400, lr = 5e-05
I0525 01:57:12.146868  9498 solver.cpp:433] Iteration 32500, Testing net (#0)
I0525 01:57:12.147097  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 01:58:16.059936  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.296996
I0525 01:58:17.295126  9498 solver.cpp:243] Iteration 32500, loss = 4.50232
I0525 01:58:17.295161  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.56449 (* 1 = 4.56449 loss)
I0525 01:58:17.295168  9498 sgd_solver.cpp:138] Iteration 32500, lr = 5e-05
I0525 02:00:30.141860  9498 solver.cpp:243] Iteration 32600, loss = 4.36952
I0525 02:00:30.142009  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.2507 (* 1 = 4.2507 loss)
I0525 02:00:30.142017  9498 sgd_solver.cpp:138] Iteration 32600, lr = 5e-05
I0525 02:02:42.972947  9498 solver.cpp:243] Iteration 32700, loss = 4.98015
I0525 02:02:42.973101  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.59178 (* 1 = 5.59178 loss)
I0525 02:02:42.973110  9498 sgd_solver.cpp:138] Iteration 32700, lr = 5e-05
I0525 02:04:55.815081  9498 solver.cpp:243] Iteration 32800, loss = 4.22296
I0525 02:04:55.815228  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.35706 (* 1 = 4.35706 loss)
I0525 02:04:55.815237  9498 sgd_solver.cpp:138] Iteration 32800, lr = 5e-05
I0525 02:07:08.690778  9498 solver.cpp:243] Iteration 32900, loss = 4.61055
I0525 02:07:08.690946  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.76484 (* 1 = 5.76484 loss)
I0525 02:07:08.690976  9498 sgd_solver.cpp:138] Iteration 32900, lr = 5e-05
I0525 02:09:20.257997  9498 solver.cpp:433] Iteration 33000, Testing net (#0)
I0525 02:09:20.258237  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 02:10:24.190733  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.32333
I0525 02:10:25.427556  9498 solver.cpp:243] Iteration 33000, loss = 4.63728
I0525 02:10:25.427592  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.82082 (* 1 = 3.82082 loss)
I0525 02:10:25.427598  9498 sgd_solver.cpp:138] Iteration 33000, lr = 5e-05
I0525 02:12:38.308920  9498 solver.cpp:243] Iteration 33100, loss = 4.90887
I0525 02:12:38.309058  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.16509 (* 1 = 5.16509 loss)
I0525 02:12:38.309067  9498 sgd_solver.cpp:138] Iteration 33100, lr = 5e-05
I0525 02:14:51.185215  9498 solver.cpp:243] Iteration 33200, loss = 4.76613
I0525 02:14:51.185374  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.40225 (* 1 = 4.40225 loss)
I0525 02:14:51.185384  9498 sgd_solver.cpp:138] Iteration 33200, lr = 5e-05
I0525 02:17:04.054687  9498 solver.cpp:243] Iteration 33300, loss = 4.46354
I0525 02:17:04.054781  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.79519 (* 1 = 4.79519 loss)
I0525 02:17:04.054790  9498 sgd_solver.cpp:138] Iteration 33300, lr = 5e-05
I0525 02:19:16.952631  9498 solver.cpp:243] Iteration 33400, loss = 4.60509
I0525 02:19:16.952780  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.72747 (* 1 = 5.72747 loss)
I0525 02:19:16.952790  9498 sgd_solver.cpp:138] Iteration 33400, lr = 5e-05
I0525 02:21:28.596530  9498 solver.cpp:433] Iteration 33500, Testing net (#0)
I0525 02:21:28.596762  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 02:22:32.583870  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.312763
I0525 02:22:33.818909  9498 solver.cpp:243] Iteration 33500, loss = 4.2262
I0525 02:22:33.818945  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.14518 (* 1 = 4.14518 loss)
I0525 02:22:33.818953  9498 sgd_solver.cpp:138] Iteration 33500, lr = 5e-05
I0525 02:24:46.677486  9498 solver.cpp:243] Iteration 33600, loss = 4.52861
I0525 02:24:46.677579  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.23251 (* 1 = 5.23251 loss)
I0525 02:24:46.677588  9498 sgd_solver.cpp:138] Iteration 33600, lr = 5e-05
I0525 02:26:59.478238  9498 solver.cpp:243] Iteration 33700, loss = 4.3601
I0525 02:26:59.478404  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.58448 (* 1 = 4.58448 loss)
I0525 02:26:59.478413  9498 sgd_solver.cpp:138] Iteration 33700, lr = 5e-05
I0525 02:29:12.365021  9498 solver.cpp:243] Iteration 33800, loss = 4.72169
I0525 02:29:12.365119  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.98854 (* 1 = 3.98854 loss)
I0525 02:29:12.365130  9498 sgd_solver.cpp:138] Iteration 33800, lr = 5e-05
I0525 02:31:25.201891  9498 solver.cpp:243] Iteration 33900, loss = 4.59623
I0525 02:31:25.202037  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.65033 (* 1 = 4.65033 loss)
I0525 02:31:25.202049  9498 sgd_solver.cpp:138] Iteration 33900, lr = 5e-05
I0525 02:33:36.880791  9498 solver.cpp:433] Iteration 34000, Testing net (#0)
I0525 02:33:36.881011  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 02:34:40.885982  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.301082
I0525 02:34:42.119411  9498 solver.cpp:243] Iteration 34000, loss = 4.09327
I0525 02:34:42.119449  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.54548 (* 1 = 4.54548 loss)
I0525 02:34:42.119458  9498 sgd_solver.cpp:138] Iteration 34000, lr = 5e-05
I0525 02:36:54.962661  9498 solver.cpp:243] Iteration 34100, loss = 4.1497
I0525 02:36:54.962800  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.05627 (* 1 = 4.05627 loss)
I0525 02:36:54.962810  9498 sgd_solver.cpp:138] Iteration 34100, lr = 5e-05
I0525 02:39:07.805372  9498 solver.cpp:243] Iteration 34200, loss = 4.45704
I0525 02:39:07.805492  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.11518 (* 1 = 3.11518 loss)
I0525 02:39:07.805503  9498 sgd_solver.cpp:138] Iteration 34200, lr = 5e-05
I0525 02:41:20.681954  9498 solver.cpp:243] Iteration 34300, loss = 5.0085
I0525 02:41:20.682121  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.62607 (* 1 = 4.62607 loss)
I0525 02:41:20.682132  9498 sgd_solver.cpp:138] Iteration 34300, lr = 5e-05
I0525 02:43:33.521663  9498 solver.cpp:243] Iteration 34400, loss = 4.70363
I0525 02:43:33.521761  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.0405 (* 1 = 4.0405 loss)
I0525 02:43:33.521770  9498 sgd_solver.cpp:138] Iteration 34400, lr = 5e-05
I0525 02:45:45.111136  9498 solver.cpp:433] Iteration 34500, Testing net (#0)
I0525 02:45:45.111310  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 02:46:49.077033  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.306568
I0525 02:46:50.309780  9498 solver.cpp:243] Iteration 34500, loss = 4.57476
I0525 02:46:50.309818  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.31342 (* 1 = 4.31342 loss)
I0525 02:46:50.309825  9498 sgd_solver.cpp:138] Iteration 34500, lr = 5e-05
I0525 02:49:03.164361  9498 solver.cpp:243] Iteration 34600, loss = 4.6268
I0525 02:49:03.164499  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.51203 (* 1 = 3.51203 loss)
I0525 02:49:03.164507  9498 sgd_solver.cpp:138] Iteration 34600, lr = 5e-05
I0525 02:51:15.982455  9498 solver.cpp:243] Iteration 34700, loss = 4.36044
I0525 02:51:15.982578  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.05901 (* 1 = 5.05901 loss)
I0525 02:51:15.982587  9498 sgd_solver.cpp:138] Iteration 34700, lr = 5e-05
I0525 02:53:28.845965  9498 solver.cpp:243] Iteration 34800, loss = 4.33403
I0525 02:53:28.846210  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.28195 (* 1 = 5.28195 loss)
I0525 02:53:28.846218  9498 sgd_solver.cpp:138] Iteration 34800, lr = 5e-05
I0525 02:55:41.662150  9498 solver.cpp:243] Iteration 34900, loss = 4.71087
I0525 02:55:41.662298  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.83068 (* 1 = 3.83068 loss)
I0525 02:55:41.662307  9498 sgd_solver.cpp:138] Iteration 34900, lr = 5e-05
I0525 02:57:53.289304  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_35000.caffemodel
I0525 02:57:53.350467  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_35000.solverstate
I0525 02:57:53.382602  9498 solver.cpp:433] Iteration 35000, Testing net (#0)
I0525 02:57:53.382748  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 02:58:57.369736  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.341622
I0525 02:58:58.604637  9498 solver.cpp:243] Iteration 35000, loss = 4.88489
I0525 02:58:58.604671  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.48525 (* 1 = 4.48525 loss)
I0525 02:58:58.604678  9498 sgd_solver.cpp:138] Iteration 35000, lr = 5e-05
I0525 03:01:11.504640  9498 solver.cpp:243] Iteration 35100, loss = 4.66902
I0525 03:01:11.504783  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.43185 (* 1 = 4.43185 loss)
I0525 03:01:11.504791  9498 sgd_solver.cpp:138] Iteration 35100, lr = 5e-05
I0525 03:03:24.327854  9498 solver.cpp:243] Iteration 35200, loss = 4.8861
I0525 03:03:24.328007  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.73791 (* 1 = 4.73791 loss)
I0525 03:03:24.328016  9498 sgd_solver.cpp:138] Iteration 35200, lr = 5e-05
I0525 03:05:37.186609  9498 solver.cpp:243] Iteration 35300, loss = 4.76475
I0525 03:05:37.186717  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.85814 (* 1 = 4.85814 loss)
I0525 03:05:37.186724  9498 sgd_solver.cpp:138] Iteration 35300, lr = 5e-05
I0525 03:07:50.084458  9498 solver.cpp:243] Iteration 35400, loss = 4.28188
I0525 03:07:50.084635  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.50367 (* 1 = 4.50367 loss)
I0525 03:07:50.084643  9498 sgd_solver.cpp:138] Iteration 35400, lr = 5e-05
I0525 03:10:01.599681  9498 solver.cpp:433] Iteration 35500, Testing net (#0)
I0525 03:10:01.599884  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 03:11:05.544231  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.310849
I0525 03:11:06.778975  9498 solver.cpp:243] Iteration 35500, loss = 4.87822
I0525 03:11:06.779006  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.58586 (* 1 = 4.58586 loss)
I0525 03:11:06.779013  9498 sgd_solver.cpp:138] Iteration 35500, lr = 5e-05
I0525 03:13:19.667117  9498 solver.cpp:243] Iteration 35600, loss = 4.34535
I0525 03:13:19.667268  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.6586 (* 1 = 4.6586 loss)
I0525 03:13:19.667277  9498 sgd_solver.cpp:138] Iteration 35600, lr = 5e-05
I0525 03:15:32.511222  9498 solver.cpp:243] Iteration 35700, loss = 4.62667
I0525 03:15:32.511420  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.81421 (* 1 = 4.81421 loss)
I0525 03:15:32.511428  9498 sgd_solver.cpp:138] Iteration 35700, lr = 5e-05
I0525 03:17:45.333868  9498 solver.cpp:243] Iteration 35800, loss = 4.51706
I0525 03:17:45.333968  9498 solver.cpp:259]     Train net output #0: mbox_loss = 2.1308 (* 1 = 2.1308 loss)
I0525 03:17:45.333976  9498 sgd_solver.cpp:138] Iteration 35800, lr = 5e-05
I0525 03:19:58.241256  9498 solver.cpp:243] Iteration 35900, loss = 4.62504
I0525 03:19:58.241394  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.19514 (* 1 = 5.19514 loss)
I0525 03:19:58.241417  9498 sgd_solver.cpp:138] Iteration 35900, lr = 5e-05
I0525 03:22:09.862534  9498 solver.cpp:433] Iteration 36000, Testing net (#0)
I0525 03:22:09.862758  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 03:23:13.790424  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.311367
I0525 03:23:15.023453  9498 solver.cpp:243] Iteration 36000, loss = 4.57186
I0525 03:23:15.023486  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.22961 (* 1 = 3.22961 loss)
I0525 03:23:15.023492  9498 sgd_solver.cpp:138] Iteration 36000, lr = 5e-05
I0525 03:25:27.874146  9498 solver.cpp:243] Iteration 36100, loss = 4.68218
I0525 03:25:27.874290  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.33138 (* 1 = 5.33138 loss)
I0525 03:25:27.874298  9498 sgd_solver.cpp:138] Iteration 36100, lr = 5e-05
I0525 03:27:40.795859  9498 solver.cpp:243] Iteration 36200, loss = 4.86851
I0525 03:27:40.796006  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.5388 (* 1 = 4.5388 loss)
I0525 03:27:40.796015  9498 sgd_solver.cpp:138] Iteration 36200, lr = 5e-05
I0525 03:29:53.716238  9498 solver.cpp:243] Iteration 36300, loss = 4.94804
I0525 03:29:53.716394  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.3879 (* 1 = 4.3879 loss)
I0525 03:29:53.716403  9498 sgd_solver.cpp:138] Iteration 36300, lr = 5e-05
I0525 03:32:06.549358  9498 solver.cpp:243] Iteration 36400, loss = 4.8024
I0525 03:32:06.549482  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.1094 (* 1 = 4.1094 loss)
I0525 03:32:06.549490  9498 sgd_solver.cpp:138] Iteration 36400, lr = 5e-05
I0525 03:34:18.217018  9498 solver.cpp:433] Iteration 36500, Testing net (#0)
I0525 03:34:18.217208  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 03:35:22.213044  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.304609
I0525 03:35:23.447091  9498 solver.cpp:243] Iteration 36500, loss = 4.89097
I0525 03:35:23.447129  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.81387 (* 1 = 4.81387 loss)
I0525 03:35:23.447134  9498 sgd_solver.cpp:138] Iteration 36500, lr = 5e-05
I0525 03:37:36.258488  9498 solver.cpp:243] Iteration 36600, loss = 4.84305
I0525 03:37:36.258654  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.07657 (* 1 = 5.07657 loss)
I0525 03:37:36.258662  9498 sgd_solver.cpp:138] Iteration 36600, lr = 5e-05
I0525 03:39:49.131688  9498 solver.cpp:243] Iteration 36700, loss = 4.23517
I0525 03:39:49.131825  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.76123 (* 1 = 4.76123 loss)
I0525 03:39:49.131834  9498 sgd_solver.cpp:138] Iteration 36700, lr = 5e-05
I0525 03:42:01.998267  9498 solver.cpp:243] Iteration 36800, loss = 4.73841
I0525 03:42:01.998410  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.35012 (* 1 = 5.35012 loss)
I0525 03:42:01.998417  9498 sgd_solver.cpp:138] Iteration 36800, lr = 5e-05
I0525 03:44:14.777091  9498 solver.cpp:243] Iteration 36900, loss = 4.49643
I0525 03:44:14.777391  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.53753 (* 1 = 4.53753 loss)
I0525 03:44:14.777415  9498 sgd_solver.cpp:138] Iteration 36900, lr = 5e-05
I0525 03:46:26.452304  9498 solver.cpp:433] Iteration 37000, Testing net (#0)
I0525 03:46:26.452487  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 03:47:30.396781  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.333162
I0525 03:47:31.632681  9498 solver.cpp:243] Iteration 37000, loss = 4.72728
I0525 03:47:31.632717  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.61101 (* 1 = 5.61101 loss)
I0525 03:47:31.632726  9498 sgd_solver.cpp:138] Iteration 37000, lr = 5e-05
I0525 03:49:44.546790  9498 solver.cpp:243] Iteration 37100, loss = 4.69031
I0525 03:49:44.546936  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.74583 (* 1 = 4.74583 loss)
I0525 03:49:44.546945  9498 sgd_solver.cpp:138] Iteration 37100, lr = 5e-05
I0525 03:51:57.410104  9498 solver.cpp:243] Iteration 37200, loss = 4.33411
I0525 03:51:57.410208  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.5952 (* 1 = 4.5952 loss)
I0525 03:51:57.410217  9498 sgd_solver.cpp:138] Iteration 37200, lr = 5e-05
I0525 03:54:10.241783  9498 solver.cpp:243] Iteration 37300, loss = 4.72022
I0525 03:54:10.241933  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.34404 (* 1 = 5.34404 loss)
I0525 03:54:10.241941  9498 sgd_solver.cpp:138] Iteration 37300, lr = 5e-05
I0525 03:56:23.046605  9498 solver.cpp:243] Iteration 37400, loss = 4.50503
I0525 03:56:23.046752  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.38798 (* 1 = 4.38798 loss)
I0525 03:56:23.046761  9498 sgd_solver.cpp:138] Iteration 37400, lr = 5e-05
I0525 03:58:34.623065  9498 solver.cpp:433] Iteration 37500, Testing net (#0)
I0525 03:58:34.623309  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 03:59:38.556700  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.290954
I0525 03:59:39.798563  9498 solver.cpp:243] Iteration 37500, loss = 4.2368
I0525 03:59:39.798595  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.0189 (* 1 = 4.0189 loss)
I0525 03:59:39.798602  9498 sgd_solver.cpp:138] Iteration 37500, lr = 5e-05
I0525 04:01:52.733893  9498 solver.cpp:243] Iteration 37600, loss = 4.47
I0525 04:01:52.734050  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.1876 (* 1 = 4.1876 loss)
I0525 04:01:52.734059  9498 sgd_solver.cpp:138] Iteration 37600, lr = 5e-05
I0525 04:04:05.557353  9498 solver.cpp:243] Iteration 37700, loss = 4.50046
I0525 04:04:05.557483  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.19353 (* 1 = 3.19353 loss)
I0525 04:04:05.557507  9498 sgd_solver.cpp:138] Iteration 37700, lr = 5e-05
I0525 04:06:18.372673  9498 solver.cpp:243] Iteration 37800, loss = 4.54418
I0525 04:06:18.372807  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.53834 (* 1 = 5.53834 loss)
I0525 04:06:18.372815  9498 sgd_solver.cpp:138] Iteration 37800, lr = 5e-05
I0525 04:08:31.232796  9498 solver.cpp:243] Iteration 37900, loss = 4.56351
I0525 04:08:31.232933  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.05611 (* 1 = 4.05611 loss)
I0525 04:08:31.232940  9498 sgd_solver.cpp:138] Iteration 37900, lr = 5e-05
I0525 04:10:42.801443  9498 solver.cpp:433] Iteration 38000, Testing net (#0)
I0525 04:10:42.801614  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 04:11:46.745386  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.312689
I0525 04:11:47.978749  9498 solver.cpp:243] Iteration 38000, loss = 4.60326
I0525 04:11:47.978780  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.1458 (* 1 = 5.1458 loss)
I0525 04:11:47.978802  9498 sgd_solver.cpp:138] Iteration 38000, lr = 5e-05
I0525 04:14:00.755194  9498 solver.cpp:243] Iteration 38100, loss = 4.58764
I0525 04:14:00.755319  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.03644 (* 1 = 4.03644 loss)
I0525 04:14:00.755327  9498 sgd_solver.cpp:138] Iteration 38100, lr = 5e-05
I0525 04:16:13.632025  9498 solver.cpp:243] Iteration 38200, loss = 4.4824
I0525 04:16:13.632194  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.46806 (* 1 = 4.46806 loss)
I0525 04:16:13.632202  9498 sgd_solver.cpp:138] Iteration 38200, lr = 5e-05
I0525 04:18:26.474436  9498 solver.cpp:243] Iteration 38300, loss = 4.53053
I0525 04:18:26.474578  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.04348 (* 1 = 4.04348 loss)
I0525 04:18:26.474587  9498 sgd_solver.cpp:138] Iteration 38300, lr = 5e-05
I0525 04:20:39.252493  9498 solver.cpp:243] Iteration 38400, loss = 4.73095
I0525 04:20:39.252671  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.1408 (* 1 = 4.1408 loss)
I0525 04:20:39.252681  9498 sgd_solver.cpp:138] Iteration 38400, lr = 5e-05
I0525 04:22:50.896462  9498 solver.cpp:433] Iteration 38500, Testing net (#0)
I0525 04:22:50.896677  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 04:23:54.862067  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.319457
I0525 04:23:56.094475  9498 solver.cpp:243] Iteration 38500, loss = 4.6729
I0525 04:23:56.094511  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.78895 (* 1 = 5.78895 loss)
I0525 04:23:56.094533  9498 sgd_solver.cpp:138] Iteration 38500, lr = 5e-05
I0525 04:26:08.935282  9498 solver.cpp:243] Iteration 38600, loss = 4.89055
I0525 04:26:08.935413  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.95096 (* 1 = 4.95096 loss)
I0525 04:26:08.935421  9498 sgd_solver.cpp:138] Iteration 38600, lr = 5e-05
I0525 04:28:21.837347  9498 solver.cpp:243] Iteration 38700, loss = 4.49751
I0525 04:28:21.837453  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.23924 (* 1 = 4.23924 loss)
I0525 04:28:21.837462  9498 sgd_solver.cpp:138] Iteration 38700, lr = 5e-05
I0525 04:30:34.692754  9498 solver.cpp:243] Iteration 38800, loss = 4.67198
I0525 04:30:34.692896  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.42634 (* 1 = 4.42634 loss)
I0525 04:30:34.692904  9498 sgd_solver.cpp:138] Iteration 38800, lr = 5e-05
I0525 04:32:47.743311  9498 solver.cpp:243] Iteration 38900, loss = 4.77088
I0525 04:32:47.743610  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.63812 (* 1 = 5.63812 loss)
I0525 04:32:47.743619  9498 sgd_solver.cpp:138] Iteration 38900, lr = 5e-05
I0525 04:34:59.368474  9498 solver.cpp:433] Iteration 39000, Testing net (#0)
I0525 04:34:59.368683  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 04:36:03.302865  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.323673
I0525 04:36:04.537199  9498 solver.cpp:243] Iteration 39000, loss = 4.70487
I0525 04:36:04.537233  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.15695 (* 1 = 5.15695 loss)
I0525 04:36:04.537242  9498 sgd_solver.cpp:138] Iteration 39000, lr = 5e-05
I0525 04:38:17.319103  9498 solver.cpp:243] Iteration 39100, loss = 4.46306
I0525 04:38:17.319238  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.72453 (* 1 = 3.72453 loss)
I0525 04:38:17.319245  9498 sgd_solver.cpp:138] Iteration 39100, lr = 5e-05
I0525 04:40:30.180826  9498 solver.cpp:243] Iteration 39200, loss = 4.91581
I0525 04:40:30.180984  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.65957 (* 1 = 5.65957 loss)
I0525 04:40:30.180992  9498 sgd_solver.cpp:138] Iteration 39200, lr = 5e-05
I0525 04:42:43.047302  9498 solver.cpp:243] Iteration 39300, loss = 4.56309
I0525 04:42:43.047417  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.02525 (* 1 = 4.02525 loss)
I0525 04:42:43.047426  9498 sgd_solver.cpp:138] Iteration 39300, lr = 5e-05
I0525 04:44:55.975487  9498 solver.cpp:243] Iteration 39400, loss = 4.12421
I0525 04:44:55.975606  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.55956 (* 1 = 4.55956 loss)
I0525 04:44:55.975615  9498 sgd_solver.cpp:138] Iteration 39400, lr = 5e-05
I0525 04:47:07.676838  9498 solver.cpp:433] Iteration 39500, Testing net (#0)
I0525 04:47:07.677088  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 04:48:11.750993  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.314656
I0525 04:48:12.985384  9498 solver.cpp:243] Iteration 39500, loss = 4.29083
I0525 04:48:12.985420  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.95682 (* 1 = 3.95682 loss)
I0525 04:48:12.985428  9498 sgd_solver.cpp:138] Iteration 39500, lr = 5e-05
I0525 04:50:25.919378  9498 solver.cpp:243] Iteration 39600, loss = 4.29917
I0525 04:50:25.919584  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.04077 (* 1 = 4.04077 loss)
I0525 04:50:25.919592  9498 sgd_solver.cpp:138] Iteration 39600, lr = 5e-05
I0525 04:52:38.894861  9498 solver.cpp:243] Iteration 39700, loss = 4.46936
I0525 04:52:38.895047  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.58537 (* 1 = 4.58537 loss)
I0525 04:52:38.895057  9498 sgd_solver.cpp:138] Iteration 39700, lr = 5e-05
I0525 04:54:51.793896  9498 solver.cpp:243] Iteration 39800, loss = 4.34622
I0525 04:54:51.794024  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.11342 (* 1 = 5.11342 loss)
I0525 04:54:51.794032  9498 sgd_solver.cpp:138] Iteration 39800, lr = 5e-05
I0525 04:57:04.653491  9498 solver.cpp:243] Iteration 39900, loss = 4.29054
I0525 04:57:04.653587  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.0557 (* 1 = 4.0557 loss)
I0525 04:57:04.653595  9498 sgd_solver.cpp:138] Iteration 39900, lr = 5e-05
I0525 04:59:16.267776  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_40000.caffemodel
I0525 04:59:16.329581  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_40000.solverstate
I0525 04:59:16.361898  9498 solver.cpp:433] Iteration 40000, Testing net (#0)
I0525 04:59:16.362002  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 05:00:20.437608  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.328564
I0525 05:00:21.675608  9498 solver.cpp:243] Iteration 40000, loss = 4.31157
I0525 05:00:21.675642  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.40455 (* 1 = 3.40455 loss)
I0525 05:00:21.675648  9498 sgd_solver.cpp:47] MultiStep Status: Iteration 40000, step = 2
I0525 05:00:21.675652  9498 sgd_solver.cpp:138] Iteration 40000, lr = 2.5e-05
I0525 05:02:34.554847  9498 solver.cpp:243] Iteration 40100, loss = 4.33584
I0525 05:02:34.554986  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.66022 (* 1 = 4.66022 loss)
I0525 05:02:34.554993  9498 sgd_solver.cpp:138] Iteration 40100, lr = 2.5e-05
I0525 05:04:47.397060  9498 solver.cpp:243] Iteration 40200, loss = 4.59631
I0525 05:04:47.397980  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.93202 (* 1 = 4.93202 loss)
I0525 05:04:47.397989  9498 sgd_solver.cpp:138] Iteration 40200, lr = 2.5e-05
I0525 05:07:00.269620  9498 solver.cpp:243] Iteration 40300, loss = 4.71582
I0525 05:07:00.269776  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.38057 (* 1 = 3.38057 loss)
I0525 05:07:00.269785  9498 sgd_solver.cpp:138] Iteration 40300, lr = 2.5e-05
I0525 05:09:13.122846  9498 solver.cpp:243] Iteration 40400, loss = 4.29
I0525 05:09:13.123020  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.65197 (* 1 = 4.65197 loss)
I0525 05:09:13.123028  9498 sgd_solver.cpp:138] Iteration 40400, lr = 2.5e-05
I0525 05:11:24.771239  9498 solver.cpp:433] Iteration 40500, Testing net (#0)
I0525 05:11:24.771445  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 05:12:28.733464  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.333172
I0525 05:12:29.964784  9498 solver.cpp:243] Iteration 40500, loss = 4.52231
I0525 05:12:29.964819  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.60104 (* 1 = 4.60104 loss)
I0525 05:12:29.964843  9498 sgd_solver.cpp:138] Iteration 40500, lr = 2.5e-05
I0525 05:14:42.841193  9498 solver.cpp:243] Iteration 40600, loss = 4.61548
I0525 05:14:42.841346  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.62907 (* 1 = 5.62907 loss)
I0525 05:14:42.841356  9498 sgd_solver.cpp:138] Iteration 40600, lr = 2.5e-05
I0525 05:16:55.721283  9498 solver.cpp:243] Iteration 40700, loss = 4.45778
I0525 05:16:55.721403  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.70617 (* 1 = 4.70617 loss)
I0525 05:16:55.721412  9498 sgd_solver.cpp:138] Iteration 40700, lr = 2.5e-05
I0525 05:19:08.553979  9498 solver.cpp:243] Iteration 40800, loss = 4.93091
I0525 05:19:08.554078  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.24181 (* 1 = 5.24181 loss)
I0525 05:19:08.554086  9498 sgd_solver.cpp:138] Iteration 40800, lr = 2.5e-05
I0525 05:21:21.371307  9498 solver.cpp:243] Iteration 40900, loss = 4.55604
I0525 05:21:21.371440  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.0646 (* 1 = 4.0646 loss)
I0525 05:21:21.371448  9498 sgd_solver.cpp:138] Iteration 40900, lr = 2.5e-05
I0525 05:23:33.008807  9498 solver.cpp:433] Iteration 41000, Testing net (#0)
I0525 05:23:33.009096  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 05:24:36.973331  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.344628
I0525 05:24:38.204614  9498 solver.cpp:243] Iteration 41000, loss = 4.47026
I0525 05:24:38.204648  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.2297 (* 1 = 4.2297 loss)
I0525 05:24:38.204655  9498 sgd_solver.cpp:138] Iteration 41000, lr = 2.5e-05
I0525 05:26:51.111876  9498 solver.cpp:243] Iteration 41100, loss = 4.48997
I0525 05:26:51.112021  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.83827 (* 1 = 3.83827 loss)
I0525 05:26:51.112030  9498 sgd_solver.cpp:138] Iteration 41100, lr = 2.5e-05
I0525 05:29:03.997745  9498 solver.cpp:243] Iteration 41200, loss = 4.53686
I0525 05:29:03.997906  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.31728 (* 1 = 4.31728 loss)
I0525 05:29:03.997915  9498 sgd_solver.cpp:138] Iteration 41200, lr = 2.5e-05
I0525 05:31:16.902437  9498 solver.cpp:243] Iteration 41300, loss = 4.41493
I0525 05:31:16.902590  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.22471 (* 1 = 4.22471 loss)
I0525 05:31:16.902601  9498 sgd_solver.cpp:138] Iteration 41300, lr = 2.5e-05
I0525 05:33:29.822456  9498 solver.cpp:243] Iteration 41400, loss = 4.58127
I0525 05:33:29.822558  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.91026 (* 1 = 4.91026 loss)
I0525 05:33:29.822566  9498 sgd_solver.cpp:138] Iteration 41400, lr = 2.5e-05
I0525 05:35:41.465045  9498 solver.cpp:433] Iteration 41500, Testing net (#0)
I0525 05:35:41.465261  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 05:36:45.449537  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.330501
I0525 05:36:46.679070  9498 solver.cpp:243] Iteration 41500, loss = 4.07287
I0525 05:36:46.679103  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.40542 (* 1 = 4.40542 loss)
I0525 05:36:46.679112  9498 sgd_solver.cpp:138] Iteration 41500, lr = 2.5e-05
I0525 05:38:59.547044  9498 solver.cpp:243] Iteration 41600, loss = 4.39276
I0525 05:38:59.547192  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.4005 (* 1 = 3.4005 loss)
I0525 05:38:59.547202  9498 sgd_solver.cpp:138] Iteration 41600, lr = 2.5e-05
I0525 05:41:12.352813  9498 solver.cpp:243] Iteration 41700, loss = 4.67911
I0525 05:41:12.352959  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.76546 (* 1 = 4.76546 loss)
I0525 05:41:12.352983  9498 sgd_solver.cpp:138] Iteration 41700, lr = 2.5e-05
I0525 05:43:25.342545  9498 solver.cpp:243] Iteration 41800, loss = 4.03842
I0525 05:43:25.342648  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.05375 (* 1 = 5.05375 loss)
I0525 05:43:25.342656  9498 sgd_solver.cpp:138] Iteration 41800, lr = 2.5e-05
I0525 05:45:38.120903  9498 solver.cpp:243] Iteration 41900, loss = 4.33358
I0525 05:45:38.121057  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.01089 (* 1 = 4.01089 loss)
I0525 05:45:38.121067  9498 sgd_solver.cpp:138] Iteration 41900, lr = 2.5e-05
I0525 05:47:49.697643  9498 solver.cpp:433] Iteration 42000, Testing net (#0)
I0525 05:47:49.697902  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 05:48:53.635977  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.349273
I0525 05:48:54.879101  9498 solver.cpp:243] Iteration 42000, loss = 4.50053
I0525 05:48:54.879150  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.73753 (* 1 = 4.73753 loss)
I0525 05:48:54.879160  9498 sgd_solver.cpp:138] Iteration 42000, lr = 2.5e-05
I0525 05:51:07.616523  9498 solver.cpp:243] Iteration 42100, loss = 4.85267
I0525 05:51:07.616657  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.74547 (* 1 = 4.74547 loss)
I0525 05:51:07.616665  9498 sgd_solver.cpp:138] Iteration 42100, lr = 2.5e-05
I0525 05:53:20.475212  9498 solver.cpp:243] Iteration 42200, loss = 4.50773
I0525 05:53:20.475313  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.44068 (* 1 = 5.44068 loss)
I0525 05:53:20.475322  9498 sgd_solver.cpp:138] Iteration 42200, lr = 2.5e-05
I0525 05:55:33.253652  9498 solver.cpp:243] Iteration 42300, loss = 4.516
I0525 05:55:33.253798  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.84289 (* 1 = 3.84289 loss)
I0525 05:55:33.253808  9498 sgd_solver.cpp:138] Iteration 42300, lr = 2.5e-05
I0525 05:57:46.136122  9498 solver.cpp:243] Iteration 42400, loss = 4.68377
I0525 05:57:46.136265  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.42572 (* 1 = 5.42572 loss)
I0525 05:57:46.136273  9498 sgd_solver.cpp:138] Iteration 42400, lr = 2.5e-05
I0525 05:59:57.762379  9498 solver.cpp:433] Iteration 42500, Testing net (#0)
I0525 05:59:57.762603  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 06:01:01.693140  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.333441
I0525 06:01:02.927011  9498 solver.cpp:243] Iteration 42500, loss = 4.55104
I0525 06:01:02.927048  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.10904 (* 1 = 4.10904 loss)
I0525 06:01:02.927057  9498 sgd_solver.cpp:138] Iteration 42500, lr = 2.5e-05
I0525 06:03:15.768880  9498 solver.cpp:243] Iteration 42600, loss = 4.34779
I0525 06:03:15.769026  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.81293 (* 1 = 4.81293 loss)
I0525 06:03:15.769033  9498 sgd_solver.cpp:138] Iteration 42600, lr = 2.5e-05
I0525 06:05:28.631536  9498 solver.cpp:243] Iteration 42700, loss = 4.68976
I0525 06:05:28.631667  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.20281 (* 1 = 4.20281 loss)
I0525 06:05:28.631675  9498 sgd_solver.cpp:138] Iteration 42700, lr = 2.5e-05
I0525 06:07:41.460512  9498 solver.cpp:243] Iteration 42800, loss = 4.11243
I0525 06:07:41.460646  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.08308 (* 1 = 4.08308 loss)
I0525 06:07:41.460654  9498 sgd_solver.cpp:138] Iteration 42800, lr = 2.5e-05
I0525 06:09:54.334012  9498 solver.cpp:243] Iteration 42900, loss = 4.58371
I0525 06:09:54.334161  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.09327 (* 1 = 4.09327 loss)
I0525 06:09:54.334169  9498 sgd_solver.cpp:138] Iteration 42900, lr = 2.5e-05
I0525 06:12:05.928651  9498 solver.cpp:433] Iteration 43000, Testing net (#0)
I0525 06:12:05.928866  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 06:13:09.886312  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.353484
I0525 06:13:11.119949  9498 solver.cpp:243] Iteration 43000, loss = 4.59583
I0525 06:13:11.119985  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.25752 (* 1 = 4.25752 loss)
I0525 06:13:11.119992  9498 sgd_solver.cpp:138] Iteration 43000, lr = 2.5e-05
I0525 06:15:23.960332  9498 solver.cpp:243] Iteration 43100, loss = 4.40304
I0525 06:15:23.960490  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.61232 (* 1 = 3.61232 loss)
I0525 06:15:23.960497  9498 sgd_solver.cpp:138] Iteration 43100, lr = 2.5e-05
I0525 06:17:36.759220  9498 solver.cpp:243] Iteration 43200, loss = 4.48081
I0525 06:17:36.759523  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.20187 (* 1 = 5.20187 loss)
I0525 06:17:36.759531  9498 sgd_solver.cpp:138] Iteration 43200, lr = 2.5e-05
I0525 06:19:49.594552  9498 solver.cpp:243] Iteration 43300, loss = 4.26502
I0525 06:19:49.594724  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.59586 (* 1 = 3.59586 loss)
I0525 06:19:49.594733  9498 sgd_solver.cpp:138] Iteration 43300, lr = 2.5e-05
I0525 06:22:02.453721  9498 solver.cpp:243] Iteration 43400, loss = 4.06534
I0525 06:22:02.453866  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.76005 (* 1 = 3.76005 loss)
I0525 06:22:02.453874  9498 sgd_solver.cpp:138] Iteration 43400, lr = 2.5e-05
I0525 06:24:14.058812  9498 solver.cpp:433] Iteration 43500, Testing net (#0)
I0525 06:24:14.059007  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 06:25:17.983245  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.348287
I0525 06:25:19.217242  9498 solver.cpp:243] Iteration 43500, loss = 4.24322
I0525 06:25:19.217274  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.56833 (* 1 = 4.56833 loss)
I0525 06:25:19.217283  9498 sgd_solver.cpp:138] Iteration 43500, lr = 2.5e-05
I0525 06:27:32.070351  9498 solver.cpp:243] Iteration 43600, loss = 4.34797
I0525 06:27:32.070518  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.06047 (* 1 = 4.06047 loss)
I0525 06:27:32.070526  9498 sgd_solver.cpp:138] Iteration 43600, lr = 2.5e-05
I0525 06:29:44.974717  9498 solver.cpp:243] Iteration 43700, loss = 4.48584
I0525 06:29:44.974870  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.65147 (* 1 = 4.65147 loss)
I0525 06:29:44.974881  9498 sgd_solver.cpp:138] Iteration 43700, lr = 2.5e-05
I0525 06:31:57.829949  9498 solver.cpp:243] Iteration 43800, loss = 4.5791
I0525 06:31:57.830101  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.20685 (* 1 = 5.20685 loss)
I0525 06:31:57.830108  9498 sgd_solver.cpp:138] Iteration 43800, lr = 2.5e-05
I0525 06:34:10.744277  9498 solver.cpp:243] Iteration 43900, loss = 4.14128
I0525 06:34:10.744397  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.85212 (* 1 = 3.85212 loss)
I0525 06:34:10.744405  9498 sgd_solver.cpp:138] Iteration 43900, lr = 2.5e-05
I0525 06:36:22.317847  9498 solver.cpp:433] Iteration 44000, Testing net (#0)
I0525 06:36:22.318064  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 06:37:26.210673  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.348712
I0525 06:37:27.448935  9498 solver.cpp:243] Iteration 44000, loss = 4.35983
I0525 06:37:27.448978  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.44799 (* 1 = 4.44799 loss)
I0525 06:37:27.448999  9498 sgd_solver.cpp:138] Iteration 44000, lr = 2.5e-05
I0525 06:39:40.306293  9498 solver.cpp:243] Iteration 44100, loss = 4.42351
I0525 06:39:40.306439  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.22177 (* 1 = 4.22177 loss)
I0525 06:39:40.306447  9498 sgd_solver.cpp:138] Iteration 44100, lr = 2.5e-05
I0525 06:41:53.113673  9498 solver.cpp:243] Iteration 44200, loss = 4.43435
I0525 06:41:53.113945  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.76159 (* 1 = 3.76159 loss)
I0525 06:41:53.113952  9498 sgd_solver.cpp:138] Iteration 44200, lr = 2.5e-05
I0525 06:44:06.004590  9498 solver.cpp:243] Iteration 44300, loss = 4.51676
I0525 06:44:06.004734  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.95889 (* 1 = 4.95889 loss)
I0525 06:44:06.004743  9498 sgd_solver.cpp:138] Iteration 44300, lr = 2.5e-05
I0525 06:46:18.802445  9498 solver.cpp:243] Iteration 44400, loss = 4.17734
I0525 06:46:18.802587  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.65725 (* 1 = 3.65725 loss)
I0525 06:46:18.802595  9498 sgd_solver.cpp:138] Iteration 44400, lr = 2.5e-05
I0525 06:48:30.371114  9498 solver.cpp:433] Iteration 44500, Testing net (#0)
I0525 06:48:30.371307  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 06:49:34.300595  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.360496
I0525 06:49:35.536413  9498 solver.cpp:243] Iteration 44500, loss = 4.84871
I0525 06:49:35.536448  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.40333 (* 1 = 4.40333 loss)
I0525 06:49:35.536454  9498 sgd_solver.cpp:138] Iteration 44500, lr = 2.5e-05
I0525 06:51:48.408710  9498 solver.cpp:243] Iteration 44600, loss = 4.3024
I0525 06:51:48.408869  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.53674 (* 1 = 3.53674 loss)
I0525 06:51:48.408893  9498 sgd_solver.cpp:138] Iteration 44600, lr = 2.5e-05
I0525 06:54:01.244786  9498 solver.cpp:243] Iteration 44700, loss = 4.22412
I0525 06:54:01.244910  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.2416 (* 1 = 4.2416 loss)
I0525 06:54:01.244933  9498 sgd_solver.cpp:138] Iteration 44700, lr = 2.5e-05
I0525 06:56:14.063594  9498 solver.cpp:243] Iteration 44800, loss = 4.39217
I0525 06:56:14.063756  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.17003 (* 1 = 4.17003 loss)
I0525 06:56:14.063764  9498 sgd_solver.cpp:138] Iteration 44800, lr = 2.5e-05
I0525 06:58:26.952409  9498 solver.cpp:243] Iteration 44900, loss = 4.78989
I0525 06:58:26.952564  9498 solver.cpp:259]     Train net output #0: mbox_loss = 2.73732 (* 1 = 2.73732 loss)
I0525 06:58:26.952572  9498 sgd_solver.cpp:138] Iteration 44900, lr = 2.5e-05
I0525 07:00:38.577742  9498 solver.cpp:596] Snapshotting to binary proto file mobilessd_step1/step1_iter_45000.caffemodel
I0525 07:00:38.638054  9498 sgd_solver.cpp:307] Snapshotting solver state to binary proto file mobilessd_step1/step1_iter_45000.solverstate
I0525 07:00:38.669356  9498 solver.cpp:433] Iteration 45000, Testing net (#0)
I0525 07:00:38.669459  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 07:01:42.576171  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.346975
I0525 07:01:43.811645  9498 solver.cpp:243] Iteration 45000, loss = 4.42279
I0525 07:01:43.811679  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.2423 (* 1 = 4.2423 loss)
I0525 07:01:43.811686  9498 sgd_solver.cpp:138] Iteration 45000, lr = 2.5e-05
I0525 07:03:56.665290  9498 solver.cpp:243] Iteration 45100, loss = 4.68892
I0525 07:03:56.665398  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.80206 (* 1 = 5.80206 loss)
I0525 07:03:56.665410  9498 sgd_solver.cpp:138] Iteration 45100, lr = 2.5e-05
I0525 07:06:09.484746  9498 solver.cpp:243] Iteration 45200, loss = 4.63376
I0525 07:06:09.484885  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.9662 (* 1 = 4.9662 loss)
I0525 07:06:09.484894  9498 sgd_solver.cpp:138] Iteration 45200, lr = 2.5e-05
I0525 07:08:22.329088  9498 solver.cpp:243] Iteration 45300, loss = 3.87824
I0525 07:08:22.329221  9498 solver.cpp:259]     Train net output #0: mbox_loss = 2.61497 (* 1 = 2.61497 loss)
I0525 07:08:22.329228  9498 sgd_solver.cpp:138] Iteration 45300, lr = 2.5e-05
I0525 07:10:35.179016  9498 solver.cpp:243] Iteration 45400, loss = 4.15414
I0525 07:10:35.179121  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.94678 (* 1 = 3.94678 loss)
I0525 07:10:35.179129  9498 sgd_solver.cpp:138] Iteration 45400, lr = 2.5e-05
I0525 07:12:46.743170  9498 solver.cpp:433] Iteration 45500, Testing net (#0)
I0525 07:12:46.743383  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 07:13:50.706497  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.349588
I0525 07:13:51.944742  9498 solver.cpp:243] Iteration 45500, loss = 4.39212
I0525 07:13:51.944777  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.99668 (* 1 = 3.99668 loss)
I0525 07:13:51.944783  9498 sgd_solver.cpp:138] Iteration 45500, lr = 2.5e-05
I0525 07:16:04.815841  9498 solver.cpp:243] Iteration 45600, loss = 4.28511
I0525 07:16:04.815982  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.62176 (* 1 = 4.62176 loss)
I0525 07:16:04.815990  9498 sgd_solver.cpp:138] Iteration 45600, lr = 2.5e-05
I0525 07:18:17.684203  9498 solver.cpp:243] Iteration 45700, loss = 4.41102
I0525 07:18:17.684362  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.51464 (* 1 = 4.51464 loss)
I0525 07:18:17.684371  9498 sgd_solver.cpp:138] Iteration 45700, lr = 2.5e-05
I0525 07:20:30.482761  9498 solver.cpp:243] Iteration 45800, loss = 4.19166
I0525 07:20:30.482898  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.60901 (* 1 = 4.60901 loss)
I0525 07:20:30.482906  9498 sgd_solver.cpp:138] Iteration 45800, lr = 2.5e-05
I0525 07:22:43.345849  9498 solver.cpp:243] Iteration 45900, loss = 4.6081
I0525 07:22:43.346002  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.11318 (* 1 = 4.11318 loss)
I0525 07:22:43.346011  9498 sgd_solver.cpp:138] Iteration 45900, lr = 2.5e-05
I0525 07:24:54.960654  9498 solver.cpp:433] Iteration 46000, Testing net (#0)
I0525 07:24:54.960878  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 07:25:58.880167  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.348024
I0525 07:26:00.115411  9498 solver.cpp:243] Iteration 46000, loss = 4.58913
I0525 07:26:00.115443  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.71079 (* 1 = 4.71079 loss)
I0525 07:26:00.115451  9498 sgd_solver.cpp:138] Iteration 46000, lr = 2.5e-05
I0525 07:28:12.985183  9498 solver.cpp:243] Iteration 46100, loss = 4.42306
I0525 07:28:12.985368  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.13395 (* 1 = 4.13395 loss)
I0525 07:28:12.985378  9498 sgd_solver.cpp:138] Iteration 46100, lr = 2.5e-05
I0525 07:30:25.820423  9498 solver.cpp:243] Iteration 46200, loss = 4.78108
I0525 07:30:25.820555  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.33822 (* 1 = 3.33822 loss)
I0525 07:30:25.820564  9498 sgd_solver.cpp:138] Iteration 46200, lr = 2.5e-05
I0525 07:32:38.650928  9498 solver.cpp:243] Iteration 46300, loss = 4.39477
I0525 07:32:38.651803  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.67251 (* 1 = 4.67251 loss)
I0525 07:32:38.651811  9498 sgd_solver.cpp:138] Iteration 46300, lr = 2.5e-05
I0525 07:34:51.527730  9498 solver.cpp:243] Iteration 46400, loss = 4.69271
I0525 07:34:51.527819  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.64074 (* 1 = 4.64074 loss)
I0525 07:34:51.527827  9498 sgd_solver.cpp:138] Iteration 46400, lr = 2.5e-05
I0525 07:37:03.121371  9498 solver.cpp:433] Iteration 46500, Testing net (#0)
I0525 07:37:03.121582  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 07:38:07.038524  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.335609
I0525 07:38:08.269862  9498 solver.cpp:243] Iteration 46500, loss = 4.41791
I0525 07:38:08.269896  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.91991 (* 1 = 4.91991 loss)
I0525 07:38:08.269904  9498 sgd_solver.cpp:138] Iteration 46500, lr = 2.5e-05
I0525 07:40:21.050966  9498 solver.cpp:243] Iteration 46600, loss = 4.54793
I0525 07:40:21.051123  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.19037 (* 1 = 4.19037 loss)
I0525 07:40:21.051133  9498 sgd_solver.cpp:138] Iteration 46600, lr = 2.5e-05
I0525 07:42:33.961035  9498 solver.cpp:243] Iteration 46700, loss = 4.64066
I0525 07:42:33.961189  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.68417 (* 1 = 5.68417 loss)
I0525 07:42:33.961196  9498 sgd_solver.cpp:138] Iteration 46700, lr = 2.5e-05
I0525 07:44:46.818795  9498 solver.cpp:243] Iteration 46800, loss = 4.54577
I0525 07:44:46.818938  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.09572 (* 1 = 4.09572 loss)
I0525 07:44:46.818946  9498 sgd_solver.cpp:138] Iteration 46800, lr = 2.5e-05
I0525 07:46:59.759452  9498 solver.cpp:243] Iteration 46900, loss = 4.66107
I0525 07:46:59.759615  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.2327 (* 1 = 4.2327 loss)
I0525 07:46:59.759624  9498 sgd_solver.cpp:138] Iteration 46900, lr = 2.5e-05
I0525 07:49:11.442430  9498 solver.cpp:433] Iteration 47000, Testing net (#0)
I0525 07:49:11.442652  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 07:50:15.390728  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.341849
I0525 07:50:16.622092  9498 solver.cpp:243] Iteration 47000, loss = 4.9035
I0525 07:50:16.622128  9498 solver.cpp:259]     Train net output #0: mbox_loss = 5.11926 (* 1 = 5.11926 loss)
I0525 07:50:16.622135  9498 sgd_solver.cpp:138] Iteration 47000, lr = 2.5e-05
I0525 07:52:29.429989  9498 solver.cpp:243] Iteration 47100, loss = 4.57607
I0525 07:52:29.430153  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.26364 (* 1 = 3.26364 loss)
I0525 07:52:29.430163  9498 sgd_solver.cpp:138] Iteration 47100, lr = 2.5e-05
I0525 07:54:42.327776  9498 solver.cpp:243] Iteration 47200, loss = 4.36989
I0525 07:54:42.327909  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.81518 (* 1 = 4.81518 loss)
I0525 07:54:42.327916  9498 sgd_solver.cpp:138] Iteration 47200, lr = 2.5e-05
I0525 07:56:55.243299  9498 solver.cpp:243] Iteration 47300, loss = 4.27575
I0525 07:56:55.243444  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.70006 (* 1 = 3.70006 loss)
I0525 07:56:55.243453  9498 sgd_solver.cpp:138] Iteration 47300, lr = 2.5e-05
I0525 07:59:08.105870  9498 solver.cpp:243] Iteration 47400, loss = 4.43615
I0525 07:59:08.105974  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.60117 (* 1 = 4.60117 loss)
I0525 07:59:08.105983  9498 sgd_solver.cpp:138] Iteration 47400, lr = 2.5e-05
I0525 08:01:19.749899  9498 solver.cpp:433] Iteration 47500, Testing net (#0)
I0525 08:01:19.750124  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 08:02:23.676903  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.351217
I0525 08:02:24.910686  9498 solver.cpp:243] Iteration 47500, loss = 5.098
I0525 08:02:24.910719  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.59541 (* 1 = 4.59541 loss)
I0525 08:02:24.910727  9498 sgd_solver.cpp:138] Iteration 47500, lr = 2.5e-05
I0525 08:04:37.722079  9498 solver.cpp:243] Iteration 47600, loss = 4.52036
I0525 08:04:37.722229  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.81867 (* 1 = 4.81867 loss)
I0525 08:04:37.722237  9498 sgd_solver.cpp:138] Iteration 47600, lr = 2.5e-05
I0525 08:06:50.540390  9498 solver.cpp:243] Iteration 47700, loss = 4.33911
I0525 08:06:50.540494  9498 solver.cpp:259]     Train net output #0: mbox_loss = 3.41373 (* 1 = 3.41373 loss)
I0525 08:06:50.540503  9498 sgd_solver.cpp:138] Iteration 47700, lr = 2.5e-05
I0525 08:09:03.412420  9498 solver.cpp:243] Iteration 47800, loss = 4.04239
I0525 08:09:03.412564  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.08367 (* 1 = 4.08367 loss)
I0525 08:09:03.412571  9498 sgd_solver.cpp:138] Iteration 47800, lr = 2.5e-05
I0525 08:11:16.303854  9498 solver.cpp:243] Iteration 47900, loss = 4.32915
I0525 08:11:16.303992  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.53061 (* 1 = 4.53061 loss)
I0525 08:11:16.304002  9498 sgd_solver.cpp:138] Iteration 47900, lr = 2.5e-05
I0525 08:13:27.887832  9498 solver.cpp:433] Iteration 48000, Testing net (#0)
I0525 08:13:27.888047  9498 net.cpp:693] Ignoring source layer mbox_loss
I0525 08:14:31.798633  9498 solver.cpp:546]     Test net output #0: detection_eval = 0.344747
I0525 08:14:33.027405  9498 solver.cpp:243] Iteration 48000, loss = 4.56623
I0525 08:14:33.027439  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.26293 (* 1 = 4.26293 loss)
I0525 08:14:33.027446  9498 sgd_solver.cpp:138] Iteration 48000, lr = 2.5e-05
I0525 08:16:45.945305  9498 solver.cpp:243] Iteration 48100, loss = 4.41415
I0525 08:16:45.945435  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.03935 (* 1 = 4.03935 loss)
I0525 08:16:45.945443  9498 sgd_solver.cpp:138] Iteration 48100, lr = 2.5e-05
I0525 08:18:58.780593  9498 solver.cpp:243] Iteration 48200, loss = 4.68201
I0525 08:18:58.780747  9498 solver.cpp:259]     Train net output #0: mbox_loss = 6.08368 (* 1 = 6.08368 loss)
I0525 08:18:58.780755  9498 sgd_solver.cpp:138] Iteration 48200, lr = 2.5e-05
I0525 08:21:11.610368  9498 solver.cpp:243] Iteration 48300, loss = 4.73285
I0525 08:21:11.610502  9498 solver.cpp:259]     Train net output #0: mbox_loss = 4.65215 (* 1 = 4.65215 loss)
I0525 08:21:11.610512  9498 sgd_solver.cpp:138] Iteration 48300, lr = 2.5e-05
